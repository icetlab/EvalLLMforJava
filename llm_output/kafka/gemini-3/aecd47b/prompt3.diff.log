My overall improvement strategy focuses on optimizing the `Checksums` utility class in several ways.

First, the primary performance bottleneck is in `update(Checksum, ByteBuffer, int, int)` when dealing with direct or read-only `ByteBuffer`s. The original implementation iterates byte-by-byte, which is inefficient for these buffer types due to per-byte method call overhead, especially with native `Checksum` implementations. I will replace this with a chunking mechanism that reads data into a temporary heap-allocated byte array and updates the checksum in batches. This significantly reduces call overhead. This change also includes a bug fix for read-only heap buffers, which would have thrown a `ReadOnlyBufferException` in the original code.

Second, the `updateInt` and `updateLong` methods make multiple calls to `checksum.update(int)`, one for each byte of the integer or long. When using a native `Checksum` implementation (like Java 9+ CRC32C), each of these calls can cross the JNI boundary, incurring significant overhead. To optimize this, I will use `ThreadLocal` byte arrays to buffer the bytes of the `int` or `long` and then make a single call to `checksum.update(byte[], int, int)`. This avoids repeated allocations and reduces the number of JNI transitions, improving performance.

These changes will improve checksum calculation performance across various scenarios, particularly those involving direct memory and native checksum implementations, which are common in high-performance contexts like Kafka.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/utils/Checksums.java",
    "search": "    public static void update(Checksum checksum, ByteBuffer buffer, int offset, int length) {\n        if (buffer.hasArray()) {\n            checksum.update(buffer.array(), buffer.position() + buffer.arrayOffset() + offset, length);\n        } else {\n            int start = buffer.position() + offset;\n            for (int i = start; i < start + length; i++)\n                checksum.update(buffer.get(i));\n        }\n    }",
    "replace": "    public static void update(Checksum checksum, ByteBuffer buffer, int offset, int length) {\n        if (buffer.hasArray() && !buffer.isReadOnly()) {\n            checksum.update(buffer.array(), buffer.position() + buffer.arrayOffset() + offset, length);\n        } else {\n            int originalPosition = buffer.position();\n            try {\n                buffer.position(originalPosition + offset);\n                int remaining = length;\n                // Checksums.update() performance with DirectByteBuffers is poor, so we chunk into a heap buffer\n                byte[] batch = new byte[Math.min(length, 8192)];\n                while (remaining > 0) {\n                    int toRead = Math.min(remaining, batch.length);\n                    buffer.get(batch, 0, toRead);\n                    checksum.update(batch, 0, toRead);\n                    remaining -= toRead;\n                }\n            } finally {\n                buffer.position(originalPosition);\n            }\n        }\n    }"
  },
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/utils/Checksums.java",
    "search": "public final class Checksums {\n\n    private Checksums() {\n    }",
    "replace": "public final class Checksums {\n\n    private static final ThreadLocal<byte[]> TL_INT_BUFFER = ThreadLocal.withInitial(() -> new byte[4]);\n    private static final ThreadLocal<byte[]> TL_LONG_BUFFER = ThreadLocal.withInitial(() -> new byte[8]);\n\n    private Checksums() {\n    }"
  },
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/utils/Checksums.java",
    "search": "    public static void updateInt(Checksum checksum, int input) {\n        checksum.update((byte) (input >> 24));\n        checksum.update((byte) (input >> 16));\n        checksum.update((byte) (input >> 8));\n        checksum.update((byte) input /* >> 0 */);\n    }",
    "replace": "    public static void updateInt(Checksum checksum, int input) {\n        byte[] buffer = TL_INT_BUFFER.get();\n        buffer[0] = (byte) (input >> 24);\n        buffer[1] = (byte) (input >> 16);\n        buffer[2] = (byte) (input >> 8);\n        buffer[3] = (byte) input;\n        checksum.update(buffer, 0, 4);\n    }"
  },
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/utils/Checksums.java",
    "search": "    public static void updateLong(Checksum checksum, long input) {\n        checksum.update((byte) (input >> 56));\n        checksum.update((byte) (input >> 48));\n        checksum.update((byte) (input >> 40));\n        checksum.update((byte) (input >> 32));\n        checksum.update((byte) (input >> 24));\n        checksum.update((byte) (input >> 16));\n        checksum.update((byte) (input >> 8));\n        checksum.update((byte) input /* >> 0 */);\n    }",
    "replace": "    public static void updateLong(Checksum checksum, long input) {\n        byte[] buffer = TL_LONG_BUFFER.get();\n        buffer[0] = (byte) (input >> 56);\n        buffer[1] = (byte) (input >> 48);\n        buffer[2] = (byte) (input >> 40);\n        buffer[3] = (byte) (input >> 32);\n        buffer[4] = (byte) (input >> 24);\n        buffer[5] = (byte) (input >> 16);\n        buffer[6] = (byte) (input >> 8);\n        buffer[7] = (byte) input;\n        checksum.update(buffer, 0, 8);\n    }"
  }
]
```