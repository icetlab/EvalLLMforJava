The overall intent of my improvements is to enhance the performance of the `Partition` class, which is critical for Kafka's broker performance. The changes focus on optimizing collection operations and replacing higher-order function calls with more efficient iterator-based loops in hot paths.

Specifically, I've made the following improvements:
1.  Optimized `OngoingReassignmentState` by caching `addingReplicas` as a `Set`. This changes `isAddingReplica` from an O(N) to an O(1) operation and improves `replicationFactor` from a potentially O(N*M) to an O(N+M) operation, avoiding performance degradation during partition reassignments.
2.  Replaced a `filter` followed by `foreach` with a single `foreach` containing an `if` condition in `updateAssignmentAndIsr`. This avoids the allocation of an intermediate collection.
3.  Converted `foreach` loops into faster `while` loops using explicit iterators in the performance-sensitive methods `maybeIncrementLeaderHW` and `lowWatermarkIfLeader`. This reduces overhead from closure and implicit object creation on each invocation.

These changes collectively reduce CPU usage and object allocation, leading to better overall performance and lower garbage collection pressure.

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "case class OngoingReassignmentState(addingReplicas: Seq[Int],\n                                    removingReplicas: Seq[Int],\n                                    replicas: Seq[Int]) extends AssignmentState {\n\n  override def replicationFactor: Int = replicas.diff(addingReplicas).size // keep the size of the original replicas\n  override def isAddingReplica(replicaId: Int): Boolean = addingReplicas.contains(replicaId)\n}",
    "replace": "case class OngoingReassignmentState(addingReplicas: Seq[Int],\n                                    removingReplicas: Seq[Int],\n                                    replicas: Seq[Int]) extends AssignmentState {\n\n  private val addingReplicasSet = addingReplicas.toSet\n\n  override def replicationFactor: Int = replicas.count(!addingReplicasSet.contains(_)) // keep the size of the original replicas\n  override def isAddingReplica(replicaId: Int): Boolean = addingReplicasSet.contains(replicaId)\n}"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "    assignment\n      .filter(_ != localBrokerId)\n      .foreach(id => remoteReplicasMap.getAndMaybePut(id, new Replica(id, topicPartition)))",
    "replace": "    assignment.foreach { id =>\n      if (id != localBrokerId)\n        remoteReplicasMap.getAndMaybePut(id, new Replica(id, topicPartition))\n    }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "      var newHighWatermark = leaderLog.logEndOffsetMetadata\n      remoteReplicasMap.values.foreach { replica =>\n        if (replica.logEndOffsetMetadata.messageOffset < newHighWatermark.messageOffset &&\n          (curTime - replica.lastCaughtUpTimeMs <= replicaLagTimeMaxMs || inSyncReplicaIds.contains(replica.brokerId))) {\n          newHighWatermark = replica.logEndOffsetMetadata\n        }\n      }",
    "replace": "      var newHighWatermark = leaderLog.logEndOffsetMetadata\n      val iterator = remoteReplicasMap.values.iterator\n      while (iterator.hasNext) {\n        val replica = iterator.next()\n        if (replica.logEndOffsetMetadata.messageOffset < newHighWatermark.messageOffset &&\n          (curTime - replica.lastCaughtUpTimeMs <= replicaLagTimeMaxMs || inSyncReplicaIds.contains(replica.brokerId))) {\n          newHighWatermark = replica.logEndOffsetMetadata\n        }\n      }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "    var lowWaterMark = localLogOrException.logStartOffset\n    remoteReplicas.foreach { replica =>\n      if (metadataCache.getAliveBroker(replica.brokerId).nonEmpty && replica.logStartOffset < lowWaterMark) {\n        lowWaterMark = replica.logStartOffset\n      }\n    }",
    "replace": "    var lowWaterMark = localLogOrException.logStartOffset\n    val iterator = remoteReplicas.iterator\n    while (iterator.hasNext) {\n      val replica = iterator.next()\n      if (metadataCache.getAliveBroker(replica.brokerId).nonEmpty && replica.logStartOffset < lowWaterMark) {\n        lowWaterMark = replica.logStartOffset\n      }\n    }"
  }
]
```