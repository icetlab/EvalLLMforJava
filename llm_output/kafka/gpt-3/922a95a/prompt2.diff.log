I have introduced a dedicated `futureReplicaLock` to isolate operations on the future replica/log from the main ISR lock. Methods that previously used `leaderIsrUpdateLock` for guarding future replica actions now use this new lock, allowing follower appends to proceed without blocking leader ISR updates.

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "private val leaderIsrUpdateLock = new ReentrantReadWriteLock",
    "replace": "private val leaderIsrUpdateLock = new ReentrantReadWriteLock\n  private val futureReplicaLock = new ReentrantReadWriteLock"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "def maybeCreateFutureReplica(logDir: String, highWatermarkCheckpoints: OffsetCheckpoints): Boolean = {\n    // The writeLock is needed to make sure that while the caller checks the log directory of the\n    // current replica and the existence of the future replica, no other thread can update the log directory of the\n    // current replica or remove the future replica.\n    inWriteLock(leaderIsrUpdateLock) {",
    "replace": "def maybeCreateFutureReplica(logDir: String, highWatermarkCheckpoints: OffsetCheckpoints): Boolean = {\n    // Guard future-log creation/removal separately\n    inWriteLock(futureReplicaLock) {"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "def futureReplicaDirChanged(newDestinationDir: String): Boolean = {\n    inReadLock(leaderIsrUpdateLock) {",
    "replace": "def futureReplicaDirChanged(newDestinationDir: String): Boolean = {\n    inReadLock(futureReplicaLock) {"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "def removeFutureLocalReplica(deleteFromLogDir: Boolean = true): Unit = {\n    inWriteLock(leaderIsrUpdateLock) {",
    "replace": "def removeFutureLocalReplica(deleteFromLogDir: Boolean = true): Unit = {\n    inWriteLock(futureReplicaLock) {"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "def maybeReplaceCurrentWithFutureReplica(): Boolean = {\n    val localReplicaLEO = localLogOrException.logEndOffset\n    val futureReplicaLEO = futureLog.map(_.logEndOffset)\n    if (futureReplicaLEO.contains(localReplicaLEO)) {\n      // The write lock is needed to make sure that while ReplicaAlterDirThread checks the LEO of the\n      // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.\n      inWriteLock(leaderIsrUpdateLock) {",
    "replace": "def maybeReplaceCurrentWithFutureReplica(): Boolean = {\n    val localReplicaLEO = localLogOrException.logEndOffset\n    val futureReplicaLEO = futureLog.map(_.logEndOffset)\n    if (futureReplicaLEO.contains(localReplicaLEO)) {\n      // Guard replacement of current with future replica separately\n      inWriteLock(futureReplicaLock) {"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {\n    // The read lock is needed to handle race condition if request handler thread tries to\n    // remove future replica after receiving AlterReplicaLogDirsRequest.\n    inReadLock(leaderIsrUpdateLock) {",
    "replace": "private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {\n    // Guard follower/future append separately\n    inReadLock(futureReplicaLock) {"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "def truncateTo(offset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    inReadLock(leaderIsrUpdateLock) {",
    "replace": "def truncateTo(offset: Long, isFuture: Boolean): Unit = {\n    // Guard truncation separately\n    inReadLock(futureReplicaLock) {"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    inReadLock(leaderIsrUpdateLock) {",
    "replace": "def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {\n    // Guard full-truncate separately\n    inReadLock(futureReplicaLock) {"
  }
]
```