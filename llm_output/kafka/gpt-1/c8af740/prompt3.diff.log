Iâ€™ve optimized removeExpiredProducers to avoid temporary collections and repeated lookups by using iterator-based in-place removal, reducing per-call allocations and improving throughput for large maps.

```json
[
  {
    "filepath": "../kafka/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java",
    "search": "public void removeExpiredProducers(long currentTimeMs) {\n        List<Long> keys = producers.entrySet().stream()\n                .filter(entry -> isProducerExpired(currentTimeMs, entry.getValue()))\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        removeProducerIds(keys);\n\n        List<Long> verificationKeys = verificationStates.entrySet().stream()\n                .filter(entry -> currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs())\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        verificationKeys.forEach(verificationStates::remove);\n    }",
    "replace": "public void removeExpiredProducers(long currentTimeMs) {\n        // Remove expired producer entries in-place to avoid extra allocations\n        Iterator<Map.Entry<Long, ProducerStateEntry>> it = producers.entrySet().iterator();\n        while (it.hasNext()) {\n            Map.Entry<Long, ProducerStateEntry> entry = it.next();\n            if (isProducerExpired(currentTimeMs, entry.getValue())) {\n                it.remove();\n            }\n        }\n        producerIdCount = producers.size();\n\n        // Remove expired verification entries in-place\n        Iterator<Map.Entry<Long, VerificationStateEntry>> vIt = verificationStates.entrySet().iterator();\n        while (vIt.hasNext()) {\n            Map.Entry<Long, VerificationStateEntry> entry = vIt.next();\n            if (currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs()) {\n                vIt.remove();\n            }\n        }\n    }"
  }
]
```