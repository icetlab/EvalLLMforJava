I have optimized the `removeExpiredProducers` method to use iterator-based removal (via `removeIf`) to avoid intermediate collections and double iteration, reducing garbage and improving throughput under heavy loads.

```json
[
  {
    "filepath": "../kafka/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java",
    "search": "public void removeExpiredProducers(long currentTimeMs) {\n        List<Long> keys = producers.entrySet().stream()\n                .filter(entry -> isProducerExpired(currentTimeMs, entry.getValue()))\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        removeProducerIds(keys);\n\n        List<Long> verificationKeys = verificationStates.entrySet().stream()\n                .filter(entry -> currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs())\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        verificationKeys.forEach(verificationStates::remove);\n    }",
    "replace": "public void removeExpiredProducers(long currentTimeMs) {\n        // Expire idle producer entries directly\n        producers.entrySet().removeIf(entry -> isProducerExpired(currentTimeMs, entry.getValue()));\n        producerIdCount = producers.size();\n\n        // Expire stale verification state entries directly\n        verificationStates.entrySet().removeIf(entry ->\n                currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs()\n        );\n    }"
  }
]
```