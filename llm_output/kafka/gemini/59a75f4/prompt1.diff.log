The overall improvement intent is to optimize several methods in `PartitionStates` and `AbstractFetcherThread` that are involved in managing and iterating over partition states. The key performance enhancements are:

1.  In `PartitionStates.java`, the `update` method is improved to iterate over the entry set of the input map and store `Map.Entry` objects in the intermediate data structure. This avoids repeated lookups (`Map.get`) in the second loop, making the process of re-grouping partitions by topic more efficient.

2.  In `AbstractFetcherThread.scala`, two methods that iterate over partition states are refactored to avoid creating unnecessary intermediate objects.
    -   `updateFetchOffsetAndMaybeMarkTruncationComplete` is modified to directly iterate over the underlying `partitionStateMap` instead of calling `partitionStates()`, which creates a new list of `PartitionState` objects on each invocation. This significantly reduces object allocation and processing overhead in a potentially hot path. The updated implementation explicitly uses a `java.util.LinkedHashMap` to ensure that the partition order is preserved, which is crucial for the subsequent `set` call.
    -   `partitionsAndOffsets` is similarly changed to iterate directly over `partitionStateMap`, eliminating the allocation of an intermediate list and `PartitionState` objects, thus improving its performance.

These changes reduce object churn and CPU usage, especially when dealing with a large number of partitions, while preserving the original functionality and correctness.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java",
    "search": "    private void update(Map<TopicPartition, S> partitionToState) {\n        LinkedHashMap<String, List<TopicPartition>> topicToPartitions = new LinkedHashMap<>();\n        for (TopicPartition tp : partitionToState.keySet()) {\n            List<TopicPartition> partitions = topicToPartitions.computeIfAbsent(tp.topic(), k -> new ArrayList<>());\n            partitions.add(tp);\n        }\n        for (Map.Entry<String, List<TopicPartition>> entry : topicToPartitions.entrySet()) {\n            for (TopicPartition tp : entry.getValue()) {\n                S state = partitionToState.get(tp);\n                map.put(tp, state);\n            }\n        }\n    }",
    "replace": "    private void update(Map<TopicPartition, S> partitionToState) {\n        LinkedHashMap<String, List<Map.Entry<TopicPartition, S>>> topicToEntries = new LinkedHashMap<>();\n        for (Map.Entry<TopicPartition, S> entry : partitionToState.entrySet()) {\n            topicToEntries.computeIfAbsent(entry.getKey().topic(), k -> new ArrayList<>()).add(entry);\n        }\n\n        for (List<Map.Entry<TopicPartition, S>> entries : topicToEntries.values()) {\n            for (Map.Entry<TopicPartition, S> entry : entries) {\n                map.put(entry.getKey(), entry.getValue());\n            }\n        }\n    }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {\n    val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStates.asScala\n      .map { state =>\n        val currentFetchState = state.value\n        val maybeTruncationComplete = fetchOffsets.get(state.topicPartition) match {\n          case Some(offsetTruncationState) =>\n            val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n            PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n              currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n          case None => currentFetchState\n        }\n        (state.topicPartition, maybeTruncationComplete)\n      }.toMap\n    partitionStates.set(newStates.asJava)\n  }",
    "replace": "  private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {\n    val newStates = new java.util.LinkedHashMap[TopicPartition, PartitionFetchState](partitionStates.size)\n    partitionStates.partitionStateMap.forEach { (tp, currentFetchState) =>\n      val newState = fetchOffsets.get(tp) match {\n        case Some(offsetTruncationState) =>\n          val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n          PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n            currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n        case None => currentFetchState\n      }\n      newStates.put(tp, newState)\n    }\n    partitionStates.set(newStates)\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {\n    partitionStates.partitionStates.asScala.map { state =>\n      val initialFetchState = InitialFetchState(sourceBroker,\n        currentLeaderEpoch = state.value.currentLeaderEpoch,\n        initOffset = state.value.fetchOffset)\n      state.topicPartition -> initialFetchState\n    }.toMap\n  }",
    "replace": "  private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {\n    partitionStates.partitionStateMap.asScala.map { case (tp, state) =>\n      tp -> InitialFetchState(sourceBroker,\n        currentLeaderEpoch = state.currentLeaderEpoch,\n        initOffset = state.fetchOffset)\n    }.toMap\n  }"
  }
]
```