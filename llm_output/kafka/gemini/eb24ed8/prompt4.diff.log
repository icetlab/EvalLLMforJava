The performance issue stems from zstd-jni's `ZstdInputStream` and `ZstdOutputStream` which can be inefficient for small, byte-by-byte reads and writes. Such operations lead to excessive JNI context switching between Java and native code, which is a significant performance bottleneck. Additionally, creating and closing these streams frequently can cause high garbage collection activity due to large internal buffer allocations.

To mitigate this, I will wrap the `ZstdInputStream` and `ZstdOutputStream` with `BufferedInputStream` and `BufferedOutputStream` respectively. This is a standard Java practice to improve I/O performance. By doing so, small read/write operations will be buffered in memory and performed in larger chunks on the underlying Zstd streams. This drastically reduces the number of JNI calls. I've chosen a buffer size of 16KB, which is consistent with the existing GZIP implementation in Kafka and provides a good balance between memory usage and performance gains.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/record/CompressionType.java",
    "search": "    ZSTD(4, \"zstd\", 1.0f) {\n        @Override\n        public OutputStream wrapForOutput(ByteBufferOutputStream buffer, byte messageVersion) {\n            try {\n                return (OutputStream) ZstdConstructors.OUTPUT.invoke(buffer);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n\n        @Override\n        public InputStream wrapForInput(ByteBuffer buffer, byte messageVersion, BufferSupplier decompressionBufferSupplier) {\n            try {\n                return (InputStream) ZstdConstructors.INPUT.invoke(new ByteBufferInputStream(buffer));\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n    };",
    "replace": "    ZSTD(4, \"zstd\", 1.0f) {\n        @Override\n        public OutputStream wrapForOutput(ByteBufferOutputStream buffer, byte messageVersion) {\n            try {\n                // Set input buffer (uncompressed) to 16 KB (GZIP default) to ensure reasonable performance in cases\n                // where the caller passes a small number of bytes to write (potentially a single byte).\n                return new BufferedOutputStream((OutputStream) ZstdConstructors.OUTPUT.invoke(buffer), 16 * 1024);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n\n        @Override\n        public InputStream wrapForInput(ByteBuffer buffer, byte messageVersion, BufferSupplier decompressionBufferSupplier) {\n            try {\n                // Set output buffer (uncompressed) to 16 KB (GZIP default) to ensure reasonable performance in cases\n                // where the caller reads a small number of bytes (potentially a single byte).\n                return new BufferedInputStream((InputStream) ZstdConstructors.INPUT.invoke(new ByteBufferInputStream(buffer)),\n                        16 * 1024);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n    };"
  }
]
```