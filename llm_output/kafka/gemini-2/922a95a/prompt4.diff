diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala
index 9cfd99e8e5..e92f1eb721 100755
--- a/core/src/main/scala/kafka/cluster/Partition.scala
+++ b/core/src/main/scala/kafka/cluster/Partition.scala
@@ -203,6 +203,9 @@ class Partition(val topicPartition: TopicPartition,
   private val remoteReplicasMap = new Pool[Int, Replica]
   // The read lock is only required when multiple reads are executed and needs to be in a consistent manner
   private val leaderIsrUpdateLock = new ReentrantReadWriteLock
+  // A lock that guards the future log. This is used to ensure that the log identity of the future-log-to-be-swapped
+  // is not changed during log directory reassignment.
+  private val futureLogLock = new ReentrantReadWriteLock
   private var zkVersion: Int = LeaderAndIsr.initialZKVersion
   @volatile private var leaderEpoch: Int = LeaderAndIsr.initialLeaderEpoch - 1
   // start offset for 'leaderEpoch' above (leader epoch of the current leader for this partition),
@@ -412,11 +415,13 @@ class Partition(val topicPartition: TopicPartition,
 
   def removeFutureLocalReplica(deleteFromLogDir: Boolean = true): Unit = {
     inWriteLock(leaderIsrUpdateLock) {
+      inWriteLock(futureLogLock) {
         futureLog = None
         if (deleteFromLogDir)
           logManager.asyncDelete(topicPartition, isFuture = true)
       }
     }
+  }
 
   // Return true iff the future replica exists and it has caught up with the current replica for this partition
   // Only ReplicaAlterDirThread will call this method and ReplicaAlterDirThread should remove the partition
@@ -428,6 +433,7 @@ class Partition(val topicPartition: TopicPartition,
       // The write lock is needed to make sure that while ReplicaAlterDirThread checks the LEO of the
       // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.
       inWriteLock(leaderIsrUpdateLock) {
+        inWriteLock(futureLogLock) {
           futureLog match {
             case Some(futurePartitionLog) =>
               if (log.exists(_.logEndOffset == futurePartitionLog.logEndOffset)) {
@@ -444,12 +450,14 @@ class Partition(val topicPartition: TopicPartition,
               false
           }
         }
+      }
     } else false
   }
 
   def delete(): Unit = {
     // need to hold the lock to prevent appendMessagesToLeader() from hitting I/O exceptions due to log being deleted
     inWriteLock(leaderIsrUpdateLock) {
+      inWriteLock(futureLogLock) {
         remoteReplicasMap.clear()
         assignmentState = SimpleAssignmentState(Seq.empty)
         log = None
@@ -463,6 +471,7 @@ class Partition(val topicPartition: TopicPartition,
           logManager.asyncDelete(topicPartition, isFuture = true)
       }
     }
+  }
 
   def getLeaderEpoch: Int = this.leaderEpoch
 
@@ -911,16 +920,14 @@ class Partition(val topicPartition: TopicPartition,
   }
 
   private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {
-    // The read lock is needed to handle race condition if request handler thread tries to
-    // remove future replica after receiving AlterReplicaLogDirsRequest.
-    inReadLock(leaderIsrUpdateLock) {
+    // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread
+    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.
+    inReadLock(futureLogLock) {
       if (isFuture) {
         // Note the replica may be undefined if it is removed by a non-ReplicaAlterLogDirsThread before
         // this method is called
         futureLog.map { _.appendAsFollower(records) }
       } else {
-        // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread
-        // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.
         Some(localLogOrException.appendAsFollower(records))
       }
     }
@@ -1128,7 +1135,7 @@ class Partition(val topicPartition: TopicPartition,
   def truncateTo(offset: Long, isFuture: Boolean): Unit = {
     // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread
     // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.
-    inReadLock(leaderIsrUpdateLock) {
+    inReadLock(futureLogLock) {
       logManager.truncateTo(Map(topicPartition -> offset), isFuture = isFuture)
     }
   }
@@ -1142,7 +1149,7 @@ class Partition(val topicPartition: TopicPartition,
   def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {
     // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread
     // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.
-    inReadLock(leaderIsrUpdateLock) {
+    inReadLock(futureLogLock) {
       logManager.truncateFullyAndStartAt(topicPartition, newOffset, isFuture = isFuture)
     }
   }
