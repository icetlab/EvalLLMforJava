My overall improvement strategy focuses on reducing object allocations and unnecessary computations in frequently called methods within the `PartitionStates` and `AbstractFetcherThread` classes.

1.  In `PartitionStates.java`, the `update` method, which is central to re-grouping partitions by topic, is optimized. The original implementation iterated through the input map's keys to build a grouping structure and then performed lookups on the original map to retrieve state values. The improved version iterates over the map's entry set, storing the entries directly. This avoids repeated map lookups, making the process more efficient, especially for a large number of partitions.

2.  In `AbstractFetcherThread.scala`, two methods, `updateFetchOffsetAndMaybeMarkTruncationComplete` and `partitionsAndOffsets`, were identified as creating unnecessary intermediate collections. They both used `partitionStates.partitionStates()`, which allocates a new `List` and populates it with new `PartitionState` wrapper objects on each call. The change replaces this with `partitionStates.partitionStateMap().entrySet()`, which provides a lightweight view of the underlying map's entries. This change significantly reduces object churn and improves performance by avoiding the creation of these temporary collections and objects.

These changes collectively enhance performance by minimizing object allocation and streamlining data processing loops, without altering the existing logic or functionality.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java",
    "search": "    private void update(Map<TopicPartition, S> partitionToState) {\n        LinkedHashMap<String, List<TopicPartition>> topicToPartitions = new LinkedHashMap<>();\n        for (TopicPartition tp : partitionToState.keySet()) {\n            List<TopicPartition> partitions = topicToPartitions.computeIfAbsent(tp.topic(), k -> new ArrayList<>());\n            partitions.add(tp);\n        }\n        for (Map.Entry<String, List<TopicPartition>> entry : topicToPartitions.entrySet()) {\n            for (TopicPartition tp : entry.getValue()) {\n                S state = partitionToState.get(tp);\n                map.put(tp, state);\n            }\n        }\n    }",
    "replace": "    private void update(Map<TopicPartition, S> partitionToState) {\n        LinkedHashMap<String, List<Map.Entry<TopicPartition, S>>> topicToPartitionEntries = new LinkedHashMap<>();\n        for (Map.Entry<TopicPartition, S> entry : partitionToState.entrySet()) {\n            topicToPartitionEntries.computeIfAbsent(entry.getKey().topic(), k -> new ArrayList<>()).add(entry);\n        }\n        for (List<Map.Entry<TopicPartition, S>> entries : topicToPartitionEntries.values()) {\n            for (Map.Entry<TopicPartition, S> entry : entries) {\n                map.put(entry.getKey(), entry.getValue());\n            }\n        }\n    }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {\n    val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStates.asScala\n      .map { state =>\n        val currentFetchState = state.value\n        val maybeTruncationComplete = fetchOffsets.get(state.topicPartition) match {\n          case Some(offsetTruncationState) =>\n            val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n            PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n              currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n          case None => currentFetchState\n        }\n        (state.topicPartition, maybeTruncationComplete)\n      }.toMap\n    partitionStates.set(newStates.asJava)\n  }",
    "replace": "  private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {\n    val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStateMap.entrySet.asScala\n      .map { entry =>\n        val tp = entry.getKey\n        val currentFetchState = entry.getValue\n        val maybeTruncationComplete = fetchOffsets.get(tp) match {\n          case Some(offsetTruncationState) =>\n            val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n            PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n              currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n          case None => currentFetchState\n        }\n        (tp, maybeTruncationComplete)\n      }.toMap\n    partitionStates.set(newStates.asJava)\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {\n    partitionStates.partitionStates.asScala.map { state =>\n      val initialFetchState = InitialFetchState(sourceBroker,\n        currentLeaderEpoch = state.value.currentLeaderEpoch,\n        initOffset = state.value.fetchOffset)\n      state.topicPartition -> initialFetchState\n    }.toMap\n  }",
    "replace": "  private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {\n    partitionStates.partitionStateMap.entrySet.asScala.map { entry =>\n      val tp = entry.getKey\n      val state = entry.getValue\n      val initialFetchState = InitialFetchState(sourceBroker,\n        currentLeaderEpoch = state.currentLeaderEpoch,\n        initOffset = state.fetchOffset)\n      tp -> initialFetchState\n    }.toMap\n  }"
  }
]
```