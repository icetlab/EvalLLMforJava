My proposed improvements focus on reducing object allocations and unnecessary computations within `AbstractFetcherThread` and `PartitionStates`.

In `AbstractFetcherThread`, I've identified two methods, `updateFetchOffsetAndMaybeMarkTruncationComplete` and `partitionsAndOffsets`, that were inefficiently creating intermediate lists and wrapper objects (`PartitionState`) when they only needed to iterate over the existing partition states. By changing them to use `partitionStateMap`, which provides direct access to the underlying map, we can avoid these expensive allocations.

In `PartitionStates`, the `update` method, which is called to re-group partitions by topic, has been optimized. The original implementation iterated over the keys of the input map and then performed a lookup for each key to get its value. The improved version iterates over the map's entry set once, which is more efficient as it avoids repeated lookups.

These changes will improve performance by reducing garbage collection pressure and CPU cycles, especially in scenarios with a large number of partitions.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java",
    "search": "private void update(Map<TopicPartition, S> partitionToState) {\n    LinkedHashMap<String, List<TopicPartition>> topicToPartitions = new LinkedHashMap<>();\n    for (TopicPartition tp : partitionToState.keySet()) {\n        List<TopicPartition> partitions = topicToPartitions.computeIfAbsent(tp.topic(), k -> new ArrayList<>());\n        partitions.add(tp);\n    }\n    for (Map.Entry<String, List<TopicPartition>> entry : topicToPartitions.entrySet()) {\n        for (TopicPartition tp : entry.getValue()) {\n            S state = partitionToState.get(tp);\n            map.put(tp, state);\n        }\n    }\n}",
    "replace": "private void update(Map<TopicPartition, S> partitionToState) {\n    LinkedHashMap<String, List<Map.Entry<TopicPartition, S>>> topicToEntries = new LinkedHashMap<>();\n    for (Map.Entry<TopicPartition, S> entry : partitionToState.entrySet()) {\n        topicToEntries.computeIfAbsent(entry.getKey().topic(), k -> new ArrayList<>()).add(entry);\n    }\n    for (List<Map.Entry<TopicPartition, S>> entries : topicToEntries.values()) {\n        for (Map.Entry<TopicPartition, S> entry : entries) {\n            map.put(entry.getKey(), entry.getValue());\n        }\n    }\n}"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStates.asScala\n    .map { state =>\n      val currentFetchState = state.value\n      val maybeTruncationComplete = fetchOffsets.get(state.topicPartition) match {\n        case Some(offsetTruncationState) =>\n          val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n          PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n            currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n        case None => currentFetchState\n      }\n      (state.topicPartition, maybeTruncationComplete)\n    }.toMap",
    "replace": "  val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStateMap.asScala\n    .map { case (tp, currentFetchState) =>\n      val maybeTruncationComplete = fetchOffsets.get(tp) match {\n        case Some(offsetTruncationState) =>\n          val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n          PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n            currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n        case None => currentFetchState\n      }\n      (tp, maybeTruncationComplete)\n    }.toMap"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  partitionStates.partitionStates.asScala.map { state =>\n    val initialFetchState = InitialFetchState(sourceBroker,\n      currentLeaderEpoch = state.value.currentLeaderEpoch,\n      initOffset = state.value.fetchOffset)\n    state.topicPartition -> initialFetchState\n  }.toMap",
    "replace": "  partitionStates.partitionStateMap.asScala.map { case (tp, state) =>\n    val initialFetchState = InitialFetchState(sourceBroker,\n      currentLeaderEpoch = state.currentLeaderEpoch,\n      initOffset = state.fetchOffset)\n    tp -> initialFetchState\n  }.toMap"
  }
]
```