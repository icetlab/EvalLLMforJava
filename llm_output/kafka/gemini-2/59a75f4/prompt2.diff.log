The previous changes failed because they removed methods and classes from `PartitionStates.java` that are used by other parts of the codebase (specifically `SubscriptionState.java`), leading to compilation errors.

To fix this, I am reverting the changes to `PartitionStates.java` entirely. Instead, I am applying localized optimizations within `AbstractFetcherThread.scala` to improve performance without introducing breaking changes. The optimizations are:

1.  **Efficient State Updates**: In `updateFetchOffsetAndMaybeMarkTruncationComplete`, instead of creating a new map of all partition states and replacing the old one, I now iterate only over the partitions that need updates. This avoids iterating over the entire collection and is much more efficient when only a few partitions are being modified.

2.  **Direct Map Usage**: In `partitionsAndOffsets`, I'm now using `partitionStateMap` to directly access the underlying map data. This avoids the `partitionStates()` method, which creates a new list of wrapper objects (`PartitionState`) on each call, thereby reducing object allocation and improving performance.

These changes achieve the desired performance improvements in the replica fetcher logic while ensuring that the `PartitionStates` class remains compatible with all its usages across the codebase, thus resolving the build failure.

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {\n    val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStates.asScala\n      .map { state =>\n        val currentFetchState = state.value\n        val maybeTruncationComplete = fetchOffsets.get(state.topicPartition) match {\n          case Some(offsetTruncationState) =>\n            val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n            PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n              currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n          case None => currentFetchState\n        }\n        (state.topicPartition, maybeTruncationComplete)\n      }.toMap\n    partitionStates.set(newStates.asJava)\n  }",
    "replace": "  private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {\n    fetchOffsets.foreach { case (tp, offsetTruncationState) =>\n      val currentFetchState = partitionStates.stateValue(tp)\n      if (currentFetchState != null) {\n        val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating\n        val newFetchState = PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,\n          currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)\n        partitionStates.updateAndMoveToEnd(tp, newFetchState)\n      }\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/server/AbstractFetcherThread.scala",
    "search": "  private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {\n    partitionStates.partitionStates.asScala.map { state =>\n      val initialFetchState = InitialFetchState(sourceBroker,\n        currentLeaderEpoch = state.value.currentLeaderEpoch,\n        initOffset = state.value.fetchOffset)\n      state.topicPartition -> initialFetchState\n    }.toMap\n  }",
    "replace": "  private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {\n    partitionStates.partitionStateMap.asScala.map { case (tp, state) =>\n      val initialFetchState = InitialFetchState(sourceBroker,\n        currentLeaderEpoch = state.currentLeaderEpoch,\n        initOffset = state.fetchOffset)\n      tp -> initialFetchState\n    }.toMap\n  }"
  }
]
```