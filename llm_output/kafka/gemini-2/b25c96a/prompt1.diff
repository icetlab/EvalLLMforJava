diff --git a/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java b/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java
index 6bcafd2d60..51b1438692 100644
--- a/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java
+++ b/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java
@@ -233,39 +233,35 @@ public class ProducerStateManager {
      * largest stray snapshot file which was emitted during clean shutdown.
      */
     public void removeStraySnapshots(Collection<Long> segmentBaseOffsets) throws IOException {
-        OptionalLong maxSegmentBaseOffset = segmentBaseOffsets.isEmpty() ? OptionalLong.empty() : OptionalLong.of(segmentBaseOffsets.stream().max(Long::compare).get());
+        OptionalLong maxSegmentBaseOffset = segmentBaseOffsets.stream().mapToLong(Long::longValue).max();
 
         HashSet<Long> baseOffsets = new HashSet<>(segmentBaseOffsets);
-        Optional<SnapshotFile> latestStraySnapshot = Optional.empty();
-
         ConcurrentSkipListMap<Long, SnapshotFile> snapshots = loadSnapshots();
-        for (SnapshotFile snapshot : snapshots.values()) {
-            long key = snapshot.offset;
-            if (latestStraySnapshot.isPresent()) {
-                SnapshotFile prev = latestStraySnapshot.get();
-                if (!baseOffsets.contains(key)) {
-                    // this snapshot is now the largest stray snapshot.
-                    prev.deleteIfExists();
-                    snapshots.remove(prev.offset);
-                    latestStraySnapshot = Optional.of(snapshot);
-                }
-            } else {
-                if (!baseOffsets.contains(key)) {
-                    latestStraySnapshot = Optional.of(snapshot);
+
+        List<SnapshotFile> straySnapshots = snapshots.values().stream()
+            .filter(snapshot -> !baseOffsets.contains(snapshot.offset))
+            .collect(Collectors.toList());
+
+        if (straySnapshots.isEmpty()) {
+            this.snapshots = snapshots;
+            return;
         }
+
+        // The last one is the latest because snapshots.values() is sorted
+        SnapshotFile latestStray = straySnapshots.get(straySnapshots.size() - 1);
+
+        // All stray snapshots except the latest one are to be deleted.
+        for (int i = 0; i < straySnapshots.size() - 1; i++) {
+            SnapshotFile toDelete = straySnapshots.get(i);
+            if (snapshots.remove(toDelete.offset) != null) {
+                toDelete.deleteIfExists();
             }
         }
 
-        // Check to see if the latestStraySnapshot is larger than the largest segment base offset, if it is not,
-        // delete the largestStraySnapshot.
-        if (latestStraySnapshot.isPresent() && maxSegmentBaseOffset.isPresent()) {
-            long strayOffset = latestStraySnapshot.get().offset;
-            long maxOffset = maxSegmentBaseOffset.getAsLong();
-            if (strayOffset < maxOffset) {
-                SnapshotFile removedSnapshot = snapshots.remove(strayOffset);
-                if (removedSnapshot != null) {
-                    removedSnapshot.deleteIfExists();
-                }
+        // Now decide about the latest one.
+        if (maxSegmentBaseOffset.isPresent() && latestStray.offset < maxSegmentBaseOffset.getAsLong()) {
+            if (snapshots.remove(latestStray.offset) != null) {
+                latestStray.deleteIfExists();
             }
         }
 
@@ -369,17 +365,12 @@ public class ProducerStateManager {
      * Also expire any verification state entries that are lingering as unverified.
      */
     public void removeExpiredProducers(long currentTimeMs) {
-        List<Long> keys = producers.entrySet().stream()
-                .filter(entry -> isProducerExpired(currentTimeMs, entry.getValue()))
-                .map(Map.Entry::getKey)
-                .collect(Collectors.toList());
-        removeProducerIds(keys);
+        if (producers.entrySet().removeIf(entry -> isProducerExpired(currentTimeMs, entry.getValue()))) {
+            producerIdCount = producers.size();
+        }
 
-        List<Long> verificationKeys = verificationStates.entrySet().stream()
-                .filter(entry -> currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs())
-                .map(Map.Entry::getKey)
-                .collect(Collectors.toList());
-        verificationKeys.forEach(verificationStates::remove);
+        verificationStates.entrySet().removeIf(entry ->
+            currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs());
     }
 
     /**
@@ -392,9 +383,13 @@ public class ProducerStateManager {
      */
     public void truncateAndReload(long logStartOffset, long logEndOffset, long currentTimeMs) throws IOException {
         // remove all out of range snapshots
-        for (SnapshotFile snapshot : snapshots.values()) {
-            if (snapshot.offset > logEndOffset || snapshot.offset <= logStartOffset) {
-                removeAndDeleteSnapshot(snapshot.offset);
+        Iterator<Map.Entry<Long, SnapshotFile>> iterator = snapshots.entrySet().iterator();
+        while (iterator.hasNext()) {
+            Map.Entry<Long, SnapshotFile> entry = iterator.next();
+            long offset = entry.getKey();
+            if (offset > logEndOffset || offset <= logStartOffset) {
+                iterator.remove();
+                entry.getValue().deleteIfExists();
             }
         }
 
