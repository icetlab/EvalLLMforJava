My optimization strategy for `ByteBufUtil.java` focuses on the `decodeString` method, which is the target of the provided benchmark. The improvements are two-fold:

1.  **Heap Buffer Fast-Path**: I've introduced a fast-path for heap-backed `ByteBuf` instances. By checking `src.hasArray()`, we can directly use the underlying `byte[]` with the `new String(byte[], int, int, Charset)` constructor. This is significantly more efficient than the generic path involving `CharsetDecoder` and intermediate `CharBuffer` allocations, as it leverages highly optimized JDK internals. This will boost performance for the `HEAP` and `HEAP_OFFSET` buffer types in the benchmark.

2.  **Composite Buffer Decoding without Copying**: The original implementation for composite buffers involved creating a temporary heap buffer and copying all data into it before decoding. This memory allocation and data copy is a major performance bottleneck, especially for large buffers. My change eliminates this by iterating through the composite buffer's underlying `ByteBuffer` components and feeding them directly to the `CharsetDecoder`. This avoids the expensive copy operation, greatly improving performance for the `COMPOSITE` buffer type.

These changes preserve the original functionality, including character decoding behavior, while providing substantial performance gains for the scenarios covered by the benchmark.

```json
[
  {
    "filepath": "../netty/buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
    "search": "        if (len == 0) {\n            return StringUtil.EMPTY_STRING;\n        }\n        final CharsetDecoder decoder = CharsetUtil.decoder(charset);",
    "replace": "        if (len == 0) {\n            return StringUtil.EMPTY_STRING;\n        }\n        if (src.hasArray()) {\n            return new String(src.array(), src.arrayOffset() + readerIndex, len, charset);\n        }\n        final CharsetDecoder decoder = CharsetUtil.decoder(charset);"
  },
  {
    "filepath": "../netty/buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
    "search": "        } else {\n            // We use a heap buffer as CharsetDecoder is most likely able to use a fast-path if src and dst buffers\n            // are both backed by a byte array.\n            ByteBuf buffer = src.alloc().heapBuffer(len);\n            try {\n                buffer.writeBytes(src, readerIndex, len);\n                // Use internalNioBuffer(...) to reduce object creation.\n                decodeString(decoder, buffer.internalNioBuffer(buffer.readerIndex(), len), dst);\n            } finally {\n                // Release the temporary buffer again.\n                buffer.release();\n            }\n        }",
    "replace": "        } else {\n            ByteBuffer[] nioBuffers = src.nioBuffers(readerIndex, len);\n            try {\n                for (int i = 0; i < nioBuffers.length; i++) {\n                    final ByteBuffer bb = nioBuffers[i];\n                    final boolean endOfInput = i == nioBuffers.length - 1;\n                    CoderResult cr = decoder.decode(bb, dst, endOfInput);\n                    if (!cr.isUnderflow()) {\n                        cr.throwException();\n                    }\n                }\n                CoderResult cr = decoder.flush(dst);\n                if (!cr.isUnderflow()) {\n                    cr.throwException();\n                }\n            } catch (CharacterCodingException x) {\n                throw new IllegalStateException(x);\n            }\n        }"
  }
]
```