The current implementation of `ByteBufUtil.decodeString` involves complex logic with `CharsetDecoder`, thread-local `CharBuffer`s, and special handling for composite buffers that includes allocating a temporary `ByteBuf` and copying data. This leads to unnecessary object allocations and memory copies, degrading performance.

My improvement simplifies this method significantly by leveraging the highly optimized `new String(byte[], ...)` constructor.

1.  A fast path is introduced for heap-backed `ByteBuf`s. If the buffer has a backing array (`hasArray()` is true), a new `String` is created directly from this array without any intermediate copying. This is a zero-copy optimization for heap buffers.
2.  For other buffer types, such as direct or composite buffers, the new implementation copies the buffer's content into a temporary `byte[]` and then creates a `String` from it. This approach replaces the convoluted `CharsetDecoder` path, reducing object churn (no intermediate `ByteBuf`, `ByteBuffer`, `CharBuffer`) and relying on the JVM's optimized string creation, which is generally faster.

This change not only improves performance by reducing memory copies and object allocations but also makes the code much simpler and easier to maintain. The now-unused private helper method `decodeString(CharsetDecoder, ...)` is also removed.

```json
[
  {
    "filepath": "../netty/buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
    "search": "    static String decodeString(ByteBuf src, int readerIndex, int len, Charset charset) {\n        if (len == 0) {\n            return StringUtil.EMPTY_STRING;\n        }\n        final CharsetDecoder decoder = CharsetUtil.decoder(charset);\n        final int maxLength = (int) ((double) len * decoder.maxCharsPerByte());\n        CharBuffer dst = CHAR_BUFFERS.get();\n        if (dst.length() < maxLength) {\n            dst = CharBuffer.allocate(maxLength);\n            if (maxLength <= MAX_CHAR_BUFFER_SIZE) {\n                CHAR_BUFFERS.set(dst);\n            }\n        } else {\n            dst.clear();\n        }\n        if (src.nioBufferCount() == 1) {\n            decodeString(decoder, src.nioBuffer(readerIndex, len), dst);\n        } else {\n            // We use a heap buffer as CharsetDecoder is most likely able to use a fast-path if src and dst buffers\n            // are both backed by a byte array.\n            ByteBuf buffer = src.alloc().heapBuffer(len);\n            try {\n                buffer.writeBytes(src, readerIndex, len);\n                // Use internalNioBuffer(...) to reduce object creation.\n                decodeString(decoder, buffer.internalNioBuffer(buffer.readerIndex(), len), dst);\n            } finally {\n                // Release the temporary buffer again.\n                buffer.release();\n            }\n        }\n        return dst.flip().toString();\n    }\n\n    private static void decodeString(CharsetDecoder decoder, ByteBuffer src, CharBuffer dst) {\n        try {\n            CoderResult cr = decoder.decode(src, dst, true);\n            if (!cr.isUnderflow()) {\n                cr.throwException();\n            }\n            cr = decoder.flush(dst);\n            if (!cr.isUnderflow()) {\n                cr.throwException();\n            }\n        } catch (CharacterCodingException x) {\n            throw new IllegalStateException(x);\n        }\n    }",
    "replace": "    static String decodeString(ByteBuf src, int readerIndex, int len, Charset charset) {\n        if (len == 0) {\n            return StringUtil.EMPTY_STRING;\n        }\n        if (src.hasArray()) {\n            return new String(src.array(), src.arrayOffset() + readerIndex, len, charset);\n        }\n\n        final byte[] array = new byte[len];\n        src.getBytes(readerIndex, array, 0, len);\n        return new String(array, 0, len, charset);\n    }"
  }
]
```