The primary goal of these changes is to improve performance by reducing object allocations and optimizing hot loops.

In `PagesSerde`, `ByteBuffer`s used for compression and decompression are now cached and reused across `serialize` and `deserialize` calls. This avoids repeated allocations and reduces garbage collection pressure, which is beneficial when processing many pages.

In `PartitionedOutputOperator`, I've made two optimizations within the `PagePartitioner` inner class:
1.  The `partitionPage` method now has a fast path to handle a common case where an entire page needs to be replicated. When the replication is determined by a `nullChannel` containing a `RunLengthEncodedBlock` of nulls, the method can now replicate all rows in a batch without expensive per-row checks. For the general case, a block lookup has been hoisted out of the main loop.
2.  In the `flush` method, the creation of `SerializedPage` objects, which previously used a stream, has been converted to a more direct `for` loop with a pre-sized `ImmutableList.Builder`. This micro-optimization reduces the overhead associated with streams, especially when dealing with a small number of pages after splitting.

These changes are designed to enhance throughput and reduce CPU and memory overhead during partitioned output operations.

```json
[
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "    private final Optional<Compressor> compressor;\n    private final Optional<Decompressor> decompressor;\n    private final Optional<SpillCipher> spillCipher;",
    "replace": "    private final Optional<Compressor> compressor;\n    private final Optional<Decompressor> decompressor;\n    private final Optional<SpillCipher> spillCipher;\n\n    private ByteBuffer compressionBuffer;\n    private ByteBuffer decompressionBuffer;"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "        if (compressor.isPresent()) {\n            ByteBuffer compressionBuffer = ByteBuffer.allocate(compressor.get().maxCompressedLength(uncompressedSize));\n            compressor.get().compress(slice.toByteBuffer(), compressionBuffer);\n            compressionBuffer.flip();\n            if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n                slice = Slices.wrappedBuffer(compressionBuffer);\n                markers = COMPRESSED.set(markers);\n            }\n        }",
    "replace": "        if (compressor.isPresent()) {\n            int maxCompressedLength = compressor.get().maxCompressedLength(uncompressedSize);\n            if (compressionBuffer == null || compressionBuffer.capacity() < maxCompressedLength) {\n                compressionBuffer = ByteBuffer.allocate(maxCompressedLength);\n            }\n            else {\n                compressionBuffer.clear();\n            }\n            compressor.get().compress(slice.toByteBuffer(), compressionBuffer);\n            compressionBuffer.flip();\n            if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n                slice = Slices.wrappedBuffer(compressionBuffer);\n                markers = COMPRESSED.set(markers);\n            }\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "        if (COMPRESSED.isSet(serializedPage.getPageCodecMarkers())) {\n            checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n\n            int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n            ByteBuffer decompressionBuffer = ByteBuffer.allocate(uncompressedSize);\n\n            decompressor.get().decompress(slice.toByteBuffer(), decompressionBuffer);\n            decompressionBuffer.flip();\n            checkState(decompressionBuffer.remaining() == uncompressedSize);\n\n            slice = Slices.wrappedBuffer(decompressionBuffer);\n        }",
    "replace": "        if (COMPRESSED.isSet(serializedPage.getPageCodecMarkers())) {\n            checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n\n            int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n            if (decompressionBuffer == null || decompressionBuffer.capacity() < uncompressedSize) {\n                decompressionBuffer = ByteBuffer.allocate(uncompressedSize);\n            }\n            else {\n                decompressionBuffer.clear();\n            }\n\n            decompressor.get().decompress(slice.toByteBuffer(), decompressionBuffer);\n            decompressionBuffer.flip();\n            checkState(decompressionBuffer.remaining() == uncompressedSize);\n\n            slice = Slices.wrappedBuffer(decompressionBuffer);\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/PartitionedOutputOperator.java",
    "search": "        public void partitionPage(Page page)\n        {\n            requireNonNull(page, \"page is null\");\n\n            Page partitionFunctionArgs = getPartitionFunctionArguments(page);\n            for (int position = 0; position < page.getPositionCount(); position++) {\n                boolean shouldReplicate = (replicatesAnyRow && !hasAnyRowBeenReplicated) ||\n                        nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n                if (shouldReplicate) {\n                    for (PageBuilder pageBuilder : pageBuilders) {\n                        appendRow(pageBuilder, page, position);\n                    }\n                    hasAnyRowBeenReplicated = true;\n                }\n                else {\n                    int partition = partitionFunction.getPartition(partitionFunctionArgs, position);\n                    appendRow(pageBuilders[partition], page, position);\n                }\n            }\n            flush(false);\n        }",
    "replace": "        public void partitionPage(Page page)\n        {\n            requireNonNull(page, \"page is null\");\n\n            Block nullBlock = null;\n            if (nullChannel.isPresent()) {\n                nullBlock = page.getBlock(nullChannel.getAsInt());\n                if (nullBlock instanceof RunLengthEncodedBlock && nullBlock.isNull(0)) {\n                    // RLE nulls, so replicate all rows to all partitions\n                    for (int position = 0; position < page.getPositionCount(); position++) {\n                        for (PageBuilder pageBuilder : pageBuilders) {\n                            appendRow(pageBuilder, page, position);\n                        }\n                    }\n                    if (page.getPositionCount() > 0) {\n                        hasAnyRowBeenReplicated = true;\n                    }\n                    flush(false);\n                    return;\n                }\n            }\n\n            Page partitionFunctionArgs = getPartitionFunctionArguments(page);\n            for (int position = 0; position < page.getPositionCount(); position++) {\n                boolean shouldReplicate = (replicatesAnyRow && !hasAnyRowBeenReplicated) ||\n                        (nullBlock != null && nullBlock.isNull(position));\n                if (shouldReplicate) {\n                    for (PageBuilder pageBuilder : pageBuilders) {\n                        appendRow(pageBuilder, page, position);\n                    }\n                    hasAnyRowBeenReplicated = true;\n                }\n                else {\n                    int partition = partitionFunction.getPartition(partitionFunctionArgs, position);\n                    appendRow(pageBuilders[partition], page, position);\n                }\n            }\n            flush(false);\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/PartitionedOutputOperator.java",
    "search": "                    List<SerializedPage> serializedPages = splitPage(pagePartition, DEFAULT_MAX_PAGE_SIZE_IN_BYTES).stream()\n                            .map(serde::serialize)\n                            .collect(toImmutableList());\n\n                    outputBuffer.enqueue(operatorContext.getDriverContext().getLifespan(), partition, serializedPages);",
    "replace": "                    List<Page> pages = splitPage(pagePartition, DEFAULT_MAX_PAGE_SIZE_IN_BYTES);\n                    com.google.common.collect.ImmutableList.Builder<SerializedPage> serializedPages = com.google.common.collect.ImmutableList.builderWithExpectedSize(pages.size());\n                    for (Page p : pages) {\n                        serializedPages.add(serde.serialize(p));\n                    }\n\n                    outputBuffer.enqueue(operatorContext.getDriverContext().getLifespan(), partition, serializedPages.build());"
  }
]
```