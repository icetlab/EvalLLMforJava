diff --git a/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java b/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java
index ce0ca747f2..45a905ae90 100644
--- a/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java
+++ b/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java
@@ -120,6 +120,9 @@ public class TDigest
     private final double[] tempWeight;
     private final double[] tempMean;
 
+    // array for holding cumulative weights of centroids. Used for faster quantile queries.
+    private final double[] cumulative;
+
     // array used for sorting the temp centroids
     // to avoid allocations during operation
     private final int[] order;
@@ -147,6 +150,7 @@ public class TDigest
         tempWeight = new double[bufferSize];
         tempMean = new double[bufferSize];
         order = new int[bufferSize];
+        cumulative = new double[size];
 
         activeCentroids = 0;
     }
@@ -177,6 +181,7 @@ public class TDigest
             r.activeCentroids = sliceInput.readInt();
             sliceInput.readBytes(wrappedDoubleArray(r.weight), r.activeCentroids * SIZE_OF_DOUBLE);
             sliceInput.readBytes(wrappedDoubleArray(r.mean), r.activeCentroids * SIZE_OF_DOUBLE);
+            r.updateCumulative();
             sliceInput.close();
             return r;
         }
@@ -215,10 +220,7 @@ public class TDigest
         checkArgument(other != null, "Cannot merge with a null t-digest");
         checkArgument(this.publicCompression == other.getCompressionFactor(), "TDigests must have the same compression, found (%s, %s)", this.publicCompression,
                 other.getCompressionFactor());
-        List<Centroid> tmp = new ArrayList<>();
-        for (Centroid centroid : other.centroids()) {
-            tmp.add(centroid);
-        }
+                List<Centroid> tmp = new ArrayList<>(other.centroids());
 
         shuffle(tmp, gen);
         for (Centroid centroid : tmp) {
@@ -315,6 +317,8 @@ public class TDigest
             reverse(weight, 0, activeCentroids);
         }
 
+        updateCumulative();
+
         if (totalWeight > 0) {
             min = Math.min(min, mean[0]);
             max = max(max, mean[activeCentroids - 1]);
@@ -491,6 +495,17 @@ public class TDigest
             return max;
         }
 
+        // if the left centroid has more than one sample, we still know
+        // that one sample occurred at min so we can do some interpolation
+        if (weight[0] > 1 && index < weight[0] / 2) {
+            // there is a single sample at min so we interpolate with less weight
+            return min + (index - 1) / (weight[0] / 2 - 1) * (mean[0] - min);
+        }
+
+        if (index > totalWeight - 1) {
+            return max;
+        }
+
         // if the right-most centroid has more than one sample, we still know
         // that one sample occurred at max so we can do some interpolation
         if (weight[n - 1] > 1 && totalWeight - index <= weight[n - 1] / 2) {
@@ -498,8 +513,40 @@ public class TDigest
         }
 
         // in between extremes we interpolate between centroids
+        int i = -1;
+        if (n > 1) {
+            // find the first centroid whose cumulative weight is greater than index
+            int low = 0;
+            int high = n - 1;
+            while (low <= high) {
+                int mid = low + (high - low) / 2;
+                double midWeight = mid > 0 ? (cumulative[mid - 1] + weight[mid] / 2.0) : (weight[mid] / 2.0);
+                if (midWeight >= index) {
+                    high = mid - 1;
+                }
+                else {
+                    low = mid + 1;
+                }
+            }
+            i = low;
+
+            if (i >= n) {
+                i = n - 1;
+            }
+
+            // We are in the interval between i-1 and i.
+            // We need to handle the case of i=0 (first interval) separately.
+            if (i > 0) {
+                double weightSoFar = (cumulative[i - 1] - weight[i - 1] / 2.0) + (weight[i - 1] + weight[i]) / 2.0;
+                double z1 = index - (cumulative[i - 1] - weight[i - 1] / 2.0);
+                double z2 = weightSoFar - index;
+                return weightedAverage(mean[i - 1], z2, mean[i], z1);
+            }
+        }
+
+        // Fallback or special handling for first interval
         double weightSoFar = weight[0] / 2;
-        for (int i = 0; i < n - 1; i++) {
+        for (i = 0; i < n - 1; i++) {
             // centroids i and i + 1 bracket our current point
             double dw = (weight[i] + weight[i + 1]) / 2;
             if (weightSoFar + dw > index) {
@@ -610,7 +657,7 @@ public class TDigest
 
     public long estimatedInMemorySizeInBytes()
     {
-        return INSTANCE_SIZE + sizeOf(weight) + sizeOf(mean) + sizeOf(tempWeight) + sizeOf(tempMean) + sizeOf(order);
+        return INSTANCE_SIZE + sizeOf(weight) + sizeOf(mean) + sizeOf(tempWeight) + sizeOf(tempMean) + sizeOf(order) + sizeOf(cumulative);
     }
 
     public Slice serialize()
@@ -645,6 +692,16 @@ public class TDigest
         return max;
     }
 
+        private void updateCumulative()
+    {
+        if (activeCentroids > 0) {
+            cumulative[0] = weight[0];
+            for (int i = 1; i < activeCentroids; i++) {
+                cumulative[i] = cumulative[i - 1] + weight[i];
+            }
+        }
+    }
+
     public String toString()
     {
         return format("TDigest\nCompression:%s\nCentroid Count:%s\nSize:%s\nMin:%s Median:%s Max:%s",
