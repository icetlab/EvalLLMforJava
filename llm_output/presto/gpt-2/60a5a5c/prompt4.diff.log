Iâ€™ve introduced a reusable `compressionBuffer` field and updated the `serialize` method to reuse this buffer across calls, only reallocating when a larger capacity is needed. This eliminates per-page buffer allocations and improves serialization performance.

```json
[
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "private final Optional<SpillCipher> spillCipher;",
    "replace": "private final Optional<SpillCipher> spillCipher;\n    // Reusable buffer to avoid per-page allocation\n    private ByteBuffer compressionBuffer;"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "if (compressor.isPresent()) {\n            ByteBuffer compressionBuffer = ByteBuffer.allocate(compressor.get().maxCompressedLength(uncompressedSize));\n            compressor.get().compress(slice.toByteBuffer(), compressionBuffer);\n            compressionBuffer.flip();\n            if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n                slice = Slices.wrappedBuffer(compressionBuffer);\n                markers = COMPRESSED.set(markers);\n            }\n        }",
    "replace": "if (compressor.isPresent()) {\n            int maxLength = compressor.get().maxCompressedLength(uncompressedSize);\n            if (compressionBuffer == null || compressionBuffer.capacity() < maxLength) {\n                compressionBuffer = ByteBuffer.allocate(maxLength);\n            } else {\n                compressionBuffer.clear();\n            }\n            compressor.get().compress(slice.toByteBuffer(), compressionBuffer);\n            compressionBuffer.flip();\n            if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n                slice = Slices.wrappedBuffer(compressionBuffer);\n                markers = COMPRESSED.set(markers);\n            }\n        }"
  }
]
```