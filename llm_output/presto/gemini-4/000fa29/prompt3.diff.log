My improvement strategy focuses on optimizing the row-by-row processing within the `OptimizedPartitionedOutputOperator`. The primary bottleneck is the repeated calculation of serialized row sizes for each partition buffer. In the original implementation, for every non-empty partition, the operator would iterate through the rows assigned to that partition and compute their serialized sizes. This is inefficient, especially with a high number of partitions, as the size of a given row is calculated multiple times if it's processed by different partitions (which it isn't, but the calculation logic is invoked per partition).

My change centralizes this size calculation. I've introduced a new private method, `getPageSerializedRowSizes`, within the `PagePartitioner`. This method is called once per input page to calculate the serialized size of every row in that page. The resulting array of sizes is then passed down to each `PartitionBuffer`.

Consequently, the `PartitionBuffer` is simplified. It no longer needs to compute row sizes. Instead, when determining the next batch of rows to flush, it directly looks up the pre-computed sizes from the array passed by the `PagePartitioner`. This avoids redundant computations, leading to a significant performance improvement, particularly when dealing with many partitions or complex data types with variable widths.

Here are the changes:

```json
[
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/repartition/OptimizedPartitionedOutputOperator.java",
    "search": "public void partitionPage(Page page)\n        {\n            // Populate positions to copy for each destination partition.\n            int positionCount = page.getPositionCount();\n\n            for (int i = 0; i < partitionBuffers.length; i++) {\n                partitionBuffers[i].resetPositions(positionCount);\n            }\n\n            Block nullBlock = nullChannel.isPresent() ? page.getBlock(nullChannel.getAsInt()) : null;\n            Page partitionFunctionArgs = getPartitionFunctionArguments(page);\n\n            for (int position = 0; position < positionCount; position++) {\n                boolean shouldReplicate = (replicatesAnyRow && !hasAnyRowBeenReplicated) ||\n                        nullBlock != null && nullBlock.isNull(position);\n\n                if (shouldReplicate) {\n                    for (int i = 0; i < partitionBuffers.length; i++) {\n                        partitionBuffers[i].addPosition(position);\n                    }\n                    hasAnyRowBeenReplicated = true;\n                }\n                else {\n                    int partition = partitionFunction.getPartition(partitionFunctionArgs, position);\n                    partitionBuffers[partition].addPosition(position);\n                }\n            }\n\n            // Decode the page just once. The decoded blocks will be fed to each PartitionBuffer object to set up AbstractBlockEncodingBuffer.\n            for (int i = 0; i < decodedBlocks.length; i++) {\n                decodedBlocks[i] = decodeBlock(flattener, blockLeaseCloser, page.getBlock(i));\n            }\n\n            // Copy the data to their destination partitions and flush when the buffer is full.\n            for (int i = 0; i < partitionBuffers.length; i++) {\n                partitionBuffers[i].appendData(decodedBlocks, fixedWidthRowSize, variableWidthChannels, outputBuffer);\n            }\n\n            // Return all borrowed arrays\n            try {\n                blockLeaseCloser.close();\n            }\n            catch (IOException e) {\n                throw new UncheckedIOException(e);\n            }\n        }",
    "replace": "public void partitionPage(Page page)\n        {\n            // Populate positions to copy for each destination partition.\n            int positionCount = page.getPositionCount();\n\n            for (int i = 0; i < partitionBuffers.length; i++) {\n                partitionBuffers[i].resetPositions(positionCount);\n            }\n\n            Block nullBlock = nullChannel.isPresent() ? page.getBlock(nullChannel.getAsInt()) : null;\n            Page partitionFunctionArgs = getPartitionFunctionArguments(page);\n\n            for (int position = 0; position < positionCount; position++) {\n                boolean shouldReplicate = (replicatesAnyRow && !hasAnyRowBeenReplicated) ||\n                        nullBlock != null && nullBlock.isNull(position);\n\n                if (shouldReplicate) {\n                    for (int i = 0; i < partitionBuffers.length; i++) {\n                        partitionBuffers[i].addPosition(position);\n                    }\n                    hasAnyRowBeenReplicated = true;\n                }\n                else {\n                    int partition = partitionFunction.getPartition(partitionFunctionArgs, position);\n                    partitionBuffers[partition].addPosition(position);\n                }\n            }\n\n            // Decode the page just once. The decoded blocks will be fed to each PartitionBuffer object to set up AbstractBlockEncodingBuffer.\n            for (int i = 0; i < decodedBlocks.length; i++) {\n                decodedBlocks[i] = decodeBlock(flattener, blockLeaseCloser, page.getBlock(i));\n            }\n\n            // Calculate serialized row sizes for the whole page.\n            final int[] pageSerializedRowSizes = getPageSerializedRowSizes(page.getPositionCount(), decodedBlocks);\n\n            // Copy the data to their destination partitions and flush when the buffer is full.\n            for (int i = 0; i < partitionBuffers.length; i++) {\n                partitionBuffers[i].appendData(decodedBlocks, fixedWidthRowSize, variableWidthChannels, outputBuffer, pageSerializedRowSizes);\n            }\n\n            // Return all borrowed arrays\n            try {\n                blockLeaseCloser.close();\n            }\n            catch (IOException e) {\n                throw new UncheckedIOException(e);\n            }\n        }\n\n        private int[] getPageSerializedRowSizes(int positionCount, DecodedBlockNode[] decodedBlocks)\n        {\n            if (variableWidthChannels.isEmpty()) {\n                return null;\n            }\n\n            // Lazily create BlockEncodingBuffers for row size calculation.\n            // These buffers are temporary and are only used for size calculation.\n            // They do not hold any serialized data.\n            BlockEncodingBuffer[] rowSizeCalculationBuffers = new BlockEncodingBuffer[sourceTypes.size()];\n            for (int i = 0; i < sourceTypes.size(); i++) {\n                rowSizeCalculationBuffers[i] = createBlockEncodingBuffers(decodedBlocks[i]);\n            }\n\n            int[] allPositions = new int[positionCount];\n            for (int i = 0; i < positionCount; i++) {\n                allPositions[i] = i;\n            }\n\n            for (int i = 0; i < sourceTypes.size(); i++) {\n                rowSizeCalculationBuffers[i].setupDecodedBlocksAndPositions(decodedBlocks[i], allPositions, positionCount);\n            }\n\n            int[] pageSerializedRowSizes = new int[positionCount];\n\n            for (int channel : variableWidthChannels) {\n                rowSizeCalculationBuffers[channel].accumulateSerializedRowSizes(pageSerializedRowSizes);\n            }\n\n            for (int i = 0; i < positionCount; i++) {\n                pageSerializedRowSizes[i] += fixedWidthRowSize;\n            }\n            return pageSerializedRowSizes;\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/repartition/OptimizedPartitionedOutputOperator.java",
    "search": "        private int[] positions;   // the default positions array for top level BlockEncodingBuffer\n        private int[] serializedRowSizes;  // The sizes of the rows in bytes if they were serialized\n        private int positionCount;  // number of positions to be copied for this partition\n        private BlockEncodingBuffer[] blockEncodingBuffers;",
    "replace": "        private int[] positions;   // the default positions array for top level BlockEncodingBuffer\n        private int positionCount;  // number of positions to be copied for this partition\n        private BlockEncodingBuffer[] blockEncodingBuffers;"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/repartition/OptimizedPartitionedOutputOperator.java",
    "search": "        private void appendData(DecodedBlockNode[] decodedBlocks, int fixedWidthRowSize, List<Integer> variableWidthChannels, OutputBuffer outputBuffer)\n        {\n            if (decodedBlocks.length != channelCount) {\n                throw new IllegalArgumentException(format(\"Unexpected number of decoded blocks %d. It should be %d.\", decodedBlocks.length, channelCount));\n            }\n\n            if (positionCount == 0) {\n                return;\n            }\n\n            if (channelCount == 0) {\n                bufferedRowCount += positionCount;\n                return;\n            }\n\n            initializeBlockEncodingBuffers(decodedBlocks);\n\n            for (int i = 0; i < channelCount; i++) {\n                blockEncodingBuffers[i].setupDecodedBlocksAndPositions(decodedBlocks[i], positions, positionCount);\n            }\n\n            populateSerializedRowSizes(fixedWidthRowSize, variableWidthChannels);\n\n            // Due to the limitation of buffer size, we append the data batch by batch\n            int offset = 0;\n            do {\n                int batchSize = calculateNextBatchSize(fixedWidthRowSize, variableWidthChannels, offset);\n\n                for (int i = 0; i < channelCount; i++) {\n                    blockEncodingBuffers[i].setNextBatch(offset, batchSize);\n                    blockEncodingBuffers[i].appendDataInBatch();\n                }\n\n                bufferedRowCount += batchSize;\n                offset += batchSize;\n\n                if (bufferFull) {\n                    flush(outputBuffer);\n                    bufferFull = false;\n                }\n            }\n            while (offset < positionCount);\n        }",
    "replace": "        private void appendData(DecodedBlockNode[] decodedBlocks, int fixedWidthRowSize, List<Integer> variableWidthChannels, OutputBuffer outputBuffer, int[] pageSerializedRowSizes)\n        {\n            if (decodedBlocks.length != channelCount) {\n                throw new IllegalArgumentException(format(\"Unexpected number of decoded blocks %d. It should be %d.\", decodedBlocks.length, channelCount));\n            }\n\n            if (positionCount == 0) {\n                return;\n            }\n\n            if (channelCount == 0) {\n                bufferedRowCount += positionCount;\n                return;\n            }\n\n            initializeBlockEncodingBuffers(decodedBlocks);\n\n            for (int i = 0; i < channelCount; i++) {\n                blockEncodingBuffers[i].setupDecodedBlocksAndPositions(decodedBlocks[i], positions, positionCount);\n            }\n\n            // Due to the limitation of buffer size, we append the data batch by batch\n            int offset = 0;\n            do {\n                int batchSize = calculateNextBatchSize(fixedWidthRowSize, variableWidthChannels, offset, pageSerializedRowSizes);\n\n                for (int i = 0; i < channelCount; i++) {\n                    blockEncodingBuffers[i].setNextBatch(offset, batchSize);\n                    blockEncodingBuffers[i].appendDataInBatch();\n                }\n\n                bufferedRowCount += batchSize;\n                offset += batchSize;\n\n                if (bufferFull) {\n                    flush(outputBuffer);\n                    bufferFull = false;\n                }\n            }\n            while (offset < positionCount);\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/repartition/OptimizedPartitionedOutputOperator.java",
    "search": "        /**\n         * Calculate the row sizes in bytes and write them to serializedRowSizes.\n         */\n        private void populateSerializedRowSizes(int fixedWidthRowSize, List<Integer> variableWidthChannels)\n        {\n            if (variableWidthChannels.isEmpty()) {\n                return;\n            }\n\n            serializedRowSizes = ensureCapacity(serializedRowSizes, positionCount, SMALL, INITIALIZE);\n\n            for (int i : variableWidthChannels) {\n                blockEncodingBuffers[i].accumulateSerializedRowSizes(serializedRowSizes);\n            }\n\n            for (int i = 0; i < positionCount; i++) {\n                serializedRowSizes[i] += fixedWidthRowSize;\n            }\n        }\n\n        private int calculateNextBatchSize(int fixedWidthRowSize, List<Integer> variableWidthChannels, int startPosition)\n        {\n            int bytesRemaining = capacity - getSerializedBuffersSizeInBytes();\n\n            if (variableWidthChannels.isEmpty()) {\n                int maxPositionsFit = max(bytesRemaining / fixedWidthRowSize, 1);\n                if (maxPositionsFit <= positionCount - startPosition) {\n                    bufferFull = true;\n                    return maxPositionsFit;\n                }\n                return positionCount - startPosition;\n            }\n\n            verify(serializedRowSizes != null);\n            for (int i = startPosition; i < positionCount; i++) {\n                bytesRemaining -= serializedRowSizes[i];\n\n                if (bytesRemaining <= 0) {\n                    bufferFull = true;\n                    return max(i - startPosition, 1);\n                }\n            }\n\n            return positionCount - startPosition;\n        }",
    "replace": "        private int calculateNextBatchSize(int fixedWidthRowSize, List<Integer> variableWidthChannels, int startPosition, int[] pageSerializedRowSizes)\n        {\n            int bytesRemaining = capacity - getSerializedBuffersSizeInBytes();\n\n            if (variableWidthChannels.isEmpty()) {\n                int maxPositionsFit = max(bytesRemaining / fixedWidthRowSize, 1);\n                if (maxPositionsFit <= positionCount - startPosition) {\n                    bufferFull = true;\n                    return maxPositionsFit;\n                }\n                return positionCount - startPosition;\n            }\n\n            verify(pageSerializedRowSizes != null);\n            for (int i = startPosition; i < positionCount; i++) {\n                bytesRemaining -= pageSerializedRowSizes[positions[i]];\n\n                if (bytesRemaining <= 0) {\n                    bufferFull = true;\n                    return max(i - startPosition, 1);\n                }\n            }\n\n            return positionCount - startPosition;\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/operator/repartition/OptimizedPartitionedOutputOperator.java",
    "search": "        private long getRetainedSizeInBytes()\n        {\n            long size = INSTANCE_SIZE + sizeOf(positions) + sizeOf(serializedRowSizes);\n\n            // Some destination partitions might get 0 rows. In that case the BlockEncodingBuffer won't be created.\n            if (blockEncodingBuffers != null) {\n                for (int i = 0; i < channelCount; i++) {\n                    size += blockEncodingBuffers[i].getRetainedSizeInBytes();\n                }\n            }\n\n            return size;\n        }",
    "replace": "        private long getRetainedSizeInBytes()\n        {\n            long size = INSTANCE_SIZE + sizeOf(positions);\n\n            // Some destination partitions might get 0 rows. In that case the BlockEncodingBuffer won't be created.\n            if (blockEncodingBuffers != null) {\n                for (int i = 0; i < channelCount; i++) {\n                    size += blockEncodingBuffers[i].getRetainedSizeInBytes();\n                }\n            }\n\n            return size;\n        }"
  }
]
```