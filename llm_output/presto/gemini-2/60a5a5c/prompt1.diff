diff --git a/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java b/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java
index 74b77228f0..b45fd74c29 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java
@@ -47,6 +47,9 @@ public class PagesSerde
     private final Optional<Decompressor> decompressor;
     private final Optional<SpillCipher> spillCipher;
 
+    private ByteBuffer compressionBuffer;
+    private ByteBuffer decompressionBuffer;
+
     public PagesSerde(BlockEncodingSerde blockEncodingSerde, Optional<Compressor> compressor, Optional<Decompressor> decompressor, Optional<SpillCipher> spillCipher)
     {
         this.blockEncodingSerde = requireNonNull(blockEncodingSerde, "blockEncodingSerde is null");
@@ -66,7 +69,13 @@ public class PagesSerde
         byte markers = PageCodecMarker.none();
 
         if (compressor.isPresent()) {
-            ByteBuffer compressionBuffer = ByteBuffer.allocate(compressor.get().maxCompressedLength(uncompressedSize));
+            int maxCompressedLength = compressor.get().maxCompressedLength(uncompressedSize);
+            if (compressionBuffer == null || compressionBuffer.capacity() < maxCompressedLength) {
+                compressionBuffer = ByteBuffer.allocate(maxCompressedLength);
+            }
+            else {
+                compressionBuffer.clear();
+            }
             compressor.get().compress(slice.toByteBuffer(), compressionBuffer);
             compressionBuffer.flip();
             if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {
@@ -103,7 +112,13 @@ public class PagesSerde
             checkState(decompressor.isPresent(), "Page is compressed, but decompressor is missing");
 
             int uncompressedSize = serializedPage.getUncompressedSizeInBytes();
-            ByteBuffer decompressionBuffer = ByteBuffer.allocate(uncompressedSize);
+            if (decompressionBuffer == null || decompressionBuffer.capacity() < uncompressedSize) {
+                decompressionBuffer = ByteBuffer.allocate(uncompressedSize);
+            }
+            else {
+                decompressionBuffer.clear();
+            }
+            decompressionBuffer.limit(uncompressedSize);
 
             decompressor.get().decompress(slice.toByteBuffer(), decompressionBuffer);
             decompressionBuffer.flip();
diff --git a/presto-main/src/main/java/com/facebook/presto/operator/PartitionedOutputOperator.java b/presto-main/src/main/java/com/facebook/presto/operator/PartitionedOutputOperator.java
index d3b9621b8e..e3ad838dbf 100644
--- a/presto-main/src/main/java/com/facebook/presto/operator/PartitionedOutputOperator.java
+++ b/presto-main/src/main/java/com/facebook/presto/operator/PartitionedOutputOperator.java
@@ -31,6 +31,7 @@ import com.fasterxml.jackson.annotation.JsonProperty;
 import com.google.common.util.concurrent.ListenableFuture;
 import io.airlift.units.DataSize;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Optional;
 import java.util.OptionalInt;
@@ -306,6 +307,8 @@ public class PartitionedOutputOperator
         private final AtomicLong pagesAdded = new AtomicLong();
         private boolean hasAnyRowBeenReplicated;
         private final OperatorContext operatorContext;
+        private final Block[] rleBlocks;
+        private int rlePositionCount = -1;
 
         public PagePartitioner(
                 PartitionFunction partitionFunction,
@@ -339,6 +342,7 @@ public class PartitionedOutputOperator
             for (int i = 0; i < partitionCount; i++) {
                 pageBuilders[i] = PageBuilder.withMaxPageSize(pageSize, sourceTypes);
             }
+            this.rleBlocks = new Block[partitionChannels.size()];
         }
 
         public ListenableFuture<?> isFull()
@@ -399,10 +403,18 @@ public class PartitionedOutputOperator
         private Page getPartitionFunctionArguments(Page page)
         {
             Block[] blocks = new Block[partitionChannels.size()];
+            boolean newRleBlocksNeeded = page.getPositionCount() != rlePositionCount;
+            if (newRleBlocksNeeded) {
+                rlePositionCount = page.getPositionCount();
+            }
+
             for (int i = 0; i < blocks.length; i++) {
                 Optional<Block> partitionConstant = partitionConstants.get(i);
                 if (partitionConstant.isPresent()) {
-                    blocks[i] = new RunLengthEncodedBlock(partitionConstant.get(), page.getPositionCount());
+                    if (newRleBlocksNeeded) {
+                        rleBlocks[i] = new RunLengthEncodedBlock(partitionConstant.get(), page.getPositionCount());
+                    }
+                    blocks[i] = rleBlocks[i];
                 }
                 else {
                     blocks[i] = page.getBlock(partitionChannels.get(i));
@@ -432,10 +444,11 @@ public class PartitionedOutputOperator
 
                     operatorContext.recordOutput(pagePartition.getSizeInBytes(), pagePartition.getPositionCount());
 
-                    List<SerializedPage> serializedPages = splitPage(pagePartition, DEFAULT_MAX_PAGE_SIZE_IN_BYTES).stream()
-                            .map(serde::serialize)
-                            .collect(toImmutableList());
-
+                    List<Page> pages = splitPage(pagePartition, DEFAULT_MAX_PAGE_SIZE_IN_BYTES);
+                    List<SerializedPage> serializedPages = new ArrayList<>(pages.size());
+                    for (Page p : pages) {
+                        serializedPages.add(serde.serialize(p));
+                    }
                     outputBuffer.enqueue(operatorContext.getDriverContext().getLifespan(), partition, serializedPages);
                     pagesAdded.incrementAndGet();
                     rowsAdded.addAndGet(pagePartition.getPositionCount());
