Looking at the performance issue description, the problem is that `makeFollower()` holds a write lock on `leaderIsrUpdateLock` while `doAppendRecordsToFollowerOrFutureReplica()` holds a read lock on the same lock. This causes contention where ongoing log appends on followers delay `makeFollower()` calls, particularly problematic during controlled shutdown when switching leadership.

The solution is to introduce a separate `futureLogLock` to synchronize between `maybeReplaceCurrentWithFutureReplica()` and `doAppendRecordsToFollowerOrFutureReplica()`, allowing the latter to avoid holding the `leaderIsrUpdateLock`. This will prevent log appends on followers from delaying `makeFollower()` calls.

Here are the required changes:

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  private val remoteReplicasMap = new Pool[Int, Replica]\n  // The read lock is only required when multiple reads are executed and needs to be in a consistent manner\n  private val leaderIsrUpdateLock = new ReentrantReadWriteLock\n  private var zkVersion: Int = LeaderAndIsr.initialZKVersion\n  @volatile private var leaderEpoch: Int = LeaderAndIsr.initialLeaderEpoch - 1",
    "replace": "  private val remoteReplicasMap = new Pool[Int, Replica]\n  // The read lock is only required when multiple reads are executed and needs to be in a consistent manner\n  private val leaderIsrUpdateLock = new ReentrantReadWriteLock\n  // Lock to protect futureLog from being updated while ReplicaAlterDirThread is executing maybeReplaceCurrentWithFutureReplica()\n  private val futureLogLock = new ReentrantReadWriteLock\n  private var zkVersion: Int = LeaderAndIsr.initialZKVersion\n  @volatile private var leaderEpoch: Int = LeaderAndIsr.initialLeaderEpoch - 1"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {\n    // The read lock is needed to handle race condition if request handler thread tries to\n    // remove future replica after receiving AlterReplicaLogDirsRequest.\n    inReadLock(leaderIsrUpdateLock) {\n      if (isFuture) {\n        // Note the replica may be undefined if it is removed by a non-ReplicaAlterLogDirsThread before\n        // this method is called\n        futureLog.map { _.appendAsFollower(records) }\n      } else {\n        // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread\n        // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n        Some(localLogOrException.appendAsFollower(records))\n      }\n    }\n  }",
    "replace": "  private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {\n    // Use futureLogLock to prevent the follower/future replica from being updated while ReplicaAlterDirThread\n    // is executing maybeReplaceCurrentWithFutureReplica() to replace follower replica with the future replica.\n    inReadLock(futureLogLock) {\n      if (isFuture) {\n        // Note the replica may be undefined if it is removed by a non-ReplicaAlterLogDirsThread before\n        // this method is called\n        futureLog.map { _.appendAsFollower(records) }\n      } else {\n        Some(localLogOrException.appendAsFollower(records))\n      }\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def maybeReplaceCurrentWithFutureReplica(): Boolean = {\n    val localReplicaLEO = localLogOrException.logEndOffset\n    val futureReplicaLEO = futureLog.map(_.logEndOffset)\n    if (futureReplicaLEO.contains(localReplicaLEO)) {\n      // The write lock is needed to make sure that while ReplicaAlterDirThread checks the LEO of the\n      // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.\n      inWriteLock(leaderIsrUpdateLock) {\n        futureLog match {\n          case Some(futurePartitionLog) =>\n            if (log.exists(_.logEndOffset == futurePartitionLog.logEndOffset)) {\n              logManager.replaceCurrentWithFutureLog(topicPartition)\n              log = futureLog\n              removeFutureLocalReplica(false)\n              true\n            } else false\n          case None =>\n            // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called\n            // In this case the partition should have been removed from state of the ReplicaAlterLogDirsThread\n            // Return false so that ReplicaAlterLogDirsThread does not have to remove this partition from the\n            // state again to avoid race condition\n            false\n        }\n      }\n    } else false\n  }",
    "replace": "  def maybeReplaceCurrentWithFutureReplica(): Boolean = {\n    val localReplicaLEO = localLogOrException.logEndOffset\n    val futureReplicaLEO = futureLog.map(_.logEndOffset)\n    if (futureReplicaLEO.contains(localReplicaLEO)) {\n      // Acquire both locks to ensure no concurrent updates to follower/future replicas\n      // while checking and potentially swapping logs.\n      inWriteLock(leaderIsrUpdateLock) {\n        inWriteLock(futureLogLock) {\n          futureLog match {\n            case Some(futurePartitionLog) =>\n              if (log.exists(_.logEndOffset == futurePartitionLog.logEndOffset)) {\n                logManager.replaceCurrentWithFutureLog(topicPartition)\n                log = futureLog\n                removeFutureLocalReplica(false)\n                true\n              } else false\n            case None =>\n              // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called\n              // In this case the partition should have been removed from state of the ReplicaAlterLogDirsThread\n              // Return false so that ReplicaAlterLogDirsThread does not have to remove this partition from the\n              // state again to avoid race condition\n              false\n          }\n        }\n      }\n    } else false\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def removeFutureLocalReplica(deleteFromLogDir: Boolean = true): Unit = {\n    inWriteLock(leaderIsrUpdateLock) {\n      futureLog = None\n      if (deleteFromLogDir)\n        logManager.asyncDelete(topicPartition, isFuture = true)\n    }\n  }",
    "replace": "  def removeFutureLocalReplica(deleteFromLogDir: Boolean = true): Unit = {\n    inWriteLock(leaderIsrUpdateLock) {\n      inWriteLock(futureLogLock) {\n        futureLog = None\n        if (deleteFromLogDir)\n          logManager.asyncDelete(topicPartition, isFuture = true)\n      }\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def truncateTo(offset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    inReadLock(leaderIsrUpdateLock) {\n      logManager.truncateTo(Map(topicPartition -> offset), isFuture = isFuture)\n    }\n  }",
    "replace": "  def truncateTo(offset: Long, isFuture: Boolean): Unit = {\n    // Use futureLogLock to prevent the follower/future replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeReplaceCurrentWithFutureReplica() to replace follower replica with the future replica.\n    inReadLock(futureLogLock) {\n      logManager.truncateTo(Map(topicPartition -> offset), isFuture = isFuture)\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    inReadLock(leaderIsrUpdateLock) {\n      logManager.truncateFullyAndStartAt(topicPartition, newOffset, isFuture = isFuture)\n    }\n  }",
    "replace": "  def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {\n    // Use futureLogLock to prevent the follower/future replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeReplaceCurrentWithFutureReplica() to replace follower replica with the future replica.\n    inReadLock(futureLogLock) {\n      logManager.truncateFullyAndStartAt(topicPartition, newOffset, isFuture = isFuture)\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def maybeCreateFutureReplica(logDir: String, highWatermarkCheckpoints: OffsetCheckpoints): Boolean = {\n    // The writeLock is needed to make sure that while the caller checks the log directory of the\n    // current replica and the existence of the future replica, no other thread can update the log directory of the\n    // current replica or remove the future replica.\n    inWriteLock(leaderIsrUpdateLock) {\n      val currentLogDir = localLogOrException.dir.getParent\n      if (currentLogDir == logDir) {\n        info(s\"Current log directory $currentLogDir is same as requested log dir $logDir. \" +\n          s\"Skipping future replica creation.\")\n        false\n      } else {\n        futureLog match {\n          case Some(partitionFutureLog) =>\n            val futureLogDir = partitionFutureLog.dir.getParent\n            if (futureLogDir != logDir)\n              throw new IllegalStateException(s\"The future log dir $futureLogDir of $topicPartition is \" +\n                s\"different from the requested log dir $logDir\")\n            false\n          case None =>\n            createLogIfNotExists(Request.FutureLocalReplicaId, isNew = false, isFutureReplica = true, highWatermarkCheckpoints)\n            true\n        }\n      }\n    }\n  }",
    "replace": "  def maybeCreateFutureReplica(logDir: String, highWatermarkCheckpoints: OffsetCheckpoints): Boolean = {\n    // Acquire both locks to ensure no concurrent updates to follower/future replicas\n    // while checking and potentially creating future replica.\n    inWriteLock(leaderIsrUpdateLock) {\n      inWriteLock(futureLogLock) {\n        val currentLogDir = localLogOrException.dir.getParent\n        if (currentLogDir == logDir) {\n          info(s\"Current log directory $currentLogDir is same as requested log dir $logDir. \" +\n            s\"Skipping future replica creation.\")\n          false\n        } else {\n          futureLog match {\n            case Some(partitionFutureLog) =>\n              val futureLogDir = partitionFutureLog.dir.getParent\n              if (futureLogDir != logDir)\n                throw new IllegalStateException(s\"The future log dir $futureLogDir of $topicPartition is \" +\n                  s\"different from the requested log dir $logDir\")\n              false\n            case None =>\n              createLogIfNotExists(Request.FutureLocalReplicaId, isNew = false, isFutureReplica = true, highWatermarkCheckpoints)\n              true\n          }\n        }\n      }\n    }\n  }"
  }
]
```