diff --git a/core/src/main/scala/kafka/log/LogValidator.scala b/core/src/main/scala/kafka/log/LogValidator.scala
index 48b9f57d9a..e3133a4100 100644
--- a/core/src/main/scala/kafka/log/LogValidator.scala
+++ b/core/src/main/scala/kafka/log/LogValidator.scala
@@ -238,12 +238,16 @@ private[log] object LogValidator extends Logging {
       validateBatch(topicPartition, firstBatch, batch, origin, toMagicValue, brokerTopicStats)
 
       val recordErrors = new ArrayBuffer[ApiRecordError](0)
-      for ((record, batchIndex) <- batch.asScala.view.zipWithIndex) {
+      val batchIterator = batch.iterator()
+      var batchIndex = 0
+      while (batchIterator.hasNext) {
+        val record = batchIterator.next()
         validateRecord(batch, topicPartition, record, batchIndex, now, timestampType,
           timestampDiffMaxMs, compactedTopic, brokerTopicStats).foreach(recordError => recordErrors += recordError)
         // we fail the batch if any record fails, so we stop appending if any record fails
         if (recordErrors.isEmpty)
           builder.appendWithOffset(offsetCounter.getAndIncrement(), record)
+        batchIndex += 1
       }
 
       processRecordErrors(recordErrors)
@@ -286,7 +290,10 @@ private[log] object LogValidator extends Logging {
       var offsetOfMaxBatchTimestamp = -1L
 
       val recordErrors = new ArrayBuffer[ApiRecordError](0)
-      for ((record, batchIndex) <- batch.asScala.view.zipWithIndex) {
+      val batchIterator = batch.iterator()
+      var batchIndex = 0
+      while (batchIterator.hasNext) {
+        val record = batchIterator.next()
         validateRecord(batch, topicPartition, record, batchIndex, now, timestampType,
           timestampDiffMaxMs, compactedTopic, brokerTopicStats).foreach(recordError => recordErrors += recordError)
 
@@ -295,6 +302,7 @@ private[log] object LogValidator extends Logging {
           maxBatchTimestamp = record.timestamp
           offsetOfMaxBatchTimestamp = offset
         }
+        batchIndex += 1
       }
 
       processRecordErrors(recordErrors)
@@ -405,7 +413,8 @@ private[log] object LogValidator extends Logging {
       try {
         val recordErrors = new ArrayBuffer[ApiRecordError](0)
         var batchIndex = 0
-        for (record <- recordsIterator.asScala) {
+        while (recordsIterator.hasNext) {
+          val record = recordsIterator.next()
           val expectedOffset = expectedInnerOffset.getAndIncrement()
           val recordError = validateRecordCompression(batchIndex, record).orElse {
             validateRecord(batch, topicPartition, record, batchIndex, now,
@@ -425,13 +434,13 @@ private[log] object LogValidator extends Logging {
             }
           }
 
-          recordError match {
-            case Some(e) => recordErrors += e
-            case None =>
-              uncompressedSizeInBytes += record.sizeInBytes()
-              validatedRecords += record
+          if (recordError.isDefined) {
+            recordErrors += recordError.get
+          } else {
+            uncompressedSizeInBytes += record.sizeInBytes()
+            validatedRecords += record
           }
-         batchIndex += 1
+          batchIndex += 1
         }
         processRecordErrors(recordErrors)
       } finally {
