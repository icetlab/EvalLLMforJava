diff --git a/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java b/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java
index c289eaa59b..2e31634e7b 100644
--- a/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java
+++ b/clients/src/main/java/org/apache/kafka/common/internals/PartitionStates.java
@@ -139,15 +139,13 @@ public class PartitionStates<S> {
     }
 
     private void update(Map<TopicPartition, S> partitionToState) {
-        LinkedHashMap<String, List<TopicPartition>> topicToPartitions = new LinkedHashMap<>();
-        for (TopicPartition tp : partitionToState.keySet()) {
-            List<TopicPartition> partitions = topicToPartitions.computeIfAbsent(tp.topic(), k -> new ArrayList<>());
-            partitions.add(tp);
-        }
-        for (Map.Entry<String, List<TopicPartition>> entry : topicToPartitions.entrySet()) {
-            for (TopicPartition tp : entry.getValue()) {
-                S state = partitionToState.get(tp);
-                map.put(tp, state);
+        LinkedHashMap<String, List<Map.Entry<TopicPartition, S>>> topicToPartitionEntries = new LinkedHashMap<>();
+        for (Map.Entry<TopicPartition, S> entry : partitionToState.entrySet()) {
+            topicToPartitionEntries.computeIfAbsent(entry.getKey().topic(), k -> new ArrayList<>()).add(entry);
+        }
+        for (List<Map.Entry<TopicPartition, S>> entries : topicToPartitionEntries.values()) {
+            for (Map.Entry<TopicPartition, S> entry : entries) {
+                map.put(entry.getKey(), entry.getValue());
             }
         }
     }
diff --git a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
index 0f3b06952a..0782bf98be 100755
--- a/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
+++ b/core/src/main/scala/kafka/server/AbstractFetcherThread.scala
@@ -435,17 +435,18 @@ abstract class AbstractFetcherThread(name: String,
     * @param fetchOffsets the partitions to update fetch offset and maybe mark truncation complete
     */
   private def updateFetchOffsetAndMaybeMarkTruncationComplete(fetchOffsets: Map[TopicPartition, OffsetTruncationState]): Unit = {
-    val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStates.asScala
-      .map { state =>
-        val currentFetchState = state.value
-        val maybeTruncationComplete = fetchOffsets.get(state.topicPartition) match {
+    val newStates: Map[TopicPartition, PartitionFetchState] = partitionStates.partitionStateMap.entrySet.asScala
+      .map { entry =>
+        val tp = entry.getKey
+        val currentFetchState = entry.getValue
+        val maybeTruncationComplete = fetchOffsets.get(tp) match {
           case Some(offsetTruncationState) =>
             val state = if (offsetTruncationState.truncationCompleted) Fetching else Truncating
             PartitionFetchState(offsetTruncationState.offset, currentFetchState.lag,
               currentFetchState.currentLeaderEpoch, currentFetchState.delay, state)
           case None => currentFetchState
         }
-        (state.topicPartition, maybeTruncationComplete)
+        (tp, maybeTruncationComplete)
       }.toMap
     partitionStates.set(newStates.asJava)
   }
@@ -648,11 +649,13 @@ abstract class AbstractFetcherThread(name: String,
   }
 
   private[server] def partitionsAndOffsets: Map[TopicPartition, InitialFetchState] = inLock(partitionMapLock) {
-    partitionStates.partitionStates.asScala.map { state =>
+    partitionStates.partitionStateMap.entrySet.asScala.map { entry =>
+      val tp = entry.getKey
+      val state = entry.getValue
       val initialFetchState = InitialFetchState(sourceBroker,
-        currentLeaderEpoch = state.value.currentLeaderEpoch,
-        initOffset = state.value.fetchOffset)
-      state.topicPartition -> initialFetchState
+        currentLeaderEpoch = state.currentLeaderEpoch,
+        initOffset = state.fetchOffset)
+      tp -> initialFetchState
     }.toMap
   }
 
