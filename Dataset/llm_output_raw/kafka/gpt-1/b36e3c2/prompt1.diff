diff --git a/core/src/main/scala/kafka/log/LogValidator.scala b/core/src/main/scala/kafka/log/LogValidator.scala
index 48b9f57d9a..d6a501e6f4 100644
--- a/core/src/main/scala/kafka/log/LogValidator.scala
+++ b/core/src/main/scala/kafka/log/LogValidator.scala
@@ -202,9 +202,8 @@ private[log] object LogValidator extends Logging {
       }
     }
 
-    validateKey(record, batchIndex, topicPartition, compactedTopic, brokerTopicStats).orElse {
-      validateTimestamp(batch, record, batchIndex, now, timestampType, timestampDiffMaxMs)
-    }
+    val keyError = validateKey(record, batchIndex, topicPartition, compactedTopic, brokerTopicStats)
+    if (keyError.isDefined) keyError else validateTimestamp(batch, record, batchIndex, now, timestampType, timestampDiffMaxMs)
   }
 
   private def convertAndAssignOffsetsNonCompressed(records: MemoryRecords,
@@ -223,10 +222,12 @@ private[log] object LogValidator extends Logging {
     val sizeInBytesAfterConversion = AbstractRecords.estimateSizeInBytes(toMagicValue, offsetCounter.value,
       CompressionType.NONE, records.records)
 
-    val (producerId, producerEpoch, sequence, isTransactional) = {
-      val first = records.batches.asScala.head
-      (first.producerId, first.producerEpoch, first.baseSequence, first.isTransactional)
-    }
+    val batches = records.batches.asScala
+    val firstMeta = batches.head
+    val producerId = firstMeta.producerId
+    val producerEpoch = firstMeta.producerEpoch
+    val sequence = firstMeta.baseSequence
+    val isTransactional = firstMeta.isTransactional
 
     val newBuffer = ByteBuffer.allocate(sizeInBytesAfterConversion)
     val builder = MemoryRecords.builder(newBuffer, toMagicValue, CompressionType.NONE, timestampType,
@@ -234,7 +235,7 @@ private[log] object LogValidator extends Logging {
 
     val firstBatch = getFirstBatchAndMaybeValidateNoMoreBatches(records, NoCompressionCodec)
 
-    for (batch <- records.batches.asScala) {
+    for (batch <- batches) {
       validateBatch(topicPartition, firstBatch, batch, origin, toMagicValue, brokerTopicStats)
 
       val recordErrors = new ArrayBuffer[ApiRecordError](0)
@@ -277,9 +278,10 @@ private[log] object LogValidator extends Logging {
     var offsetOfMaxTimestamp = -1L
     val initialOffset = offsetCounter.value
 
+    val batches = records.batches.asScala
     val firstBatch = getFirstBatchAndMaybeValidateNoMoreBatches(records, NoCompressionCodec)
 
-    for (batch <- records.batches.asScala) {
+    for (batch <- batches) {
       validateBatch(topicPartition, firstBatch, batch, origin, magic, brokerTopicStats)
 
       var maxBatchTimestamp = RecordBatch.NO_TIMESTAMP
