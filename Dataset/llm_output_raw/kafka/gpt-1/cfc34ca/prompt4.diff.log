Here are changes to remove the expensive logsByDir grouping in the checkpoint paths and instead directly filter the existing currentLogs and futureLogs pools, greatly reducing intermediate allocations.

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/log/LogManager.scala",
    "search": "def checkpointLogRecoveryOffsets(): Unit = {\n    logsByDir.foreach { case (dir, partitionToLogMap) =>\n      liveLogDirs.find(_.getAbsolutePath.equals(dir)).foreach { f =>\n        checkpointRecoveryOffsetsAndCleanSnapshot(f, partitionToLogMap.values.toSeq)\n      }\n    }\n  }",
    "replace": "def checkpointLogRecoveryOffsets(): Unit = {\n    for {\n      dir <- liveLogDirs\n      checkpoint <- recoveryPointCheckpoints.get(dir)\n    } {\n      // collect all logs in this directory without materializing the full logsByDir map\n      val logsInDir = (currentLogs.iterator ++ futureLogs.iterator).collect {\n        case (_, log) if log.parentDir == dir.getAbsolutePath => log\n      }.toSeq\n      checkpointRecoveryOffsetsAndCleanSnapshot(dir, logsInDir)\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/log/LogManager.scala",
    "search": "private def checkpointLogRecoveryOffsetsInDir(dir: File): Unit = {\n    for {\n      partitionToLog <- logsByDir.get(dir.getAbsolutePath)\n      checkpoint <- recoveryPointCheckpoints.get(dir)\n    } {\n      checkpoint.write(partitionToLog.map { case (tp, log) => tp -> log.recoveryPoint })\n    }\n  }",
    "replace": "private def checkpointLogRecoveryOffsetsInDir(dir: File): Unit = {\n    // write recovery points by directly filtering the pools\n    for (checkpoint <- recoveryPointCheckpoints.get(dir)) {\n      val recoveryPoints = (currentLogs.iterator ++ futureLogs.iterator).collect {\n        case (tp, log) if log.parentDir == dir.getAbsolutePath => tp -> log.recoveryPoint\n      }.toMap\n      checkpoint.write(recoveryPoints)\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/log/LogManager.scala",
    "search": "def checkpointLogStartOffsets(): Unit = {\n    liveLogDirs.foreach(checkpointLogStartOffsetsInDir)\n  }",
    "replace": "def checkpointLogStartOffsets(): Unit = {\n    for {\n      dir <- liveLogDirs\n      checkpoint <- logStartOffsetCheckpoints.get(dir)\n    } {\n      // collect start offsets directly without grouping all logs\n      val startOffsets = (currentLogs.iterator ++ futureLogs.iterator).collect {\n        case (tp, log) if log.parentDir == dir.getAbsolutePath && log.logStartOffset > log.logSegments.head.baseOffset =>\n          tp -> log.logStartOffset\n      }.toMap\n      try {\n        checkpoint.write(startOffsets)\n      } catch {\n        case e: IOException =>\n          logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath,\n            s\"Disk error while writing to logStartOffset file in directory $dir\", e)\n      }\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/log/LogManager.scala",
    "search": "private def checkpointLogStartOffsetsInDir(dir: File): Unit = {\n    for {\n      partitionToLog <- logsByDir.get(dir.getAbsolutePath)\n      checkpoint <- logStartOffsetCheckpoints.get(dir)\n    } {\n      try {\n        val logStartOffsets = partitionToLog.collect {\n          case (k, log) if log.logStartOffset > log.logSegments.head.baseOffset => k -> log.logStartOffset\n        }\n        checkpoint.write(logStartOffsets)\n      } catch {\n        case e: IOException =>\n          logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath, s\"Disk error while writing to logStartOffset file in directory $dir\", e)\n      }\n    }\n  }",
    "replace": "private def checkpointLogStartOffsetsInDir(dir: File): Unit = {\n    // write start offsets by scanning pools directly\n    for (checkpoint <- logStartOffsetCheckpoints.get(dir)) {\n      try {\n        val startOffsets = (currentLogs.iterator ++ futureLogs.iterator).collect {\n          case (tp, log) if log.parentDir == dir.getAbsolutePath && log.logStartOffset > log.logSegments.head.baseOffset =>\n            tp -> log.logStartOffset\n        }.toMap\n        checkpoint.write(startOffsets)\n      } catch {\n        case e: IOException =>\n          logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath,\n            s\"Disk error while writing to logStartOffset file in directory $dir\", e)\n      }\n    }\n  }"
  }
]
```