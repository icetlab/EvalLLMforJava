I’ve converted the include/exclude collections from Lists to Sets to make the `filter` method’s `contains` checks O(1) rather than O(n), improving performance for large numbers of fields.

```json
[
  {
    "filepath": "../kafka/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ReplaceField.java",
    "search": "import java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;",
    "replace": "import java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;"
  },
  {
    "filepath": "../kafka/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ReplaceField.java",
    "search": "private List<String> exclude;\n    private List<String> include;",
    "replace": "private Set<String> exclude;\n    private Set<String> include;"
  },
  {
    "filepath": "../kafka/connect/transforms/src/main/java/org/apache/kafka/connect/transforms/ReplaceField.java",
    "search": "exclude = config.getList(ConfigName.EXCLUDE);\n        include = config.getList(ConfigName.INCLUDE);",
    "replace": "exclude = new HashSet<>(config.getList(ConfigName.EXCLUDE));\n        include = new HashSet<>(config.getList(ConfigName.INCLUDE));"
  }
]
```