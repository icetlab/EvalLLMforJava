The performance issue stems from zstd-jni's `ZstdInputStream` and `ZstdOutputStream` being inefficient for single-byte read/write operations. These operations are common in Kafka's record processing logic and result in high JNI call overhead and temporary object allocations.

To address this, I will wrap the raw ZSTD streams with `BufferedInputStream` and `BufferedOutputStream`. This strategy is similar to the existing implementation for GZIP compression. By buffering the I/O, we can aggregate multiple small read/write calls into larger, more efficient bulk operations, significantly reducing the number of expensive JNI context switches and improving overall throughput. I've chosen a 16KB buffer size, consistent with the GZIP implementation, as a reasonable default for uncompressed data.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/record/CompressionType.java",
    "search": "        @Override\n        public OutputStream wrapForOutput(ByteBufferOutputStream buffer, byte messageVersion) {\n            try {\n                return (OutputStream) ZstdConstructors.OUTPUT.invoke(buffer);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }",
    "replace": "        @Override\n        public OutputStream wrapForOutput(ByteBufferOutputStream buffer, byte messageVersion) {\n            try {\n                // Zstd-jni's ZstdOutputStream doesn't buffer writes well, so we wrap it in a\n                // BufferedOutputStream to avoid expensive JNI calls for every byte written.\n                return new BufferedOutputStream((OutputStream) ZstdConstructors.OUTPUT.invoke(buffer), 16 * 1024);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }"
  },
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/record/CompressionType.java",
    "search": "        @Override\n        public InputStream wrapForInput(ByteBuffer buffer, byte messageVersion, BufferSupplier decompressionBufferSupplier) {\n            try {\n                return (InputStream) ZstdConstructors.INPUT.invoke(new ByteBufferInputStream(buffer));\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }",
    "replace": "        @Override\n        public InputStream wrapForInput(ByteBuffer buffer, byte messageVersion, BufferSupplier decompressionBufferSupplier) {\n            try {\n                // Zstd-jni's ZstdInputStream doesn't buffer reads well, so we wrap it in a\n                // BufferedInputStream to avoid expensive JNI calls for every byte read.\n                return new BufferedInputStream((InputStream) ZstdConstructors.INPUT.invoke(new ByteBufferInputStream(buffer)),\n                        16 * 1024);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }"
  }
]
```