diff --git a/core/src/main/scala/kafka/cluster/Partition.scala b/core/src/main/scala/kafka/cluster/Partition.scala
index 9cfd99e8e5..1aad888f95 100755
--- a/core/src/main/scala/kafka/cluster/Partition.scala
+++ b/core/src/main/scala/kafka/cluster/Partition.scala
@@ -481,10 +481,10 @@ class Partition(val topicPartition: TopicPartition,
       controllerEpoch = partitionState.controllerEpoch
 
       updateAssignmentAndIsr(
-        assignment = partitionState.replicas.asScala.map(_.toInt),
-        isr = partitionState.isr.asScala.map(_.toInt).toSet,
-        addingReplicas = partitionState.addingReplicas.asScala.map(_.toInt),
-        removingReplicas = partitionState.removingReplicas.asScala.map(_.toInt)
+        assignment = partitionState.replicas.asScala.iterator.map(_.toInt).toSeq,
+        isr = partitionState.isr.asScala.iterator.map(_.toInt).toSet,
+        addingReplicas = partitionState.addingReplicas.asScala.iterator.map(_.toInt).toSeq,
+        removingReplicas = partitionState.removingReplicas.asScala.iterator.map(_.toInt).toSeq
       )
       createLogIfNotExists(localBrokerId, partitionState.isNew, isFutureReplica = false, highWatermarkCheckpoints)
 
@@ -556,8 +556,8 @@ class Partition(val topicPartition: TopicPartition,
       updateAssignmentAndIsr(
         assignment = partitionState.replicas.asScala.iterator.map(_.toInt).toSeq,
         isr = Set.empty[Int],
-        addingReplicas = partitionState.addingReplicas.asScala.map(_.toInt),
-        removingReplicas = partitionState.removingReplicas.asScala.map(_.toInt)
+        addingReplicas = partitionState.addingReplicas.asScala.iterator.map(_.toInt).toSeq,
+        removingReplicas = partitionState.removingReplicas.asScala.iterator.map(_.toInt).toSeq
       )
       createLogIfNotExists(localBrokerId, partitionState.isNew, isFutureReplica = false, highWatermarkCheckpoints)
 
@@ -651,9 +651,10 @@ class Partition(val topicPartition: TopicPartition,
     val replicaSet = assignment.toSet
     val removedReplicas = remoteReplicasMap.keys -- replicaSet
 
-    assignment
-      .filter(_ != localBrokerId)
-      .foreach(id => remoteReplicasMap.getAndMaybePut(id, new Replica(id, topicPartition)))
+    assignment.foreach { id =>
+      if (id != localBrokerId)
+        remoteReplicasMap.getAndMaybePut(id, new Replica(id, topicPartition))
+    }
     removedReplicas.foreach(remoteReplicasMap.remove)
     if (addingReplicas.nonEmpty || removingReplicas.nonEmpty)
       assignmentState = OngoingReassignmentState(addingReplicas, removingReplicas, assignment)
@@ -904,10 +905,9 @@ class Partition(val topicPartition: TopicPartition,
      * is violated, that replica is considered to be out of sync
      *
      **/
-    val candidateReplicaIds = inSyncReplicaIds - localBrokerId
     val currentTimeMs = time.milliseconds()
     val leaderEndOffset = localLogOrException.logEndOffset
-    candidateReplicaIds.filter(replicaId => isFollowerOutOfSync(replicaId, leaderEndOffset, currentTimeMs, maxLagMs))
+    inSyncReplicaIds.filter(replicaId => replicaId != localBrokerId && isFollowerOutOfSync(replicaId, leaderEndOffset, currentTimeMs, maxLagMs))
   }
 
   private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {
