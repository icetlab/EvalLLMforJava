The performance issue stems from lock contention on `leaderIsrUpdateLock`. Specifically, `Partition.makeFollower()` acquires a write lock, while `Partition.doAppendRecordsToFollowerOrFutureReplica()` (for follower appends) acquires a read lock. This causes `makeFollower()` to be blocked by ongoing follower appends, which can delay leadership changes and cause unnecessary ISR shrinking.

The root cause is that `doAppendRecordsToFollowerOrFutureReplica` holds this lock to synchronize with `maybeReplaceCurrentWithFutureReplica`, a method related to log directory alterations. To resolve this, I will introduce a new, more fine-grained lock, `futureLogLock`.

My changes are as follows:
1.  A new `ReentrantReadWriteLock` named `futureLogLock` is added to the `Partition` class.
2.  This new lock will be used to protect the local log during replica log directory alterations. `maybeReplaceCurrentWithFutureReplica` will now acquire a write lock on `futureLogLock`.
3.  The methods `doAppendRecordsToFollowerOrFutureReplica`, `truncateTo`, and `truncateFullyAndStartAt` are modified. When operating on the local log (i.e., not the future log), they will now use `futureLogLock` instead of `leaderIsrUpdateLock`. Operations on the future log will continue to use `leaderIsrUpdateLock` for correctness.

This change decouples the locking for follower appends from general partition state changes, eliminating the contention between `makeFollower` and `doAppendRecordsToFollowerOrFutureReplica` and thus improving the performance of leadership transitions.

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  private val leaderIsrUpdateLock = new ReentrantReadWriteLock\n  private var zkVersion: Int = LeaderAndIsr.initialZKVersion",
    "replace": "  private val leaderIsrUpdateLock = new ReentrantReadWriteLock\n  private val futureLogLock = new ReentrantReadWriteLock\n  private var zkVersion: Int = LeaderAndIsr.initialZKVersion"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "      // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.\n      inWriteLock(leaderIsrUpdateLock) {\n        futureLog match {\n          case Some(futurePartitionLog) =>\n            if (log.exists(_.logEndOffset == futurePartitionLog.logEndOffset)) {\n              logManager.replaceCurrentWithFutureLog(topicPartition)\n              log = futureLog\n              removeFutureLocalReplica(false)\n              true\n            } else false\n          case None =>\n            // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called\n            // In this case the partition should have been removed from state of the ReplicaAlterLogDirsThread\n            // Return false so that ReplicaAlterLogDirsThread does not have to remove this partition from the\n            // state again to avoid race condition\n            false\n        }\n      }",
    "replace": "      // current replica, no other thread can update LEO of the current replica via log truncation or log append operation.\n      inWriteLock(leaderIsrUpdateLock) {\n        inWriteLock(futureLogLock) {\n          futureLog match {\n            case Some(futurePartitionLog) =>\n              if (log.exists(_.logEndOffset == futurePartitionLog.logEndOffset)) {\n                logManager.replaceCurrentWithFutureLog(topicPartition)\n                log = futureLog\n                removeFutureLocalReplica(false)\n                true\n              } else false\n            case None =>\n              // Future replica is removed by a non-ReplicaAlterLogDirsThread before this method is called\n              // In this case the partition should have been removed from state of the ReplicaAlterLogDirsThread\n              // Return false so that ReplicaAlterLogDirsThread does not have to remove this partition from the\n              // state again to avoid race condition\n              false\n          }\n        }\n      }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {\n    // The read lock is needed to handle race condition if request handler thread tries to\n    // remove future replica after receiving AlterReplicaLogDirsRequest.\n    inReadLock(leaderIsrUpdateLock) {\n      if (isFuture) {\n        // Note the replica may be undefined if it is removed by a non-ReplicaAlterLogDirsThread before\n        // this method is called\n        futureLog.map { _.appendAsFollower(records) }\n      } else {\n        // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread\n        // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n        Some(localLogOrException.appendAsFollower(records))\n      }\n    }\n  }",
    "replace": "  private def doAppendRecordsToFollowerOrFutureReplica(records: MemoryRecords, isFuture: Boolean): Option[LogAppendInfo] = {\n    if (isFuture) {\n      // The read lock is needed to handle race condition if request handler thread tries to\n      // remove future replica after receiving AlterReplicaLogDirsRequest.\n      inReadLock(leaderIsrUpdateLock) {\n        // Note the replica may be undefined if it is removed by a non-ReplicaAlterLogDirsThread before\n        // this method is called\n        futureLog.map { _.appendAsFollower(records) }\n      }\n    } else {\n      // The read lock is needed to prevent the follower replica from being updated while ReplicaAlterDirThread\n      // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n      inReadLock(futureLogLock) {\n        Some(localLogOrException.appendAsFollower(records))\n      }\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def truncateTo(offset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    inReadLock(leaderIsrUpdateLock) {\n      logManager.truncateTo(Map(topicPartition -> offset), isFuture = isFuture)\n    }\n  }",
    "replace": "  def truncateTo(offset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    if (isFuture) {\n      inReadLock(leaderIsrUpdateLock) {\n        logManager.truncateTo(Map(topicPartition -> offset), isFuture = isFuture)\n      }\n    } else {\n      inReadLock(futureLogLock) {\n        logManager.truncateTo(Map(topicPartition -> offset), isFuture = isFuture)\n      }\n    }\n  }"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/cluster/Partition.scala",
    "search": "  def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    inReadLock(leaderIsrUpdateLock) {\n      logManager.truncateFullyAndStartAt(topicPartition, newOffset, isFuture = isFuture)\n    }\n  }",
    "replace": "  def truncateFullyAndStartAt(newOffset: Long, isFuture: Boolean): Unit = {\n    // The read lock is needed to prevent the follower replica from being truncated while ReplicaAlterDirThread\n    // is executing maybeDeleteAndSwapFutureReplica() to replace follower replica with the future replica.\n    if (isFuture) {\n      inReadLock(leaderIsrUpdateLock) {\n        logManager.truncateFullyAndStartAt(topicPartition, newOffset, isFuture = isFuture)\n      }\n    } else {\n      inReadLock(futureLogLock) {\n        logManager.truncateFullyAndStartAt(topicPartition, newOffset, isFuture = isFuture)\n      }\n    }\n  }"
  }
]
```