The performance issue with Zstd compression stems from the `zstd-jni` library's I/O handling. Frequent, small read/write operations, common in Kafka's record processing, lead to excessive and expensive JNI context switches between Java and native code. This is because the underlying `ZstdInputStream` and `ZstdOutputStream` do not buffer these small operations.

To improve performance, I will wrap the Zstd streams with `BufferedInputStream` and `BufferedOutputStream`. This standard Java practice will buffer data, aggregating small reads and writes into larger chunks before they are passed to the native Zstd implementation. This significantly reduces the number of JNI calls, improving throughput and reducing CPU overhead. The chosen buffer size of 16KB is consistent with the existing, optimized GZIP implementation in Kafka, providing a reasonable balance between memory usage and performance gain.

```json
[
  {
    "filepath": "../kafka/clients/src/main/java/org/apache/kafka/common/record/CompressionType.java",
    "search": "    ZSTD(4, \"zstd\", 1.0f) {\n        @Override\n        public OutputStream wrapForOutput(ByteBufferOutputStream buffer, byte messageVersion) {\n            try {\n                return (OutputStream) ZstdConstructors.OUTPUT.invoke(buffer);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n\n        @Override\n        public InputStream wrapForInput(ByteBuffer buffer, byte messageVersion, BufferSupplier decompressionBufferSupplier) {\n            try {\n                return (InputStream) ZstdConstructors.INPUT.invoke(new ByteBufferInputStream(buffer));\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n    };",
    "replace": "    ZSTD(4, \"zstd\", 1.0f) {\n        @Override\n        public OutputStream wrapForOutput(ByteBufferOutputStream buffer, byte messageVersion) {\n            try {\n                // To ensure reasonable performance in cases where the caller passes a small number of bytes to write\n                // (potentially a single byte), we need to buffer the data before writing it to the Zstd JNI.\n                // The Zstd JNI is more efficient if the writes of uncompressed data are flushed in large pieces\n                // rather than for each byte.\n                return new BufferedOutputStream((OutputStream) ZstdConstructors.OUTPUT.invoke(buffer), 16 * 1024);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n\n        @Override\n        public InputStream wrapForInput(ByteBuffer buffer, byte messageVersion, BufferSupplier decompressionBufferSupplier) {\n            try {\n                // To ensure reasonable performance in cases where the caller reads a small number of bytes\n                // (potentially a single byte), we need to buffer the data read from the Zstd JNI.\n                // The Zstd JNI is more efficient if the reads of uncompressed data are flushed in large pieces\n                // rather than for each byte.\n                return new BufferedInputStream((InputStream) ZstdConstructors.INPUT.invoke(new ByteBufferInputStream(buffer)), 16 * 1024);\n            } catch (Throwable e) {\n                throw new KafkaException(e);\n            }\n        }\n    };"
  }
]
```