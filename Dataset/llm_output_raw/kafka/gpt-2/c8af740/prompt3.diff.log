Iâ€™ve optimized removeExpiredProducers to avoid stream allocations and intermediate lists by iterating and removing entries directly, reducing GC pressure and improving throughput when handling large producer maps.

```json
[
  {
    "filepath": "../kafka/storage/src/main/java/org/apache/kafka/storage/internals/log/ProducerStateManager.java",
    "search": "public void removeExpiredProducers(long currentTimeMs) {\n        List<Long> keys = producers.entrySet().stream()\n                .filter(entry -> isProducerExpired(currentTimeMs, entry.getValue()))\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        removeProducerIds(keys);\n\n        List<Long> verificationKeys = verificationStates.entrySet().stream()\n                .filter(entry -> currentTimeMs - entry.getValue().timestamp() >= producerStateManagerConfig.producerIdExpirationMs())\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        verificationKeys.forEach(verificationStates::remove);\n    }",
    "replace": "public void removeExpiredProducers(long currentTimeMs) {\n        long expirationMs = producerStateManagerConfig.producerIdExpirationMs();\n        Iterator<Map.Entry<Long, ProducerStateEntry>> it = producers.entrySet().iterator();\n        while (it.hasNext()) {\n            Map.Entry<Long, ProducerStateEntry> entry = it.next();\n            if (isProducerExpired(currentTimeMs, entry.getValue())) {\n                it.remove();\n            }\n        }\n        producerIdCount = producers.size();\n\n        Iterator<Map.Entry<Long, VerificationStateEntry>> it2 = verificationStates.entrySet().iterator();\n        while (it2.hasNext()) {\n            Map.Entry<Long, VerificationStateEntry> entry = it2.next();\n            if (currentTimeMs - entry.getValue().timestamp() >= expirationMs) {\n                it2.remove();\n            }\n        }\n    }"
  }
]
```