Iâ€™ve added a local `batches` val in both non-compressed conversion and assignment methods to cache `records.batches.asScala`, and updated the loop headers to iterate over this cached collection, avoiding repeated collection wrapping.

```json
[
  {
    "filepath": "../kafka/core/src/main/scala/kafka/log/LogValidator.scala",
    "search": "    val firstBatch = getFirstBatchAndMaybeValidateNoMoreBatches(records, NoCompressionCodec)",
    "replace": "    val firstBatch = getFirstBatchAndMaybeValidateNoMoreBatches(records, NoCompressionCodec)\n    val batches = records.batches.asScala"
  },
  {
    "filepath": "../kafka/core/src/main/scala/kafka/log/LogValidator.scala",
    "search": "    for (batch <- records.batches.asScala) {",
    "replace": "    for (batch <- batches) {"
  }
]
```