The performance issue is that the current `decodeString` method in `ByteBufUtil` uses an inefficient path with `CharsetDecoder` and `CharBuffer` even when the `ByteBuf` is backed by a single heap array. This causes unnecessary memory copies. We can optimize by using `new String(byte[], Charset)` directly when the underlying buffer has an accessible array, leveraging Java's built-in optimizations.

```json
[
  {
    "filepath": "../netty/buffer/src/main/java/io/netty/buffer/ByteBufUtil.java",
    "search": "    static String decodeString(ByteBuf src, int readerIndex, int len, Charset charset) {\n        if (len == 0) {\n            return StringUtil.EMPTY_STRING;\n        }\n        final CharsetDecoder decoder = CharsetUtil.decoder(charset);\n        final int maxLength = (int) ((double) len * decoder.maxCharsPerByte());\n        CharBuffer dst = CHAR_BUFFERS.get();\n        if (dst.length() < maxLength) {\n            dst = CharBuffer.allocate(maxLength);\n            if (maxLength <= MAX_CHAR_BUFFER_SIZE) {\n                CHAR_BUFFERS.set(dst);\n            }\n        } else {\n            dst.clear();\n        }\n        if (src.nioBufferCount() == 1) {\n            decodeString(decoder, src.nioBuffer(readerIndex, len), dst);\n        } else {\n            // We use a heap buffer as CharsetDecoder is most likely able to use a fast-path if src and dst buffers\n            // are both backed by a byte array.\n            ByteBuf buffer = src.alloc().heapBuffer(len);\n            try {\n                buffer.writeBytes(src, readerIndex, len);\n                // Use internalNioBuffer(...) to reduce object creation.\n                decodeString(decoder, buffer.internalNioBuffer(buffer.readerIndex(), len), dst);\n            } finally {\n                // Release the temporary buffer again.\n                buffer.release();\n            }\n        }\n        return dst.flip().toString();\n    }",
    "replace": "    static String decodeString(ByteBuf src, int readerIndex, int len, Charset charset) {\n        if (len == 0) {\n            return StringUtil.EMPTY_STRING;\n        }\n        if (src.nioBufferCount() == 1) {\n            ByteBuffer nioBuffer = src.nioBuffer(readerIndex, len);\n            if (nioBuffer.hasArray()) {\n                return new String(nioBuffer.array(), nioBuffer.arrayOffset() + nioBuffer.position(), len, charset);\n            }\n        }\n        final CharsetDecoder decoder = CharsetUtil.decoder(charset);\n        final int maxLength = (int) ((double) len * decoder.maxCharsPerByte());\n        CharBuffer dst = CHAR_BUFFERS.get();\n        if (dst.length() < maxLength) {\n            dst = CharBuffer.allocate(maxLength);\n            if (maxLength <= MAX_CHAR_BUFFER_SIZE) {\n                CHAR_BUFFERS.set(dst);\n            }\n        } else {\n            dst.clear();\n        }\n        if (src.nioBufferCount() == 1) {\n            decodeString(decoder, src.nioBuffer(readerIndex, len), dst);\n        } else {\n            // We use a heap buffer as CharsetDecoder is most likely able to use a fast-path if src and dst buffers\n            // are both backed by a byte array.\n            ByteBuf buffer = src.alloc().heapBuffer(len);\n            try {\n                buffer.writeBytes(src, readerIndex, len);\n                // Use internalNioBuffer(...) to reduce object creation.\n                decodeString(decoder, buffer.internalNioBuffer(buffer.readerIndex(), len), dst);\n            } finally {\n                // Release the temporary buffer again.\n                buffer.release();\n            }\n        }\n        return dst.flip().toString();\n    }"
  }
]
```