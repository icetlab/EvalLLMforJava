The performance issue indicates that we should reuse the compression buffer when serializing pages. Currently, in `PagesSerde.serialize()`, a new `ByteBuffer` is allocated for compression each time the method is called. This can lead to excessive memory allocation and GC pressure. We can improve performance by reusing a single compression buffer across serializations, perhaps as a thread-local buffer since `PagesSerde` is marked `@NotThreadSafe`.

However, note that `PagesSerde` is not thread-safe, so we can reuse a buffer instance field. But we must consider that the buffer size may need to grow if a larger uncompressed size is encountered. We'll allocate a buffer lazily and ensure it's large enough for each compression operation.

We'll also need to handle the decompression buffer similarly? The issue only mentions serializing pages, but we can also apply the same optimization for deserialization to reuse a decompression buffer.

Let's examine the code:

1. In `serialize`, we have:
```java
ByteBuffer compressionBuffer = ByteBuffer.allocate(compressor.get().maxCompressedLength(uncompressedSize));
```

We can change this to reuse a buffer stored as an instance field.

2. In `deserialize`, we have:
```java
ByteBuffer decompressionBuffer = ByteBuffer.allocate(uncompressedSize);
```

Similarly, we can reuse a buffer for decompression.

But note: `PagesSerde` is `@NotThreadSafe` and each instance is used by a single thread (likely per operator). So we can add instance fields `compressionBuffer` and `decompressionBuffer` and reuse them.

We must ensure that the buffers are large enough. We can use a method to ensure capacity.

Also, note that the compression buffer size is based on `compressor.get().maxCompressedLength(uncompressedSize)`, which may vary. We can store a `ByteBuffer` and reallocate only when needed.

Similarly for decompression buffer, the size is exactly `uncompressedSize`.

We'll add two private `ByteBuffer` fields and two helper methods to ensure capacity.

But note: the `PagesSerde` is created by `PagesSerdeFactory` and used in `PartitionedOutputOperator.PagePartitioner`. The `PagePartitioner` creates a `PagesSerde` via `serdeFactory.createPagesSerde()`. Each `PagePartitioner` has its own `PagesSerde` instance, so it's safe to add instance fields.

Let's implement:

- Add `private ByteBuffer compressionBuffer` and `private ByteBuffer decompressionBuffer`.
- In `serialize`, when compression is needed, call `ensureCompressionBufferCapacity(compressor.get().maxCompressedLength(uncompressedSize))`.
- In `deserialize`, when decompression is needed, call `ensureDecompressionBufferCapacity(uncompressedSize)`.

We must also clear the buffers before use? The `compress` and `decompress` methods expect the buffer to be ready for writing (position=0, limit=capacity). We'll allocate with `ByteBuffer.allocate(capacity)` and then before each use we need to clear it? Actually, after we ensure capacity, we should set the buffer's position to 0 and limit to capacity. We can do `buffer.clear()` but note that `clear` sets limit=capacity, position=0. That's what we want before compression/decompression.

But after compression, we flip the buffer (limit=position, position=0). That's fine.

We'll also need to be careful about thread safety: since the class is not thread-safe, we are safe.

Now, we also need to consider that the buffer may be used for compression and then later for decompression? They are separate buffers, so we can keep them separate.

Let's write the changes.

First, we'll modify `PagesSerde.java`:

We'll add fields and helper methods.

We'll also need to import `java.nio.ByteBuffer` (already imported).

We'll change the `serialize` method to reuse the compression buffer.

We'll change the `deserialize` method to reuse the decompression buffer.

We must also consider that the `spillCipher` may be present and encryption/decryption also uses `ByteBuffer` but it's via `slice.toByteBuffer()` and then `Slices.wrappedBuffer`. That doesn't allocate a new buffer per call? Actually, `slice.toByteBuffer()` returns a view, and `spillCipher.encrypt` returns a new byte array wrapped into a ByteBuffer? Looking at `SpillCipher` interface, we don't have the code, but likely it returns a new byte array. So we cannot reuse there.

We'll focus on compression/decompression buffers.

Now, we must ensure that the changes do not break existing functionality. The unit tests should pass.

Let's produce the JSON changes.

We'll create two changes: one for adding fields and helper methods, and another for modifying the serialize and deserialize methods.

But note: the JSON array expects each change to be independent. We'll break into two changes: one for adding fields and helper methods, and one for modifying the methods. However, the helper methods are used in the methods, so they must be added first. But each change is applied sequentially? The instructions say each element is an independent, atomic change. We can combine adding fields and helper methods into one change? Actually, we can add fields and helper methods in one change, and then modify the methods in another. That should be fine because the helper methods are defined before they are used.

But we must ensure the search strings are unique. We'll search for the class definition and add fields after the existing fields.

Alternatively, we can add the fields and helper methods in one change by searching for the constructor and adding after it? Let's look at the file structure.

We'll output the changes.

```json
[
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "    private final Optional<Compressor> compressor;\n    private final Optional<Decompressor> decompressor;\n    private final Optional<SpillCipher> spillCipher;",
    "replace": "    private final Optional<Compressor> compressor;\n    private final Optional<Decompressor> decompressor;\n    private final Optional<SpillCipher> spillCipher;\n    private ByteBuffer compressionBuffer;\n    private ByteBuffer decompressionBuffer;"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "    public SerializedPage serialize(Page page)\n    {\n        SliceOutput serializationBuffer = new DynamicSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n        writeRawPage(page, serializationBuffer, blockEncodingSerde);\n        Slice slice = serializationBuffer.slice();\n        int uncompressedSize = serializationBuffer.size();\n        byte markers = PageCodecMarker.none();\n\n        if (compressor.isPresent()) {\n            ByteBuffer compressionBuffer = ByteBuffer.allocate(compressor.get().maxCompressedLength(uncompressedSize));\n            compressor.get().compress(slice.toByteBuffer(), compressionBuffer);\n            compressionBuffer.flip();\n            if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n                slice = Slices.wrappedBuffer(compressionBuffer);\n                markers = COMPRESSED.set(markers);\n            }\n        }",
    "replace": "    public SerializedPage serialize(Page page)\n    {\n        SliceOutput serializationBuffer = new DynamicSliceOutput(toIntExact(page.getSizeInBytes() + Integer.BYTES)); // block length is an int\n        writeRawPage(page, serializationBuffer, blockEncodingSerde);\n        Slice slice = serializationBuffer.slice();\n        int uncompressedSize = serializationBuffer.size();\n        byte markers = PageCodecMarker.none();\n\n        if (compressor.isPresent()) {\n            int maxCompressedLength = compressor.get().maxCompressedLength(uncompressedSize);\n            ensureCompressionBufferCapacity(maxCompressedLength);\n            compressionBuffer.clear();\n            compressor.get().compress(slice.toByteBuffer(), compressionBuffer);\n            compressionBuffer.flip();\n            if ((((double) compressionBuffer.remaining()) / uncompressedSize) <= MINIMUM_COMPRESSION_RATIO) {\n                slice = Slices.wrappedBuffer(compressionBuffer);\n                markers = COMPRESSED.set(markers);\n            }\n        }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "    public Page deserialize(SerializedPage serializedPage)\n    {\n        checkArgument(serializedPage != null, \"serializedPage is null\");\n\n        Slice slice = serializedPage.getSlice();\n\n        if (ENCRYPTED.isSet(serializedPage.getPageCodecMarkers())) {\n            checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n            slice = Slices.wrappedBuffer(spillCipher.get().decrypt(slice.toByteBuffer()));\n        }\n\n        if (COMPRESSED.isSet(serializedPage.getPageCodecMarkers())) {\n            checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n\n            int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n            ByteBuffer decompressionBuffer = ByteBuffer.allocate(uncompressedSize);\n\n            decompressor.get().decompress(slice.toByteBuffer(), decompressionBuffer);\n            decompressionBuffer.flip();\n            checkState(decompressionBuffer.remaining() == uncompressedSize);\n\n            slice = Slices.wrappedBuffer(decompressionBuffer);\n        }\n\n        return readRawPage(serializedPage.getPositionCount(), slice.getInput(), blockEncodingSerde);\n    }",
    "replace": "    public Page deserialize(SerializedPage serializedPage)\n    {\n        checkArgument(serializedPage != null, \"serializedPage is null\");\n\n        Slice slice = serializedPage.getSlice();\n\n        if (ENCRYPTED.isSet(serializedPage.getPageCodecMarkers())) {\n            checkState(spillCipher.isPresent(), \"Page is encrypted, but spill cipher is missing\");\n            slice = Slices.wrappedBuffer(spillCipher.get().decrypt(slice.toByteBuffer()));\n        }\n\n        if (COMPRESSED.isSet(serializedPage.getPageCodecMarkers())) {\n            checkState(decompressor.isPresent(), \"Page is compressed, but decompressor is missing\");\n\n            int uncompressedSize = serializedPage.getUncompressedSizeInBytes();\n            ensureDecompressionBufferCapacity(uncompressedSize);\n            decompressionBuffer.clear();\n            decompressor.get().decompress(slice.toByteBuffer(), decompressionBuffer);\n            decompressionBuffer.flip();\n            checkState(decompressionBuffer.remaining() == uncompressedSize);\n\n            slice = Slices.wrappedBuffer(decompressionBuffer);\n        }\n\n        return readRawPage(serializedPage.getPositionCount(), slice.getInput(), blockEncodingSerde);\n    }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/execution/buffer/PagesSerde.java",
    "search": "        checkState(!spillCipher.isPresent() || !spillCipher.get().isDestroyed(), \"spillCipher is already destroyed\");\n    }",
    "replace": "        checkState(!spillCipher.isPresent() || !spillCipher.get().isDestroyed(), \"spillCipher is already destroyed\");\n    }\n\n    private void ensureCompressionBufferCapacity(int capacity)\n    {\n        if (compressionBuffer == null || compressionBuffer.capacity() < capacity) {\n            compressionBuffer = ByteBuffer.allocate(capacity);\n        }\n    }\n\n    private void ensureDecompressionBufferCapacity(int capacity)\n    {\n        if (decompressionBuffer == null || decompressionBuffer.capacity() < capacity) {\n            decompressionBuffer = ByteBuffer.allocate(capacity);\n        }\n    }"
  }
]
```