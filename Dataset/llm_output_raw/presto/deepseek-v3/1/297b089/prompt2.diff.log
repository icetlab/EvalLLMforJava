Looking at the performance issue and the provided code, the goal is to improve the reading of `lengthVector` in `SliceDirectSelectiveStreamReader`. Currently, the `useBatchMode` method always returns `true`, which forces batch mode even when it might not be optimal. This leads to reading all lengths into `lengthVector` even when only a subset of positions are needed (non-batch mode). The commented-out logic in `useBatchMode` suggests a more sophisticated heuristic based on filter rate and type characteristics.

The main improvement is to enable the smarter `useBatchMode` logic that was already designed but commented out. This will reduce unnecessary length reads in non-batch mode scenarios, improving performance.

Here are the atomic changes to enable the smarter batch mode logic:

```json
[
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private boolean useBatchMode(int positionCount, int totalPositionCount)\n    {\n        return true;\n        // maxCodePointCount < 0 means it's unbounded varchar VARCHAR.\n        // If the types are VARCHAR(N) or CHAR(N), the length of the string need to be calculated and truncated.\n//        if (lengthStream == null || maxCodePointCount >= 0) {\n//            return false;\n//        }\n//\n//        double inputFilterRate = (double) (totalPositionCount - positionCount) / totalPositionCount;\n//        if (filter == null) {  // readNoFilter\n//            // When there is no filter, batch mode performs better for almost all inputFilterRate.\n//            // But to limit data buffer size, we enable it for the range of [0.0f, 0.5f]\n//            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.5f) {\n//                return true;\n//            }\n//\n//            return false;\n//        }\n//        else { // readWithFilter\n//            // When there is filter, batch mode performs better for almost all inputFilterRate except when inputFilterRate is around 0.1f.\n//            // To limit data buffer size, we enable it for the range of [0.0f, 0.05f] and [0.15f, 0.5f]\n//            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.05f || inputFilterRate >= 0.15f && inputFilterRate <= 0.5f) {\n//                return true;\n//            }\n//\n//            return false;\n//        }\n    }",
    "replace": "    private boolean useBatchMode(int positionCount, int totalPositionCount)\n    {\n        // maxCodePointCount < 0 means it's unbounded varchar VARCHAR.\n        // If the types are VARCHAR(N) or CHAR(N), the length of the string need to be calculated and truncated.\n        if (lengthStream == null || maxCodePointCount >= 0) {\n            return false;\n        }\n\n        double inputFilterRate = (double) (totalPositionCount - positionCount) / totalPositionCount;\n        if (filter == null) {  // readNoFilter\n            // When there is no filter, batch mode performs better for almost all inputFilterRate.\n            // But to limit data buffer size, we enable it for the range of [0.0f, 0.5f]\n            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.5f) {\n                return true;\n            }\n\n            return false;\n        }\n        else { // readWithFilter\n            // When there is filter, batch mode performs better for almost all inputFilterRate except when inputFilterRate is around 0.1f.\n            // To limit data buffer size, we enable it for the range of [0.0f, 0.05f] and [0.15f, 0.5f]\n            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.05f || inputFilterRate >= 0.15f && inputFilterRate <= 0.5f) {\n                return true;\n            }\n\n            return false;\n        }\n    }"
  }
]
```