Looking at the provided `SliceDirectSelectiveStreamReader.java`, I can see several performance improvement opportunities. The main issues are:

1. **Batch mode heuristic is disabled**: The `useBatchMode()` method always returns `true`, which means batch processing is always used regardless of data characteristics. This could be inefficient for certain scenarios.

2. **Memory allocation patterns**: There are opportunities to optimize memory allocation and reuse.

3. **Loop optimizations**: Some loops can be optimized for better performance.

Here are the specific improvements:

```json
[
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private boolean useBatchMode(int positionCount, int totalPositionCount)\n    {\n        return true;\n        // maxCodePointCount < 0 means it's unbounded varchar VARCHAR.\n        // If the types are VARCHAR(N) or CHAR(N), the length of the string need to be calculated and truncated.\n//        if (lengthStream == null || maxCodePointCount >= 0) {\n//            return false;\n//        }\n//\n//        double inputFilterRate = (double) (totalPositionCount - positionCount) / totalPositionCount;\n//        if (filter == null) {  // readNoFilter\n//            // When there is no filter, batch mode performs better for almost all inputFilterRate.\n//            // But to limit data buffer size, we enable it for the range of [0.0f, 0.5f]\n//            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.5f) {\n//                return true;\n//            }\n//\n//            return false;\n//        }\n//        else { // readWithFilter\n//            // When there is filter, batch mode performs better for almost all inputFilterRate except when inputFilterRate is around 0.1f.\n//            // To limit data buffer size, we enable it for the range of [0.0f, 0.05f] and [0.15f, 0.5f]\n//            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.05f || inputFilterRate >= 0.15f && inputFilterRate <= 0.5f) {\n//                return true;\n//            }\n//\n//            return false;\n//        }\n    }",
    "replace": "    private boolean useBatchMode(int positionCount, int totalPositionCount)\n    {\n        // maxCodePointCount < 0 means it's unbounded varchar VARCHAR.\n        // If the types are VARCHAR(N) or CHAR(N), the length of the string need to be calculated and truncated.\n        if (lengthStream == null || maxCodePointCount >= 0) {\n            return false;\n        }\n\n        double inputFilterRate = (double) (totalPositionCount - positionCount) / totalPositionCount;\n        if (filter == null) {  // readNoFilter\n            // When there is no filter, batch mode performs better for almost all inputFilterRate.\n            // But to limit data buffer size, we enable it for the range of [0.0f, 0.5f]\n            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.5f) {\n                return true;\n            }\n\n            return false;\n        }\n        else { // readWithFilter\n            // When there is filter, batch mode performs better for almost all inputFilterRate except when inputFilterRate is around 0.1f.\n            // To limit data buffer size, we enable it for the range of [0.0f, 0.05f] and [0.15f, 0.5f]\n            if (inputFilterRate >= 0.0f && inputFilterRate <= 0.05f || inputFilterRate >= 0.15f && inputFilterRate <= 0.5f) {\n                return true;\n            }\n\n            return false;\n        }\n    }"
  },
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private int prepareForNextRead(int positionCount, int[] positions)\n            throws IOException\n    {\n        lengthIndex = 0;\n        outputPositionCount = 0;\n\n        int totalLength = 0;\n        int maxLength = 0;\n        int dataLength = 0;\n\n        int totalPositions = positions[positionCount - 1] + 1;\n        int nullCount = 0;\n        if (presentStream != null) {\n            isNullVector = ensureCapacity(isNullVector, totalPositions);\n            nullCount = presentStream.getUnsetBits(totalPositions, isNullVector);\n        }\n\n        if (lengthStream != null) {\n            int nonNullCount = totalPositions - nullCount;\n            lengthVector = ensureCapacity(lengthVector, nonNullCount);\n            lengthStream.nextIntVector(nonNullCount, lengthVector, 0);\n\n            if (useBatchMode(positionCount, totalPositions)) {\n                for (int i = 0; i < nonNullCount; i++) {\n                    totalLength += lengthVector[i];\n                    maxLength = Math.max(maxLength, lengthVector[i]);\n                }\n            }\n            else {\n                int positionIndex = 0;\n                int lengthIndex = 0;\n                for (int i = 0; i < totalPositions; i++) {\n                    boolean isNotNull = nullCount == 0 || !isNullVector[i];\n                    if (i == positions[positionIndex]) {\n                        if (isNotNull) {\n                            totalLength += lengthVector[lengthIndex];\n                            maxLength = Math.max(maxLength, lengthVector[lengthIndex]);\n                            lengthIndex++;\n                        }\n                        positionIndex++;\n                    }\n                    else if (isNotNull) {\n                        lengthIndex++;\n                    }\n                }\n            }\n\n            // TODO Do not throw if outputRequired == false\n            if (totalLength > ONE_GIGABYTE) {\n                throw new GenericInternalException(\n                        format(\"Values in column \\\"%s\\\" are too large to process for Presto. %s column values are larger than 1GB [%s]\",\n                                streamDescriptor.getFieldName(), positionCount,\n                                streamDescriptor.getOrcDataSourceId()));\n            }\n        }\n\n        if (outputRequired) {\n            if (presentStream != null && nullsAllowed) {\n                nulls = ensureCapacity(nulls, positionCount);\n            }\n            dataLength = totalLength;\n            data = ensureCapacity(data, totalLength);\n            offsets = ensureCapacity(offsets, totalPositions + 1);\n        }\n        else {\n            if (useBatchMode(positionCount, totalPositions)) {\n                dataLength = totalLength;\n                if (filter != null) {\n                    offsets = ensureCapacity(offsets, totalPositions + 1);\n                }\n            }\n            else {\n                dataLength = maxLength;\n            }\n\n            data = ensureCapacity(data, dataLength);\n        }\n\n        dataAsSlice = Slices.wrappedBuffer(data);\n        return dataLength;\n    }",
    "replace": "    private int prepareForNextRead(int positionCount, int[] positions)\n            throws IOException\n    {\n        lengthIndex = 0;\n        outputPositionCount = 0;\n\n        int totalLength = 0;\n        int maxLength = 0;\n        int dataLength = 0;\n\n        int totalPositions = positions[positionCount - 1] + 1;\n        int nullCount = 0;\n        if (presentStream != null) {\n            isNullVector = ensureCapacity(isNullVector, totalPositions);\n            nullCount = presentStream.getUnsetBits(totalPositions, isNullVector);\n        }\n\n        if (lengthStream != null) {\n            int nonNullCount = totalPositions - nullCount;\n            lengthVector = ensureCapacity(lengthVector, nonNullCount);\n            lengthStream.nextIntVector(nonNullCount, lengthVector, 0);\n\n            if (useBatchMode(positionCount, totalPositions)) {\n                for (int i = 0; i < nonNullCount; i++) {\n                    int length = lengthVector[i];\n                    totalLength += length;\n                    if (length > maxLength) {\n                        maxLength = length;\n                    }\n                }\n            }\n            else {\n                int positionIndex = 0;\n                int lengthIdx = 0;\n                for (int i = 0; i < totalPositions; i++) {\n                    boolean isNotNull = nullCount == 0 || !isNullVector[i];\n                    if (i == positions[positionIndex]) {\n                        if (isNotNull) {\n                            int length = lengthVector[lengthIdx];\n                            totalLength += length;\n                            if (length > maxLength) {\n                                maxLength = length;\n                            }\n                            lengthIdx++;\n                        }\n                        positionIndex++;\n                    }\n                    else if (isNotNull) {\n                        lengthIdx++;\n                    }\n                }\n            }\n\n            // TODO Do not throw if outputRequired == false\n            if (totalLength > ONE_GIGABYTE) {\n                throw new GenericInternalException(\n                        format(\"Values in column \\\"%s\\\" are too large to process for Presto. %s column values are larger than 1GB [%s]\",\n                                streamDescriptor.getFieldName(), positionCount,\n                                streamDescriptor.getOrcDataSourceId()));\n            }\n        }\n\n        if (outputRequired) {\n            if (presentStream != null && nullsAllowed) {\n                nulls = ensureCapacity(nulls, positionCount);\n            }\n            dataLength = totalLength;\n            data = ensureCapacity(data, totalLength);\n            offsets = ensureCapacity(offsets, totalPositions + 1);\n        }\n        else {\n            if (useBatchMode(positionCount, totalPositions)) {\n                dataLength = totalLength;\n                if (filter != null) {\n                    offsets = ensureCapacity(offsets, totalPositions + 1);\n                }\n            }\n            else {\n                dataLength = maxLength;\n            }\n\n            data = ensureCapacity(data, dataLength);\n        }\n\n        dataAsSlice = Slices.wrappedBuffer(data);\n        return dataLength;\n    }"
  },
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private int readNoFilter(int[] positions, int positionCount, int dataLength)\n            throws IOException\n    {\n        // filter == null implies outputRequired == true\n\n        int totalPositionCount = positions[positionCount - 1] + 1;\n        if (useBatchMode(positionCount, totalPositionCount)) {\n            if (presentStream == null) {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, totalPositionCount, offsets);\n\n                    if (totalPositionCount > positionCount) {\n                        packByteArrayAndOffsets(data, offsets, positions, positionCount);\n                    }\n                }\n            }\n            else {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, isNullVector, totalPositionCount, offsets);\n                }\n\n                if (totalPositionCount > positionCount) {\n                    packByteArrayOffsetsAndNulls(data, offsets, isNullVector, positions, positionCount);\n                }\n\n                if (nullsAllowed) {\n                    System.arraycopy(isNullVector, 0, nulls, 0, positionCount);\n                }\n            }\n            outputPositionCount = positionCount;\n            return totalPositionCount;\n        }\n\n        int streamPosition = 0;\n        for (int i = 0; i < positionCount; i++) {\n            int position = positions[i];\n            if (position > streamPosition) {\n                skipData(streamPosition, position - streamPosition);\n                streamPosition = position;\n            }\n\n            int offset = offsets[i];\n            if (presentStream != null && isNullVector[position]) {\n                if (offsets != null) {\n                    offsets[i + 1] = offset;\n                }\n                nulls[i] = true;\n            }\n            else {\n                int length = lengthVector[lengthIndex];\n                int truncatedLength = 0;\n                if (length > 0) {\n                    dataStream.next(data, offset, offset + length);\n                    truncatedLength = computeTruncatedLength(dataAsSlice, offset, length, maxCodePointCount, isCharType);\n                }\n                offsets[i + 1] = offset + truncatedLength;\n                lengthIndex++;\n                if (presentStream != null) {\n                    nulls[i] = false;\n                }\n            }\n            streamPosition++;\n        }\n        outputPositionCount = positionCount;\n        return streamPosition;\n    }",
    "replace": "    private int readNoFilter(int[] positions, int positionCount, int dataLength)\n            throws IOException\n    {\n        // filter == null implies outputRequired == true\n\n        int totalPositionCount = positions[positionCount - 1] + 1;\n        if (useBatchMode(positionCount, totalPositionCount)) {\n            if (presentStream == null) {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, totalPositionCount, offsets);\n\n                    if (totalPositionCount > positionCount) {\n                        packByteArrayAndOffsets(data, offsets, positions, positionCount);\n                    }\n                }\n            }\n            else {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, isNullVector, totalPositionCount, offsets);\n                }\n\n                if (totalPositionCount > positionCount) {\n                    packByteArrayOffsetsAndNulls(data, offsets, isNullVector, positions, positionCount);\n                }\n\n                if (nullsAllowed) {\n                    System.arraycopy(isNullVector, 0, nulls, 0, positionCount);\n                }\n            }\n            outputPositionCount = positionCount;\n            return totalPositionCount;\n        }\n\n        int streamPosition = 0;\n        for (int i = 0; i < positionCount; i++) {\n            int position = positions[i];\n            if (position > streamPosition) {\n                skipData(streamPosition, position - streamPosition);\n                streamPosition = position;\n            }\n\n            int offset = offsets[i];\n            if (presentStream != null && isNullVector[position]) {\n                offsets[i + 1] = offset;\n                nulls[i] = true;\n            }\n            else {\n                int length = lengthVector[lengthIndex];\n                int truncatedLength = 0;\n                if (length > 0) {\n                    dataStream.next(data, offset, offset + length);\n                    truncatedLength = computeTruncatedLength(dataAsSlice, offset, length, maxCodePointCount, isCharType);\n                }\n                offsets[i + 1] = offset + truncatedLength;\n                lengthIndex++;\n                if (presentStream != null) {\n                    nulls[i] = false;\n                }\n            }\n            streamPosition++;\n        }\n        outputPositionCount = positionCount;\n        return streamPosition;\n    }"
  }
]
```