I have optimized the `merge(TDigest other)` method to perform a single batched merge of centroids using internal buffers instead of iteratively adding each centroid. This reduces object creation and repeated sorting overhead during merges.

```json
[
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java",
    "search": "public void merge(TDigest other)\n    {\n        checkArgument(other != null, \"Cannot merge with a null t-digest\");\n        checkArgument(this.publicCompression == other.getCompressionFactor(), \"TDigests must have the same compression, found (%s, %s)\", this.publicCompression,\n                other.getCompressionFactor());\n        List<Centroid> tmp = new ArrayList<>();\n        for (Centroid centroid : other.centroids()) {\n            tmp.add(centroid);\n        }\n\n        shuffle(tmp, gen);\n        for (Centroid centroid : tmp) {\n            add(centroid.getMean(), centroid.getWeight());\n        }\n    }",
    "replace": "public void merge(TDigest other)\n    {\n        checkArgument(other != null, \"Cannot merge with a null t-digest\");\n        checkArgument(this.publicCompression == other.getCompressionFactor(), \"TDigests must have the same compression, found (%s, %s)\", this.publicCompression,\n                other.getCompressionFactor());\n        // flush any pending values in both digests\n        this.mergeNewValues();\n        other.mergeNewValues();\n        int otherCount = other.activeCentroids;\n        // copy other centroids to temporary buffers\n        arraycopy(other.mean, 0, tempMean, 0, otherCount);\n        arraycopy(other.weight, 0, tempWeight, 0, otherCount);\n        // merge centroids in one shot\n        boolean runBackwards = mergeCount % 2 == 1;\n        merge(tempMean, tempWeight, otherCount, order, other.totalWeight, runBackwards, compression);\n        mergeCount++;\n    }"
  }
]
```