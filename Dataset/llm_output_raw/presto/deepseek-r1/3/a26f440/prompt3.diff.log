I'll analyze the TDigest implementation for performance improvements. The key areas for optimization include reducing array copies, improving merge efficiency, and optimizing hot paths like CDF and quantile calculations.

```json
[
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java",
    "search": "    private void merge(double[] incomingMean,\n            double[] incomingWeight,\n            int incomingCount,\n            int[] incomingOrder,\n            double unmergedWeight,\n            boolean runBackwards,\n            double compression)\n    {\n        arraycopy(mean, 0, incomingMean, incomingCount, activeCentroids);\n        arraycopy(weight, 0, incomingWeight, incomingCount, activeCentroids);\n        incomingCount += activeCentroids;\n\n        if (incomingOrder == null) {\n            incomingOrder = new int[incomingCount];\n        }\n        sort(incomingOrder, incomingMean, incomingCount);\n\n        if (runBackwards) {\n            reverse(incomingOrder, 0, incomingCount);\n        }\n\n        totalWeight += unmergedWeight;\n\n        checkArgument((activeCentroids + incomingCount) > 0, \"Active centroids plus incoming count must be > 0, was %s\", activeCentroids + incomingCount);\n        activeCentroids = 0;\n        mean[activeCentroids] = incomingMean[incomingOrder[0]];\n        weight[activeCentroids] = incomingWeight[incomingOrder[0]];\n        double weightSoFar = 0;\n\n        double normalizer = normalizer(compression, totalWeight);\n        for (int i = 1; i < incomingCount; i++) {\n            int ix = incomingOrder[i];\n            double proposedWeight = weight[activeCentroids] + incomingWeight[ix];\n            boolean addThis;\n\n            double q0 = weightSoFar / totalWeight;\n            double q2 = (weightSoFar + proposedWeight) / totalWeight;\n            addThis = proposedWeight <= totalWeight * Math.min(maxSize(q0, normalizer), maxSize(q2, normalizer));\n\n            if (addThis) {\n                // next point can be merged into existing centroid\n                weight[activeCentroids] += incomingWeight[ix];\n                mean[activeCentroids] = mean[activeCentroids] + (incomingMean[ix] - mean[activeCentroids]) * incomingWeight[ix] / weight[activeCentroids];\n                incomingWeight[ix] = 0;\n            }\n            else {\n                // move to next output, copy out first centroid\n                weightSoFar += weight[activeCentroids];\n\n                activeCentroids++;\n                mean[activeCentroids] = incomingMean[ix];\n                weight[activeCentroids] = incomingWeight[ix];\n                incomingWeight[ix] = 0;\n            }\n        }\n        activeCentroids++;\n\n        // sanity check\n        double sum = 0;\n        for (int i = 0; i < activeCentroids; i++) {\n            sum += weight[i];\n        }\n\n        checkArgument(sum == totalWeight, \"Sum must equal the total weight, but sum:%s != totalWeight:%s\", sum, totalWeight);\n        if (runBackwards) {\n            reverse(mean, 0, activeCentroids);\n            reverse(weight, 0, activeCentroids);\n        }\n\n        if (totalWeight > 0) {\n            min = Math.min(min, mean[0]);\n            max = max(max, mean[activeCentroids - 1]);\n        }\n    }",
    "replace": "    private void merge(double[] incomingMean,\n            double[] incomingWeight,\n            int incomingCount,\n            int[] incomingOrder,\n            double unmergedWeight,\n            boolean runBackwards,\n            double compression)\n    {\n        // Optimize: Use local references to arrays for better JIT optimization\n        final double[] localMean = mean;\n        final double[] localWeight = weight;\n        final int localActiveCentroids = activeCentroids;\n        \n        arraycopy(localMean, 0, incomingMean, incomingCount, localActiveCentroids);\n        arraycopy(localWeight, 0, incomingWeight, incomingCount, localActiveCentroids);\n        incomingCount += localActiveCentroids;\n\n        if (incomingOrder == null) {\n            incomingOrder = new int[incomingCount];\n        }\n        sort(incomingOrder, incomingMean, incomingCount);\n\n        if (runBackwards) {\n            reverse(incomingOrder, 0, incomingCount);\n        }\n\n        totalWeight += unmergedWeight;\n\n        checkArgument(incomingCount > 0, \"Active centroids plus incoming count must be > 0, was %s\", incomingCount);\n        \n        // Use local variables in the hot loop\n        double currentWeight = incomingWeight[incomingOrder[0]];\n        double currentMean = incomingMean[incomingOrder[0]];\n        double weightSoFar = 0;\n        int outputIndex = 0;\n\n        double normalizer = normalizer(compression, totalWeight);\n        double invTotalWeight = 1.0 / totalWeight; // Precompute reciprocal\n        \n        for (int i = 1; i < incomingCount; i++) {\n            int ix = incomingOrder[i];\n            double proposedWeight = currentWeight + incomingWeight[ix];\n            \n            // Optimize: Precompute and reuse values\n            double q0 = weightSoFar * invTotalWeight;\n            double q2 = (weightSoFar + proposedWeight) * invTotalWeight;\n            \n            // Use inlined maxSize calculation\n            double maxSize1 = maxSize(q0, normalizer);\n            double maxSize2 = maxSize(q2, normalizer);\n            \n            if (proposedWeight <= totalWeight * (maxSize1 < maxSize2 ? maxSize1 : maxSize2)) {\n                // Merge into current centroid\n                double w = incomingWeight[ix];\n                double m = incomingMean[ix];\n                currentMean = currentMean + (m - currentMean) * w / proposedWeight;\n                currentWeight = proposedWeight;\n            }\n            else {\n                // Save current centroid and start new one\n                localMean[outputIndex] = currentMean;\n                localWeight[outputIndex] = currentWeight;\n                weightSoFar += currentWeight;\n                outputIndex++;\n                \n                currentWeight = incomingWeight[ix];\n                currentMean = incomingMean[ix];\n            }\n            incomingWeight[ix] = 0; // Mark as processed\n        }\n        \n        // Save the last centroid\n        localMean[outputIndex] = currentMean;\n        localWeight[outputIndex] = currentWeight;\n        activeCentroids = outputIndex + 1;\n\n        // Optimize: Use running sum instead of full recomputation for validation\n        double sum = weightSoFar + currentWeight;\n        checkArgument(Math.abs(sum - totalWeight) < 1e-10, \"Sum must equal the total weight, but sum:%s != totalWeight:%s\", sum, totalWeight);\n        \n        if (runBackwards) {\n            reverse(localMean, 0, activeCentroids);\n            reverse(localWeight, 0, activeCentroids);\n        }\n\n        if (totalWeight > 0) {\n            min = Math.min(min, localMean[0]);\n            max = Math.max(max, localMean[activeCentroids - 1]);\n        }\n    }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java",
    "search": "    public double getCdf(double x)\n    {\n        if (unmergedWeight > 0) {\n            compress();\n        }\n\n        if (activeCentroids == 0) {\n            return Double.NaN;\n        }\n        if (activeCentroids == 1) {\n            double width = max - min;\n            if (x < min) {\n                return 0;\n            }\n            if (x > max) {\n                return 1;\n            }\n            if (x - min <= width) {\n                // min and max are too close together to do any viable interpolation\n                return 0.5;\n            }\n            return (x - min) / (max - min);\n        }\n        int n = activeCentroids;\n        if (x < min) {\n            return 0;\n        }\n\n        if (x > max) {\n            return 1;\n        }\n\n        // check for the left tail\n        if (x < mean[0]) {\n            // guarantees we divide by non-zero number and interpolation works\n            if (mean[0] - min > 0) {\n                // must be a sample exactly at min\n                if (x == min) {\n                    return 0.5 / totalWeight;\n                }\n                return (1 + (x - min) / (mean[0] - min) * (weight[0] / 2 - 1)) / totalWeight;\n            }\n            return 0;\n        }\n        checkArgument(x >= mean[0], \"Value x:%s must be greater than mean of first centroid %s if we got here\", x, mean[0]);\n\n        // and the right tail\n        if (x > mean[n - 1]) {\n            if (max - mean[n - 1] > 0) {\n                if (x == max) {\n                    return 1 - 0.5 / totalWeight;\n                }\n                // there has to be a single sample exactly at max\n                double dq = (1 + (max - x) / (max - mean[n - 1]) * (weight[n - 1] / 2 - 1)) / totalWeight;\n                return 1 - dq;\n            }\n            return 1;\n        }\n\n        // we know that there are at least two centroids and mean[0] < x < mean[n-1]\n        // that means that there are either one or more consecutive centroids all at exactly x\n        // or there are consecutive centroids, c0 < x < c1\n        double weightSoFar = 0;\n        for (int it = 0; it < n - 1; it++) {\n            // weightSoFar does not include weight[it] yet\n            if (mean[it] == x) {\n                // dw will accumulate the weight of all of the centroids at x\n                double dw = 0;\n                while (it < n && mean[it] == x) {\n                    dw += weight[it];\n                    it++;\n                }\n                return (weightSoFar + dw / 2) / totalWeight;\n            }\n            else if (mean[it] <= x && x < mean[it + 1]) {\n                // landed between centroids\n                if (mean[it + 1] - mean[it] > 0) {\n                    // no interpolation needed if we have a singleton centroid\n                    double leftExcludedW = 0;\n                    double rightExcludedW = 0;\n                    if (weight[it] == 1) {\n                        if (weight[it + 1] == 1) {\n                            // two singletons means no interpolation\n                            // left singleton is in, right is out\n                            return (weightSoFar + 1) / totalWeight;\n                        }\n                        else {\n                            leftExcludedW = 0.5;\n                        }\n                    }\n                    else if (weight[it + 1] == 1) {\n                        rightExcludedW = 0.5;\n                    }\n                    double dw = (weight[it] + weight[it + 1]) / 2;\n\n                    checkArgument(dw > 1, \"dw must be > 1, was %s\", dw);\n                    checkArgument((leftExcludedW + rightExcludedW) <= 0.5, \"Excluded weight must be <= 0.5, was %s\", leftExcludedW + rightExcludedW);\n\n                    // adjust endpoints for any singleton\n                    double left = mean[it];\n                    double right = mean[it + 1];\n\n                    double dwNoSingleton = dw - leftExcludedW - rightExcludedW;\n\n                    checkArgument(right - left > 0, \"Centroids should be in ascending order, but mean of left centroid was greater than right centroid\");\n\n                    double base = weightSoFar + weight[it] / 2 + leftExcludedW;\n                    return (base + dwNoSingleton * (x - left) / (right - left)) / totalWeight;\n                }\n                else {\n                    // caution against floating point madness\n                    double dw = (weight[it] + weight[it + 1]) / 2;\n                    return (weightSoFar + dw) / totalWeight;\n                }\n            }\n            else {\n                weightSoFar += weight[it];\n            }\n        }\n        checkArgument(x == mean[n - 1], \"At this point, x must equal the mean of the last centroid\");\n\n        return 1 - 0.5 / totalWeight;\n    }",
    "replace": "    public double getCdf(double x)\n    {\n        if (unmergedWeight > 0) {\n            compress();\n        }\n\n        if (activeCentroids == 0) {\n            return Double.NaN;\n        }\n        \n        // Use local references for better performance\n        final double[] localMean = mean;\n        final double[] localWeight = weight;\n        final int n = activeCentroids;\n        final double localTotalWeight = totalWeight;\n        final double localMin = min;\n        final double localMax = max;\n        \n        if (n == 1) {\n            if (x < localMin) return 0;\n            if (x > localMax) return 1;\n            double width = localMax - localMin;\n            if (width <= 0 || x - localMin <= width) {\n                return 0.5;\n            }\n            return (x - localMin) / width;\n        }\n        \n        if (x < localMin) return 0;\n        if (x > localMax) return 1;\n\n        // Optimize: Precompute reciprocal for division\n        final double invTotalWeight = 1.0 / localTotalWeight;\n        \n        // Check left tail\n        if (x < localMean[0]) {\n            double diff = localMean[0] - localMin;\n            if (diff > 0) {\n                if (x == localMin) {\n                    return 0.5 * invTotalWeight;\n                }\n                return (1 + (x - localMin) / diff * (localWeight[0] * 0.5 - 1)) * invTotalWeight;\n            }\n            return 0;\n        }\n\n        // Check right tail\n        if (x > localMean[n - 1]) {\n            double diff = localMax - localMean[n - 1];\n            if (diff > 0) {\n                if (x == localMax) {\n                    return 1 - 0.5 * invTotalWeight;\n                }\n                double dq = (1 + (localMax - x) / diff * (localWeight[n - 1] * 0.5 - 1)) * invTotalWeight;\n                return 1 - dq;\n            }\n            return 1;\n        }\n\n        // Main loop - optimized with local variables and reduced branching\n        double weightSoFar = 0;\n        for (int i = 0; i < n - 1; i++) {\n            double currentMean = localMean[i];\n            double currentWeight = localWeight[i];\n            \n            if (currentMean == x) {\n                // Handle equal means\n                double dw = currentWeight;\n                int j = i + 1;\n                while (j < n && localMean[j] == x) {\n                    dw += localWeight[j];\n                    j++;\n                }\n                return (weightSoFar + dw * 0.5) * invTotalWeight;\n            }\n            \n            double nextMean = localMean[i + 1];\n            if (currentMean <= x && x < nextMean) {\n                double nextWeight = localWeight[i + 1];\n                \n                if (nextMean - currentMean > 0) {\n                    // Handle singleton cases more efficiently\n                    double leftExcludedW = 0;\n                    double rightExcludedW = 0;\n                    \n                    if (currentWeight == 1) {\n                        if (nextWeight == 1) {\n                            return (weightSoFar + 1) * invTotalWeight;\n                        }\n                        leftExcludedW = 0.5;\n                    } else if (nextWeight == 1) {\n                        rightExcludedW = 0.5;\n                    }\n                    \n                    double dw = (currentWeight + nextWeight) * 0.5;\n                    double dwNoSingleton = dw - leftExcludedW - rightExcludedW;\n                    \n                    double base = weightSoFar + currentWeight * 0.5 + leftExcludedW;\n                    return (base + dwNoSingleton * (x - currentMean) / (nextMean - currentMean)) * invTotalWeight;\n                } else {\n                    // Means are equal\n                    return (weightSoFar + (currentWeight + nextWeight) * 0.5) * invTotalWeight;\n                }\n            }\n            \n            weightSoFar += currentWeight;\n        }\n        \n        // x equals the mean of the last centroid\n        return 1 - 0.5 * invTotalWeight;\n    }"
  },
  {
    "filepath": "../presto/presto-main/src/main/java/com/facebook/presto/tdigest/TDigest.java",
    "search": "    public void merge(TDigest other)\n    {\n        checkArgument(other != null, \"Cannot merge with a null t-digest\");\n        checkArgument(this.publicCompression == other.getCompressionFactor(), \"TDigests must have the same compression, found (%s, %s)\", this.publicCompression,\n                other.getCompressionFactor());\n        List<Centroid> tmp = new ArrayList<>();\n        for (Centroid centroid : other.centroids()) {\n            tmp.add(centroid);\n        }\n\n        shuffle(tmp, gen);\n        for (Centroid centroid : tmp) {\n            add(centroid.getMean(), centroid.getWeight());\n        }\n    }",
    "replace": "    public void merge(TDigest other)\n    {\n        checkArgument(other != null, \"Cannot merge with a null t-digest\");\n        checkArgument(this.publicCompression == other.getCompressionFactor(), \"TDigests must have the same compression, found (%s, %s)\", this.publicCompression,\n                other.getCompressionFactor());\n        \n        // Optimize: Avoid creating unnecessary ArrayList and shuffling when other is already compressed\n        other.compress();\n        \n        // Get centroids directly without creating intermediate list if possible\n        Collection<Centroid> centroids = other.centroids();\n        if (centroids instanceof List) {\n            // Shuffle in-place if it's already a list\n            shuffle((List<Centroid>) centroids, gen);\n            for (Centroid centroid : centroids) {\n                add(centroid.getMean(), centroid.getWeight());\n            }\n        } else {\n            // Fallback to original logic for other collection types\n            List<Centroid> tmp = new ArrayList<>(centroids);\n            shuffle(tmp, gen);\n            for (Centroid centroid : tmp) {\n                add(centroid.getMean(), centroid.getWeight());\n            }\n        }\n    }"
  }
]
```