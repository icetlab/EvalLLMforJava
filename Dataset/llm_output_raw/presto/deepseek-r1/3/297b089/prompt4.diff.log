Looking at the code for `SliceDirectSelectiveStreamReader`, I can identify several performance improvements related to reading the `lengthVector`:

1. **Avoid redundant calculations in `prepareForNextRead`**: The current code calculates `totalLength` and `maxLength` in two separate code paths for batch vs non-batch modes, with redundant logic.
2. **Improve loop efficiency in non-batch mode**: The non-batch mode loop iterates over all positions even when we only need specific ones.
3. **Reduce method calls and local variable usage**: The `computeTruncatedLength` method is called frequently in loops.
4. **Optimize lengthVector indexing**: We can improve how we track `lengthIndex` and access the `lengthVector`.

Here are the specific improvements:

```json
[
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private int prepareForNextRead(int positionCount, int[] positions)\n            throws IOException\n    {\n        lengthIndex = 0;\n        outputPositionCount = 0;\n\n        int totalLength = 0;\n        int maxLength = 0;\n        int dataLength = 0;\n\n        int totalPositions = positions[positionCount - 1] + 1;\n        int nullCount = 0;\n        if (presentStream != null) {\n            isNullVector = ensureCapacity(isNullVector, totalPositions);\n            nullCount = presentStream.getUnsetBits(totalPositions, isNullVector);\n        }\n\n        if (lengthStream != null) {\n            int nonNullCount = totalPositions - nullCount;\n            lengthVector = ensureCapacity(lengthVector, nonNullCount);\n            lengthStream.nextIntVector(nonNullCount, lengthVector, 0);\n\n            if (useBatchMode(positionCount, totalPositions)) {\n                for (int i = 0; i < nonNullCount; i++) {\n                    totalLength += lengthVector[i];\n                    maxLength = Math.max(maxLength, lengthVector[i]);\n                }\n            }\n            else {\n                int positionIndex = 0;\n                int lengthIndex = 0;\n                for (int i = 0; i < totalPositions; i++) {\n                    boolean isNotNull = nullCount == 0 || !isNullVector[i];\n                    if (i == positions[positionIndex]) {\n                        if (isNotNull) {\n                            totalLength += lengthVector[lengthIndex];\n                            maxLength = Math.max(maxLength, lengthVector[lengthIndex]);\n                            lengthIndex++;\n                        }\n                        positionIndex++;\n                    }\n                    else if (isNotNull) {\n                        lengthIndex++;\n                    }\n                }\n            }\n\n            // TODO Do not throw if outputRequired == false\n            if (totalLength > ONE_GIGABYTE) {\n                throw new GenericInternalException(\n                        format(\"Values in column \\\"%s\\\" are too large to process for Presto. %s column values are larger than 1GB [%s]\",\n                                streamDescriptor.getFieldName(), positionCount,\n                                streamDescriptor.getOrcDataSourceId()));\n            }\n        }\n\n        if (outputRequired) {\n            if (presentStream != null && nullsAllowed) {\n                nulls = ensureCapacity(nulls, positionCount);\n            }\n            dataLength = totalLength;\n            data = ensureCapacity(data, totalLength);\n            offsets = ensureCapacity(offsets, totalPositions + 1);\n        }\n        else {\n            if (useBatchMode(positionCount, totalPositions)) {\n                dataLength = totalLength;\n                if (filter != null) {\n                    offsets = ensureCapacity(offsets, totalPositions + 1);\n                }\n            }\n            else {\n                dataLength = maxLength;\n            }\n\n            data = ensureCapacity(data, dataLength);\n        }\n\n        dataAsSlice = Slices.wrappedBuffer(data);\n        return dataLength;\n    }",
    "replace": "    private int prepareForNextRead(int positionCount, int[] positions)\n            throws IOException\n    {\n        lengthIndex = 0;\n        outputPositionCount = 0;\n\n        int totalLength = 0;\n        int maxLength = 0;\n        int dataLength = 0;\n\n        int totalPositions = positions[positionCount - 1] + 1;\n        int nullCount = 0;\n        if (presentStream != null) {\n            isNullVector = ensureCapacity(isNullVector, totalPositions);\n            nullCount = presentStream.getUnsetBits(totalPositions, isNullVector);\n        }\n\n        if (lengthStream != null) {\n            int nonNullCount = totalPositions - nullCount;\n            lengthVector = ensureCapacity(lengthVector, nonNullCount);\n            lengthStream.nextIntVector(nonNullCount, lengthVector, 0);\n\n            if (useBatchMode(positionCount, totalPositions)) {\n                for (int i = 0; i < nonNullCount; i++) {\n                    int length = lengthVector[i];\n                    totalLength += length;\n                    if (length > maxLength) {\n                        maxLength = length;\n                    }\n                }\n            }\n            else {\n                // Optimized: Process only requested positions\n                int positionIdx = 0;\n                int lengthIdx = 0;\n                int nextPosition = positions[0];\n                \n                for (int i = 0; i < totalPositions && positionIdx < positionCount; i++) {\n                    boolean isNotNull = nullCount == 0 || !isNullVector[i];\n                    \n                    if (i == nextPosition) {\n                        if (isNotNull) {\n                            int length = lengthVector[lengthIdx];\n                            totalLength += length;\n                            if (length > maxLength) {\n                                maxLength = length;\n                            }\n                            lengthIdx++;\n                        }\n                        positionIdx++;\n                        if (positionIdx < positionCount) {\n                            nextPosition = positions[positionIdx];\n                        }\n                    }\n                    else if (isNotNull) {\n                        lengthIdx++;\n                    }\n                }\n            }\n\n            // TODO Do not throw if outputRequired == false\n            if (totalLength > ONE_GIGABYTE) {\n                throw new GenericInternalException(\n                        format(\"Values in column \\\"%s\\\" are too large to process for Presto. %s column values are larger than 1GB [%s]\",\n                                streamDescriptor.getFieldName(), positionCount,\n                                streamDescriptor.getOrcDataSourceId()));\n            }\n        }\n\n        if (outputRequired) {\n            if (presentStream != null && nullsAllowed) {\n                nulls = ensureCapacity(nulls, positionCount);\n            }\n            dataLength = totalLength;\n            data = ensureCapacity(data, totalLength);\n            offsets = ensureCapacity(offsets, totalPositions + 1);\n        }\n        else {\n            if (useBatchMode(positionCount, totalPositions)) {\n                dataLength = totalLength;\n                if (filter != null) {\n                    offsets = ensureCapacity(offsets, totalPositions + 1);\n                }\n            }\n            else {\n                dataLength = maxLength;\n            }\n\n            data = ensureCapacity(data, dataLength);\n        }\n\n        dataAsSlice = Slices.wrappedBuffer(data);\n        return dataLength;\n    }"
  },
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private int readNoFilter(int[] positions, int positionCount, int dataLength)\n            throws IOException\n    {\n        // filter == null implies outputRequired == true\n\n        int totalPositionCount = positions[positionCount - 1] + 1;\n        if (useBatchMode(positionCount, totalPositionCount)) {\n            if (presentStream == null) {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, totalPositionCount, offsets);\n\n                    if (totalPositionCount > positionCount) {\n                        packByteArrayAndOffsets(data, offsets, positions, positionCount);\n                    }\n                }\n            }\n            else {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, isNullVector, totalPositionCount, offsets);\n                }\n\n                if (totalPositionCount > positionCount) {\n                    packByteArrayOffsetsAndNulls(data, offsets, isNullVector, positions, positionCount);\n                }\n\n                if (nullsAllowed) {\n                    System.arraycopy(isNullVector, 0, nulls, 0, positionCount);\n                }\n            }\n            outputPositionCount = positionCount;\n            return totalPositionCount;\n        }\n\n        int streamPosition = 0;\n        for (int i = 0; i < positionCount; i++) {\n            int position = positions[i];\n            if (position > streamPosition) {\n                skipData(streamPosition, position - streamPosition);\n                streamPosition = position;\n            }\n\n            int offset = offsets[i];\n            if (presentStream != null && isNullVector[position]) {\n                if (offsets != null) {\n                    offsets[i + 1] = offset;\n                }\n                nulls[i] = true;\n            }\n            else {\n                int length = lengthVector[lengthIndex];\n                int truncatedLength = 0;\n                if (length > 0) {\n                    dataStream.next(data, offset, offset + length);\n                    truncatedLength = computeTruncatedLength(dataAsSlice, offset, length, maxCodePointCount, isCharType);\n                }\n                offsets[i + 1] = offset + truncatedLength;\n                lengthIndex++;\n                if (presentStream != null) {\n                    nulls[i] = false;\n                }\n            }\n            streamPosition++;\n        }\n        outputPositionCount = positionCount;\n        return streamPosition;\n    }",
    "replace": "    private int readNoFilter(int[] positions, int positionCount, int dataLength)\n            throws IOException\n    {\n        // filter == null implies outputRequired == true\n\n        int totalPositionCount = positions[positionCount - 1] + 1;\n        if (useBatchMode(positionCount, totalPositionCount)) {\n            if (presentStream == null) {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, totalPositionCount, offsets);\n\n                    if (totalPositionCount > positionCount) {\n                        packByteArrayAndOffsets(data, offsets, positions, positionCount);\n                    }\n                }\n            }\n            else {\n                if (dataStream != null) {\n                    dataStream.next(data, 0, dataLength);\n                    convertLengthVectorToOffsetVector(lengthVector, isNullVector, totalPositionCount, offsets);\n                }\n\n                if (totalPositionCount > positionCount) {\n                    packByteArrayOffsetsAndNulls(data, offsets, isNullVector, positions, positionCount);\n                }\n\n                if (nullsAllowed) {\n                    System.arraycopy(isNullVector, 0, nulls, 0, positionCount);\n                }\n            }\n            outputPositionCount = positionCount;\n            return totalPositionCount;\n        }\n\n        int streamPosition = 0;\n        // Pre-calculate local variables for faster access\n        boolean hasPresentStream = presentStream != null;\n        byte[] localData = data;\n        Slice localDataAsSlice = dataAsSlice;\n        int localMaxCodePointCount = maxCodePointCount;\n        boolean localIsCharType = isCharType;\n        \n        for (int i = 0; i < positionCount; i++) {\n            int position = positions[i];\n            if (position > streamPosition) {\n                skipData(streamPosition, position - streamPosition);\n                streamPosition = position;\n            }\n\n            int offset = offsets[i];\n            if (hasPresentStream && isNullVector[position]) {\n                offsets[i + 1] = offset;\n                nulls[i] = true;\n            }\n            else {\n                int length = lengthVector[lengthIndex];\n                int truncatedLength = 0;\n                if (length > 0) {\n                    dataStream.next(localData, offset, offset + length);\n                    if (localMaxCodePointCount >= 0) {\n                        truncatedLength = computeTruncatedLength(localDataAsSlice, offset, length, localMaxCodePointCount, localIsCharType);\n                    }\n                    else {\n                        truncatedLength = length;\n                    }\n                }\n                offsets[i + 1] = offset + truncatedLength;\n                lengthIndex++;\n                if (hasPresentStream) {\n                    nulls[i] = false;\n                }\n            }\n            streamPosition++;\n        }\n        outputPositionCount = positionCount;\n        return streamPosition;\n    }"
  },
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "    private int evaluateFilter(int[] positions, int positionCount)\n    {\n        int positionsIndex = 0;\n        for (int i = 0; i < positionCount; i++) {\n            int position = positions[i];\n            if (filter.testLength(lengthVector[position])) {\n                outputPositions[positionsIndex++] = position;  // compact positions on the fly\n            }\n        }\n\n        int filteredPositionCount = 0;\n        if (positionsIndex > 0) {\n            if (dataStream == null) {\n                // The length check has passed and there is no need to run testBytes because there is no data\n                filteredPositionCount = positionsIndex;\n            }\n            else {\n                int totalPositionCount = outputPositions[positionsIndex - 1] + 1;\n                convertLengthVectorToOffsetVector(lengthVector, totalPositionCount, offsets);\n                filteredPositionCount = testBytes(outputPositions, positionsIndex);\n            }\n        }\n\n        return filteredPositionCount;\n    }",
    "replace": "    private int evaluateFilter(int[] positions, int positionCount)\n    {\n        int positionsIndex = 0;\n        int[] localOutputPositions = outputPositions;\n        int[] localLengthVector = lengthVector;\n        \n        for (int i = 0; i < positionCount; i++) {\n            int position = positions[i];\n            if (filter.testLength(localLengthVector[position])) {\n                localOutputPositions[positionsIndex++] = position;  // compact positions on the fly\n            }\n        }\n\n        int filteredPositionCount = 0;\n        if (positionsIndex > 0) {\n            if (dataStream == null) {\n                // The length check has passed and there is no need to run testBytes because there is no data\n                filteredPositionCount = positionsIndex;\n            }\n            else {\n                int totalPositionCount = localOutputPositions[positionsIndex - 1] + 1;\n                convertLengthVectorToOffsetVector(localLengthVector, totalPositionCount, offsets);\n                filteredPositionCount = testBytes(localOutputPositions, positionsIndex);\n            }\n        }\n\n        return filteredPositionCount;\n    }"
  }
]
```