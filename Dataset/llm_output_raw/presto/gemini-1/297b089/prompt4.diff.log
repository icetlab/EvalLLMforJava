The primary performance issue in `SliceDirectSelectiveStreamReader` is in the `prepareForNextRead` method, specifically how it reads value lengths and calculates their total sum. The existing implementation first reads all the lengths for non-null values into a `lengthVector` array using `lengthStream.nextIntVector()`, and then iterates over this array to compute the total length. This two-pass approach can be inefficient, especially for a large number of values.

My improvement combines these two steps into a single loop. Instead of the bulk-read `nextIntVector`, I will iterate and read lengths one by one using `lengthStream.next()`. In the same loop, I will populate the `lengthVector` and accumulate the `totalLength`. This eliminates one full iteration over the `lengthVector`, reducing data access and improving performance.

Additionally, I've identified and fixed a potential integer overflow bug. The `totalLength` was an `int`, which could overflow with a large number of values before being checked against the 1GB limit. I've changed it to a `long` during accumulation to prevent this, ensuring the size check is accurate. The `maxLength` calculation is also removed in the batch mode path as it was unused, providing a minor additional optimization.

```json
[
  {
    "filepath": "../presto/presto-orc/src/main/java/com/facebook/presto/orc/reader/SliceDirectSelectiveStreamReader.java",
    "search": "        if (lengthStream != null) {\n            int nonNullCount = totalPositions - nullCount;\n            lengthVector = ensureCapacity(lengthVector, nonNullCount);\n            lengthStream.nextIntVector(nonNullCount, lengthVector, 0);\n\n            if (useBatchMode(positionCount, totalPositions)) {\n                for (int i = 0; i < nonNullCount; i++) {\n                    totalLength += lengthVector[i];\n                    maxLength = Math.max(maxLength, lengthVector[i]);\n                }\n            }\n            else {\n                int positionIndex = 0;\n                int lengthIndex = 0;\n                for (int i = 0; i < totalPositions; i++) {\n                    boolean isNotNull = nullCount == 0 || !isNullVector[i];\n                    if (i == positions[positionIndex]) {\n                        if (isNotNull) {\n                            totalLength += lengthVector[lengthIndex];\n                            maxLength = Math.max(maxLength, lengthVector[lengthIndex]);\n                            lengthIndex++;\n                        }\n                        positionIndex++;\n                    }\n                    else if (isNotNull) {\n                        lengthIndex++;\n                    }\n                }\n            }\n\n            // TODO Do not throw if outputRequired == false\n            if (totalLength > ONE_GIGABYTE) {\n                throw new GenericInternalException(\n                        format(\"Values in column \\\"%s\\\" are too large to process for Presto. %s column values are larger than 1GB [%s]\",\n                                streamDescriptor.getFieldName(), positionCount,\n                                streamDescriptor.getOrcDataSourceId()));\n            }\n        }",
    "replace": "        if (lengthStream != null) {\n            int nonNullCount = totalPositions - nullCount;\n            lengthVector = ensureCapacity(lengthVector, nonNullCount);\n            long longTotalLength = 0;\n\n            if (useBatchMode(positionCount, totalPositions)) {\n                for (int i = 0; i < nonNullCount; i++) {\n                    int length = (int) lengthStream.next();\n                    lengthVector[i] = length;\n                    longTotalLength += length;\n                }\n                // maxLength is not used in batch mode\n            }\n            else {\n                lengthStream.nextIntVector(nonNullCount, lengthVector, 0);\n                int positionIndex = 0;\n                int lengthIndex = 0;\n                for (int i = 0; i < totalPositions; i++) {\n                    boolean isNotNull = nullCount == 0 || !isNullVector[i];\n                    if (i == positions[positionIndex]) {\n                        if (isNotNull) {\n                            longTotalLength += lengthVector[lengthIndex];\n                            maxLength = Math.max(maxLength, lengthVector[lengthIndex]);\n                            lengthIndex++;\n                        }\n                        positionIndex++;\n                    }\n                    else if (isNotNull) {\n                        lengthIndex++;\n                    }\n                }\n            }\n\n            // TODO Do not throw if outputRequired == false\n            if (longTotalLength > ONE_GIGABYTE) {\n                throw new GenericInternalException(\n                        format(\"Values in column \\\"%s\\\" are too large to process for Presto. %s column values are larger than 1GB [%s]\",\n                                streamDescriptor.getFieldName(), positionCount,\n                                streamDescriptor.getOrcDataSourceId()));\n            }\n            totalLength = (int) longTotalLength;\n        }"
  }
]
```