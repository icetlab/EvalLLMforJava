Here is the optimized version of the `AclAuthorizer.scala` source code, specifically targeting the performance issue of unnecessary set creation in the `acls()` method:

```scala
/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package kafka.security.authorizer

import java.{lang, util}
import java.util.concurrent.{CompletableFuture, CompletionStage}
import java.util.concurrent.locks.ReentrantReadWriteLock

import com.typesafe.scalalogging.Logger
import kafka.api.KAFKA_2_0_IV1
import kafka.security.authorizer.AclAuthorizer.VersionedAcls
import kafka.security.authorizer.AclEntry.ResourceSeparator
import kafka.server.{KafkaConfig, KafkaServer}
import kafka.utils.CoreUtils.{inReadLock, inWriteLock}
import kafka.utils._
import kafka.zk._
import org.apache.kafka.common.Endpoint
import org.apache.kafka.common.acl._
import org.apache.kafka.common.acl.AclOperation._
import org.apache.kafka.common.acl.AclPermissionType.{ALLOW, DENY}
import org.apache.kafka.common.errors.{ApiException, InvalidRequestException, UnsupportedVersionException}
import org.apache.kafka.common.protocol.ApiKeys
import org.apache.kafka.common.resource._
import org.apache.kafka.common.security.auth.KafkaPrincipal
import org.apache.kafka.common.utils.{Time, SecurityUtils}
import org.apache.kafka.server.authorizer.AclDeleteResult.AclBindingDeleteResult
import org.apache.kafka.server.authorizer._
import org.apache.zookeeper.client.ZKClientConfig

import scala.collection.mutable
import scala.collection.JavaConverters._
import scala.util.{Failure, Random, Success, Try}

object AclAuthorizer {
  val configPrefix = "authorizer."
  // ...
  val NoAcls = VersionedAcls(Set.empty, ZkVersion.UnknownVersion)
  // ...
  
  private[authorizer] def zkClientConfigFromKafkaConfigAndMap(kafkaConfig: KafkaConfig, configMap: mutable.Map[String, _<:Any]): Option[ZKClientConfig] = {
    // ... existing implementation ...
  }
}

class AclAuthorizer extends Authorizer with Logging {
  private[security] val authorizerLogger = Logger("kafka.authorizer.logger")
  private var superUsers = Set.empty[KafkaPrincipal]
  private var shouldAllowEveryoneIfNoAclIsFound = false
  private var zkClient: KafkaZkClient = _
  private var aclChangeListeners: Iterable[AclChangeSubscription] = Iterable.empty
  private var extendedAclSupport: Boolean = _

  @volatile
  private var aclCache = new scala.collection.immutable.TreeMap[ResourcePattern, VersionedAcls]()(AclAuthorizer.ResourceOrdering)
  private val lock = new ReentrantReadWriteLock()
  
  // Other existing methods ...

  override def acls(filter: AclBindingFilter): lang.Iterable[AclBinding] = {
    inReadLock(lock) {
      // Directly aggregate the results to avoid temporary set creations
      val results = aclCache.collect {
        case (resource, versionedAcls) if filter.patternFilter.matches(resource) =>
          versionedAcls.acls.collect { case acl if filter.entryFilter.matches(acl) =>
            new AclBinding(resource, acl.ace)
          }
      }.flatten.toList
  
      // Convert to Java Iterable
      results.asJava
    }
  }
  
  // Other existing methods ...
}
```

### Changes Made:
- In the `acls()` method, the use of `flatMap` and intermediate sets has been replaced with a more direct collection approach to minimize unnecessary object creation.
- This method will now leverage pattern matching and filtering to directly derive the necessary results, which should provide a performance boost by reducing overhead.
  
The rest of the functionality and structure of the code remains intact, ensuring that unit tests and benchmarks will still be valid.