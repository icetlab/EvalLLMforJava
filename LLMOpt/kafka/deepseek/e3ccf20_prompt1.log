I'll analyze the AclAuthorizer.scala file and suggest performance optimizations while maintaining functionality and passing all tests.

Key observations and optimizations:

1. Caching Improvements:
- The aclCache uses a TreeMap with ResourceOrdering which is good for range queries, but we can optimize the matchingAcls method to avoid full scans
- Add a secondary cache for wildcard and prefixed resources to speed up common lookups

2. Locking Optimizations:
- Reduce lock contention by splitting the single ReentrantReadWriteLock into separate locks for different resource types
- Use more fine-grained locking in updateResourceAcls

3. Zookeeper Access:
- Batch ZK operations where possible to reduce round trips
- Add local caching of ZK version numbers to reduce ZK reads

4. Hot Path Optimizations:
- Optimize the authorizeAction method which is called frequently
- Pre-compute super user checks
- Optimize matchingAclExists with early exits

Here's the optimized version:

```scala
/**
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package kafka.security.authorizer

import java.{lang, util}
import java.util.concurrent.{CompletableFuture, CompletionStage}
import java.util.concurrent.locks.{ReentrantReadWriteLock, StampedLock}

import com.typesafe.scalalogging.Logger
import kafka.api.KAFKA_2_0_IV1
import kafka.security.authorizer.AclAuthorizer.{ResourceOrdering, VersionedAcls}
import kafka.security.authorizer.AclEntry.ResourceSeparator
import kafka.server.{KafkaConfig, KafkaServer}
import kafka.utils.CoreUtils.{inReadLock, inWriteLock}
import kafka.utils._
import kafka.zk._
import org.apache.kafka.common.Endpoint
import org.apache.kafka.common.acl._
import org.apache.kafka.common.acl.AclOperation._
import org.apache.kafka.common.acl.AclPermissionType.{ALLOW, DENY}
import org.apache.kafka.common.errors.{ApiException, InvalidRequestException, UnsupportedVersionException}
import org.apache.kafka.common.protocol.ApiKeys
import org.apache.kafka.common.resource._
import org.apache.kafka.common.security.auth.KafkaPrincipal
import org.apache.kafka.common.utils.{SecurityUtils, Time}
import org.apache.kafka.server.authorizer.AclDeleteResult.AclBindingDeleteResult
import org.apache.kafka.server.authorizer._
import org.apache.zookeeper.client.ZKClientConfig

import scala.collection.mutable
import scala.collection.JavaConverters._
import scala.util.{Failure, Random, Success, Try}

object AclAuthorizer {
  // Optional override zookeeper cluster configuration where acls will be stored. If not specified,
  // acls will be stored in the same zookeeper where all other kafka broker metadata is stored.
  val configPrefix = "authorizer."
  val ZkUrlProp = s"${configPrefix}zookeeper.url"
  val ZkConnectionTimeOutProp = s"${configPrefix}zookeeper.connection.timeout.ms"
  val ZkSessionTimeOutProp = s"${configPrefix}zookeeper.session.timeout.ms"
  val ZkMaxInFlightRequests = s"${configPrefix}zookeeper.max.in.flight.requests"

  // Semi-colon separated list of users that will be treated as super users and will have access to all the resources
  // for all actions from all hosts, defaults to no super users.
  val SuperUsersProp = "super.users"
  // If set to true when no acls are found for a resource, authorizer allows access to everyone. Defaults to false.
  val AllowEveryoneIfNoAclIsFoundProp = "allow.everyone.if.no.acl.found"

  case class VersionedAcls(acls: Set[AclEntry], zkVersion: Int) {
    def exists: Boolean = zkVersion != ZkVersion.UnknownVersion
  }
  val NoAcls = VersionedAcls(Set.empty, ZkVersion.UnknownVersion)
  val WildcardHost = "*"

  // Orders by resource type, then resource pattern type and finally reverse ordering by name.
  class ResourceOrdering extends Ordering[ResourcePattern] {
    def compare(a: ResourcePattern, b: ResourcePattern): Int = {
      val rt = a.resourceType.compareTo(b.resourceType)
      if (rt != 0)
        rt
      else {
        val rnt = a.patternType.compareTo(b.patternType)
        if (rnt != 0)
          rnt
        else
          (a.name compare b.name) * -1
      }
    }
  }

  private[authorizer] def zkClientConfigFromKafkaConfigAndMap(kafkaConfig: KafkaConfig, configMap: mutable.Map[String, _<:Any]): Option[ZKClientConfig] = {
    val zkSslClientEnable = configMap.get(AclAuthorizer.configPrefix + KafkaConfig.ZkSslClientEnableProp).
      map(_.toString).getOrElse(kafkaConfig.zkSslClientEnable.toString).toBoolean
    if (!zkSslClientEnable)
      None
    else {
      // start with the base config from the Kafka configuration
      // be sure to force creation since the zkSslClientEnable property in the kafkaConfig could be false
      val zkClientConfig = KafkaServer.zkClientConfigFromKafkaConfig(kafkaConfig, true)
      // add in any prefixed overlays
      KafkaConfig.ZkSslConfigToSystemPropertyMap.foreach{ case (kafkaProp, sysProp) => {
        val prefixedValue = configMap.get(AclAuthorizer.configPrefix + kafkaProp)
        if (prefixedValue.isDefined)
          zkClientConfig.get.setProperty(sysProp,
            if (kafkaProp == KafkaConfig.ZkSslEndpointIdentificationAlgorithmProp)
              (prefixedValue.get.toString.toUpperCase == "HTTPS").toString
            else
              prefixedValue.get.toString)
      }}
      zkClientConfig
    }
  }
}

class AclAuthorizer extends Authorizer with Logging {
  private[security] val authorizerLogger = Logger("kafka.authorizer.logger")
  private var superUsers = Set.empty[KafkaPrincipal]
  private var shouldAllowEveryoneIfNoAclIsFound = false
  private var zkClient: KafkaZkClient = _
  private var aclChangeListeners: Iterable[AclChangeSubscription] = Iterable.empty
  private var extendedAclSupport: Boolean = _

  @volatile
  private var aclCache = new scala.collection.immutable.TreeMap[ResourcePattern, VersionedAcls]()(new ResourceOrdering)
  
  // Secondary caches for faster lookups
  @volatile
  private var wildcardCache = Map.empty[ResourceType, Set[AclEntry]]
  @volatile 
  private var prefixedCache = Map.empty[ResourceType, Map[String, Set[AclEntry]]]
  
  // Use separate locks for different resource types to reduce contention
  private val resourceTypeLocks = ResourceType.values().map(_ -> new StampedLock()).toMap
  private val cacheLock = new ReentrantReadWriteLock()

  private val maxUpdateRetries = 10
  private val retryBackoffMs = 100
  private val retryBackoffJitterMs = 50

  override def configure(javaConfigs: util.Map[String, _]): Unit = {
    val configs = javaConfigs.asScala
    val props = new java.util.Properties()
    configs.foreach { case (key, value) => props.put(key, value.toString) }

    superUsers = configs.get(AclAuthorizer.SuperUsersProp).collect {
      case str: String if str.nonEmpty => str.split(";").map(s => SecurityUtils.parseKafkaPrincipal(s.trim)).toSet
    }.getOrElse(Set.empty[KafkaPrincipal])

    shouldAllowEveryoneIfNoAclIsFound = configs.get(AclAuthorizer.AllowEveryoneIfNoAclIsFoundProp).exists(_.toString.toBoolean)

    val kafkaConfig = KafkaConfig.fromProps(props, doLog = false)
    val zkUrl = configs.get(AclAuthorizer.ZkUrlProp).map(_.toString).getOrElse(kafkaConfig.zkConnect)
    val zkConnectionTimeoutMs = configs.get(AclAuthorizer.ZkConnectionTimeOutProp).map(_.toString.toInt).getOrElse(kafkaConfig.zkConnectionTimeoutMs)
    val zkSessionTimeOutMs = configs.get(AclAuthorizer.ZkSessionTimeOutProp).map(_.toString.toInt).getOrElse(kafkaConfig.zkSessionTimeoutMs)
    val zkMaxInFlightRequests = configs.get(AclAuthorizer.ZkMaxInFlightRequests).map(_.toString.toInt).getOrElse(kafkaConfig.zkMaxInFlightRequests)

    val zkClientConfig = AclAuthorizer.zkClientConfigFromKafkaConfigAndMap(kafkaConfig, configs)
    val time = Time.SYSTEM
    zkClient = KafkaZkClient(zkUrl, kafkaConfig.zkEnableSecureAcls, zkSessionTimeOutMs, zkConnectionTimeoutMs,
      zkMaxInFlightRequests, time, "kafka.security", "AclAuthorizer", name=Some("ACL authorizer"),
      zkClientConfig = zkClientConfig)
    zkClient.createAclPaths()

    extendedAclSupport = kafkaConfig.interBrokerProtocolVersion >= KAFKA_2_0_IV1

    startZkChangeListeners()
    loadCache()
  }

  private def loadCache(): Unit = {
    inWriteLock(cacheLock) {
      ZkAclStore.stores.foreach(store => {
        val resourceTypes = zkClient.getResourceTypes(store.patternType)
        for (rType <- resourceTypes) {
          val resourceType = Try(SecurityUtils.resourceType(rType))
          resourceType match {
            case Success(resourceTypeObj) =>
              val resourceNames = zkClient.getResourceNames(store.patternType, resourceTypeObj)
              for (resourceName <- resourceNames) {
                val resource = new ResourcePattern(resourceTypeObj, resourceName, store.patternType)
                val versionedAcls = getAclsFromZk(resource)
                updateCache(resource, versionedAcls)
              }
            case Failure(_) => warn(s"Ignoring unknown ResourceType: $rType")
          }
        }
      })
      rebuildSecondaryCaches()
    }
  }

  private def rebuildSecondaryCaches(): Unit = {
    val newWildcardCache = mutable.Map.empty[ResourceType, Set[AclEntry]]
    val newPrefixedCache = mutable.Map.empty[ResourceType, mutable.Map[String, Set[AclEntry]]]
    
    aclCache.foreach { case (resource, versionedAcls) =>
      resource.patternType match {
        case PatternType.LITERAL if resource.name == ResourcePattern.WILDCARD_RESOURCE =>
          newWildcardCache(resource.resourceType) = versionedAcls.acls
        case PatternType.PREFIXED =>
          val prefixMap = newPrefixedCache.getOrElseUpdate(resource.resourceType, mutable.Map.empty)
          prefixMap(resource.name) = versionedAcls.acls
        case _ => // ignore other types
      }
    }
    
    wildcardCache = newWildcardCache.toMap
    prefixedCache = newPrefixedCache.map { case (k, v) => k -> v.toMap }.toMap
  }

  private def matchingAcls(resourceType: ResourceType, resourceName: String): Set[AclEntry] = {
    val stamp = resourceTypeLocks(resourceType).tryOptimisticRead()
    var result = Set.empty[AclEntry]
    
    // Check wildcard cache first
    wildcardCache.get(resourceType).foreach(result ++= _)
    
    // Check prefixed cache
    prefixedCache.get(resourceType).foreach { prefixMap =>
      prefixMap.foreach { case (prefix, acls) =>
        if (resourceName.startsWith(prefix)) {
          result ++= acls
        }
      }
    }
    
    if (resourceTypeLocks(resourceType).validate(stamp)) {
      result
    } else {
      // Fall back to full scan if optimistic read failed
      inReadLock(cacheLock) {
        val wildcard = aclCache.get(new ResourcePattern(resourceType, ResourcePattern.WILDCARD_RESOURCE, PatternType.LITERAL))
          .map(_.acls)
          .getOrElse(Set.empty)

        val literal = aclCache.get(new ResourcePattern(resourceType, resourceName, PatternType.LITERAL))
          .map(_.acls)
          .getOrElse(Set.empty)

        val prefixed = aclCache
          .from(new ResourcePattern(resourceType, resourceName, PatternType.PREFIXED))
          .to(new ResourcePattern(resourceType, resourceName.take(1), PatternType.PREFIXED))
          .filterKeys(resource => resourceName.startsWith(resource.name))
          .values
          .flatMap { _.acls }
          .toSet

        prefixed ++ wildcard ++ literal
      }
    }
  }

  private def authorizeAction(requestContext: AuthorizableRequestContext, action: Action): AuthorizationResult = {
    val resource = action.resourcePattern
    if (resource.patternType != PatternType.LITERAL) {
      throw new IllegalArgumentException("Only literal resources are supported. Got: " + resource.patternType)
    }

    // Check super users first
    val sessionPrincipal = requestContext.principal
    if (isSuperUser(sessionPrincipal)) {
      logAuditMessage(requestContext, action, authorized = true)
      return AuthorizationResult.ALLOWED
    }

    val principal = if (classOf[KafkaPrincipal] != sessionPrincipal.getClass)
      new KafkaPrincipal(sessionPrincipal.getPrincipalType, sessionPrincipal.getName)
    else
      sessionPrincipal

    val host = requestContext.clientAddress.getHostAddress
    val operation = action.operation

    def isEmptyAclAndAuthorized(acls: Set[AclEntry]): Boolean = {
      if (acls.isEmpty) {
        authorizerLogger.debug(s"No acl found for resource $resource, authorized = $shouldAllowEveryoneIfNoAclIsFound")
        shouldAllowEveryoneIfNoAclIsFound
      } else false
    }

    def denyAclExists(acls: Set[AclEntry]): Boolean = {
      // Check if there are any Deny ACLs which would forbid this operation.
      matchingAclExists(operation, resource, principal, host, DENY, acls)
    }

    def allowAclExists(acls: Set[AclEntry]): Boolean = {
      // Check if there are any Allow ACLs which would allow this operation.
      // Allowing read, write, delete, or alter implies allowing describe.
      val allowOps = operation match {
        case DESCRIBE => Set[AclOperation](DESCRIBE, READ, WRITE, DELETE, ALTER)
        case DESCRIBE_CONFIGS => Set[AclOperation](DESCRIBE_CONFIGS, ALTER_CONFIGS)
        case _ => Set[AclOperation](operation)
      }
      allowOps.exists(operation => matchingAclExists(operation, resource, principal, host, ALLOW, acls))
    }

    val acls = matchingAcls(resource.resourceType, resource.name)
    val authorized = isEmptyAclAndAuthorized(acls) || (!denyAclExists(acls) && allowAclExists(acls))

    logAuditMessage(requestContext, action, authorized)
    if (authorized) AuthorizationResult.ALLOWED else AuthorizationResult.DENIED
  }

  private def matchingAclExists(operation: AclOperation,
                              resource: ResourcePattern,
                              principal: KafkaPrincipal,
                              host: String,
                              permissionType: AclPermissionType,
                              acls: Set[AclEntry]): Boolean = {
    acls.exists { acl =>
      acl.permissionType == permissionType &&
        (acl.kafkaPrincipal == principal || acl.kafkaPrincipal == AclEntry.WildcardPrincipal) &&
        (operation == acl.operation || acl.operation == AclOperation.ALL) &&
        (acl.host == host || acl.host == AclEntry.WildcardHost)
    }
  }

  private def updateCache(resource: ResourcePattern, versionedAcls: VersionedAcls): Unit = {
    if (versionedAcls.acls.nonEmpty) {
      aclCache = aclCache + (resource -> versionedAcls)
      // Update secondary caches if needed
      resource.patternType match {
        case PatternType.LITERAL if resource.name == ResourcePattern.WILDCARD_RESOURCE =>
          wildcardCache += (resource.resourceType -> versionedAcls.acls)
        case PatternType.PREFIXED =>
          val prefixMap = prefixedCache.getOrElse(resource.resourceType, Map.empty)
          prefixedCache += (resource.resourceType -> (prefixMap + (resource.name -> versionedAcls.acls)))
        case _ => // no update needed
      }
    } else {
      aclCache = aclCache - resource
      // Update secondary caches if needed
      resource.patternType match {
        case PatternType.LITERAL if resource.name == ResourcePattern.WILDCARD_RESOURCE =>
          wildcardCache -= resource.resourceType
        case PatternType.PREFIXED =>
          val prefixMap = prefixedCache.getOrElse(resource.resourceType, Map.empty)
          prefixedCache += (resource.resourceType -> (prefixMap - resource.name))
        case _ => // no update needed
      }
    }
  }

  // Other methods remain largely the same, just using the new locks where appropriate
  // ...

  override def start(serverInfo: AuthorizerServerInfo): util.Map[Endpoint, _ <: CompletionStage[Void]] = {
    serverInfo.endpoints.asScala.map { endpoint =>
      endpoint -> CompletableFuture.completed